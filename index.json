[{"categories":["dl-note"],"content":"L2归一化 L2 归一化（L2 normalization）是一种常用的数据处理操作，通常用于向量或矩阵。它的目的是将向量的每个元素除以该向量的 L2 范数（也称为欧几里德范数），以使得向量的长度为 1。这个操作也被称为向量的单位化（vector normalization）。这样，经过 L2 归一化后，向量的长度就变为 1，也就是说向量变成了单位向量。这种处理有助于在某些机器学习和数据处理任务中，使得向量之间的距离计算更加准确，也有助于降低数据的尺度差异对结果的影响。 ","date":"2024-03-15","objectID":"/posts/dl/note/202403/:1:0","tags":["dl-note"],"title":"202403","uri":"/posts/dl/note/202403/"},{"categories":["draft"],"content":"摘要 去噪扩散模型是一类生成模型，最近在各种深度学习问题中引起了极大的兴趣。扩散概率模型定义了一个正向扩散阶段，在这个阶段中，输入数据通过加入高斯噪声在几个步骤中逐渐受到扰动，然后学习反向扩散过程以从有噪声的数据样本中检索所需的无噪声数据。扩散模型因其强大的模式覆盖率和生成样本的质量而广受欢迎，尽管它们已知的计算负担。利用计算机视觉的进步，医学成像领域也观察到对扩散模型的兴趣日益增长。为了帮助研究人员浏览这一丰富的内容，本调查旨在提供医学成像学科中扩散模型的全面概述。具体来说，我们首先介绍扩散模型和三种通用扩散建模框架(即ddpm、ncsn和sde背后的坚实理论基础和基本概念。然后，我们对医学领域的扩散模型进行了系统的分类，并提出了基于其应用，成像方式，感兴趣的器官和算法的多视角分类。为此，我们涵盖了扩散模型在医学领域的广泛应用，包括图像到图像的转换、重建、配准、分类、分割、去噪、2/3D生成、异常检测和其他与医学相关的挑战。此外，我们强调了一些选定方法的实际用例，然后讨论了扩散模型在医学领域的局限性，并提出了满足该领域需求的几个方向。最后，我们在GitHub1上收集了概述的研究及其可用的开源实现。我们的目标是定期更新其中的相关最新论文。 图表(a)显示了根据应用分类的已发表论文的相对比例，(b)根据其成像方式分类的相对比例。(c)表示在医学领域发表的基于扩散的研究论文的数量。每年的增长速度揭示了扩散模型对未来工作的重要性。值得一提的是，论文总数为103篇。 ","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:1:0","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"介绍 在过去十年中，使用神经网络的生成建模一直是深度学习的主导力量。自其出现以来，生成模型在图像[1,2]、音频[3,4]、文本[5]和点云[6]等各个领域产生了巨大的影响。从概率建模的角度来看，生成模型的关键定义特征是它以这样一种方式进行训练，使其样本≈x ~ pθ(≈x)来自与训练数据分布x ~ pd(x)相同的分布。基于能量的模型(EBMs)通过定义状态空间上的非规范化概率密度来实现这一点;然而，这些方法在训练和推理过程中都需要马尔可夫链蒙特卡罗(MCMC)采样，这是一个缓慢的迭代过程[7]。在过去的几年里，由于一般深度学习架构的发展，人们对生成模型的兴趣重新燃起，揭示了视觉保真度和采样速度的提高。具体来说，已经出现了生成对抗网络(GANs)[8]、变分自编码器(vae)[9]和归一化流[10]。除此之外，基于扩散过程的生成模型为现有的V ae、EBMs、gan和规范化流提供了一种替代方案，这些模型不需要对后验分布进行对齐、估计难以处理的配分函数、引入额外的鉴别器网络或分别放置网络约束。迄今为止，已经发现扩散模型在许多领域都很有用，从生成建模任务(如图像生成[11]、图像超分辨率[12]、图像绘制[13])到判别任务(如图像分割[14]、分类[15]和异常检测[16])。最近，医学影像领域基于扩散的技术数量呈指数级增长(见图1)。如图1所示，大量研究致力于扩散模型在不同医学成像场景中的应用。由于扩散模型最近受到了研究界的极大关注，因此该方向的文献正在大量涌入。因此，对现有文献进行调查是有益的，也是及时的。为此，本调查旨在提供最近取得的进展的全面概述，并提供这类模型在医学成像的整体概述。对相关文献的彻底搜索表明，我们是第一个涵盖医学领域中利用的基于扩散的模型的人。我们希望这项工作将指出新的路径，为研究人员提供路线图，并激发视觉社区进一步的兴趣，以利用扩散模型在医学领域的潜力。我们的主要贡献包括: 这是第一篇全面涵盖扩散模型在医学成像领域应用的调查论文。具体来说，我们将全面概述所有可用的相关论文(直到2022年10月)，并展示2023年4月之前的一些最新技术。 我们设计了一个医学界扩散模型的多视角分类，为扩散模型及其应用的研究提供了一个系统的分类。我们将现有的扩散模型分为两类:基于变分的模型和基于分数的模型。此外，我们将扩散模型的应用分为九类:图像到图像的翻译、重建、配准、分类、分割、去噪、图像生成、异常检测和其他应用。 我们没有将注意力限制在应用上，并提供了一个新的分类法(见图5)，其中每篇论文分别根据所提出的算法以及相关器官和成像方式进行了广泛的分类。 最后，我们讨论了挑战和开放的问题，并确定了新的趋势，提出了关于扩散模型在医疗领域的算法和应用的未来发展的开放问题。 ","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:2:0","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"本次调查的动机和独特性 此外，我们相信医学界可以通过回顾我们的调查提供的扩散模型的过去和未来的研究方向，从视觉扩散模型的成功产品中获得启示。此外，扩散模型已经证明了它们在生成合成数据方面的潜力，可以作为现有真实数据的有效补充，以及生物医学逆成像问题的生成先验(如第3节所述)。尽管如此，我们并没有将我们的兴趣限制在应用上，而是描述了所提出方法的基本工作原理、器官和成像方式。 ","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:2:1","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"搜索策略 我们搜索了DBLP、Google Scholar和Arxiv Sanity Preserver，使用定制的搜索查询，因为它们允许定制搜索查询，并提供所有学术出版物的列表:同行评议的期刊论文或在会议或研讨会论文集中发表的论文，非同行评议的论文和预印本。我们的搜索查询是(扩散深度|医学|成像)(去噪|医学*)(扩散* |医学* |概率* |模型*)(评分* |扩散* |模型* |医学*)。 ","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:2:2","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"综述结构 在第2节中，我们详细概述了扩散模型背后的概念和理论基础，涵盖了扩散模型的两个视角。在第3节中，我们将深入研究在临床环境中使用生成模型，特别是扩散模型的意义，并讨论它们提供的好处。第4节全面介绍了扩散模型在几种医学成像任务中的应用，如图5所示，最后对不同的文献工作进行了特定任务的比较概述。我们通过在第5节中指出医学成像领域扩散模型面临的未来方向和开放挑战来总结这项调查。 ","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:2:3","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"理论 ","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:3:0","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"2.1Where do diffusion models fit the generative learning landscape? 随着可用数据集的显著激增，以及一般深度学习架构的进步，生成建模发生了革命性的范式转变。具体来说，三种主流生成框架包括gan[8]、V ae[9,24]和归一化流10。生成模型通常包含在现实世界问题中采用的关键要求。这些要求包括(i)高质量采样，(ii)模式覆盖和样本多样性，以及(iii)快速执行时间和计算成本低廉的采样26。 ","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:3:1","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"2.2 Variational Perspective ","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:3:2","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"2.3Score Perspective","date":"2023-09-06","objectID":"/posts/dl/diffusion/dminmi/:3:3","tags":["draft"],"title":"Dminmi","uri":"/posts/dl/diffusion/dminmi/"},{"categories":["draft"],"content":"MSE MSE（Mean Squared Error，均方误差）是一种常用的损失函数，通常用于衡量回归问题中预测值与实际值之间的差异。在机器学习和深度学习中，我们经常使用MSE来评估模型的性能，并通过优化算法（如梯度下降）来最小化这个损失函数，以使模型更好地拟合数据。 假设有一个回归问题，我们有n个样本数据，其中第i个样本的预测值为y_predi，实际值为y_truei（i = 1, 2, …, n）。那么MSE的计算公式如下： MSE = (1/n) * Σ(y_truei - y_predi)² 简而言之，MSE是预测值与真实值之间差异的平方和的均值。为了计算MSE，我们需要按照上述公式，将每个样本的预测值与实际值的差异平方后相加，然后除以样本数n来得到均值，这就是MSE的值。 ","date":"2023-07-30","objectID":"/posts/dl/diffusion/esssay/:1:0","tags":["draft"],"title":"Esssay","uri":"/posts/dl/diffusion/esssay/"},{"categories":["draft"],"content":"tokenizer 在自然语言处理（NLP）和机器学习中，分词器（Tokenizer）是一个用于将文本分解成单独的词（或标记）的工具。在NLP任务中，文本通常是由一系列字符组成的，而计算机在处理文本时通常需要将其拆分成更小的单元，例如单词或子词。 分词器的主要目标是将原始文本转换为语义上有意义的片段，使得文本可以更方便地被计算机处理。这些片段通常被称为“标记”（tokens），可以是单词、子词、字符或其他更小的语言单位，具体取决于分词器的类型和任务要求。 在NLP任务中，一些常见的分词器类型包括： 基于规则的分词器：这些分词器使用预定义的规则来将文本分割成标记。例如，通过空格将文本拆分成单词，或者使用特定的标点符号来划分句子。 统计分词器：这些分词器基于统计模型，使用概率方法来确定哪些部分应该被分割成标记。这些方法可以根据大量的文本数据学习词语的概率分布，然后根据概率来拆分文本。 子词分词器：这些分词器将单词拆分成更小的子词，例如将复杂单词拆分成词根或词缀。这种方法可以有效处理未登录词（Out-of-Vocabulary，OOV）问题，即在训练数据中没有出现的词。 神经网络分词器：随着深度学习的发展，使用神经网络模型来进行分词变得越来越流行。这些分词器使用循环神经网络（RNNs）、Transformer等结构来学习文本的上下文信息，并根据上下文来划分标记。 分词器是NLP任务中的重要组成部分，因为文本的正确切分对于后续的文本处理和特征提取等任务至关重要。不同的任务和语言可能需要不同类型的分词器来处理，因此在实际应用中，选择合适的分词器是很重要的。 ","date":"2023-07-30","objectID":"/posts/dl/diffusion/esssay/:2:0","tags":["draft"],"title":"Esssay","uri":"/posts/dl/diffusion/esssay/"},{"categories":["draft"],"content":"iamgenet 1000类的图片 约100万张图片； 分割是说， 我想知道某一个像素是属于谁； 样式迁移，样式迁移整体布局是不变的，不同于dreambooth，drambooth布局是可变的，是重新生成了一个物体。 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:0:0","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"数据操作 创建数组需要这些参数，什么形状规模的，数据类型是什么，元素的值是怎么定的。下图中左面正态分布就是说0的颜色绿色最多，两边的颜色少。右面均匀分布就是说每个颜色都是随机的。 张量表示一数值组成的数组，这个数组可能有多个维度。 基础操作如下： x = torch.arange(12) # 输出x： tensor([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) x.shape # torch.Size([12]) len(x) x.ndim # 获取x的维度 x.numel # 12 x.reshape(3,4) #tensor([[ 0, 1, 2, 3],[ 4, 5, 6, 7], [ 8, 9, 10, 11]]) # 创建全0或全1张量或指定值的张量 # 2 3 4 可以从后往前理解，最里层4个，然后有3个 4个的，最后有2个3*4的。 tensor([[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]], [[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]]) torch.zeros((2, 3, 4)) torch.ones((2, 3, 4)) torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) x = torch.tensor([1.0, 2, 4, 8]) y = torch.tensor([2, 2, 2, 2]) # 可以通过x+y，x-y， x/y，x*y，x**y进行运算，**是求幂运算 对每个元素做以上运算。 torch.exp(x) x = torch.arange(12, dtype=torch.float32).reshape((3, 4)) y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) x1 = torch.cat((X, Y), dim=0) y1 = torch.cat((X, Y), dim=0) x == y # 输出的也是一个tensor张量，x、y的shape是多大的 结果就是多大的，每一位上是true或false x.sum() # 对x这个张量进行求和 例如输出tensor(66.) x[-1] # 指访问最后一个元素 如果是3*4的张量就是说访问最后一行 x[1:3] # 标号为1的行就是第二行 因为下标从0开始，1:3 是左闭右开的 x[1, 2] = 9 # 还可以通过这样改变第二行第三列的值为9 x[0:2, :] = 12 # 第一行和第二行 中的全部列的值都置为12 广播机制，当两个张量的shape不一致，但是维度一致的时候也可以相加，这个时候用到的是广播机制，如这里a是3*1，b是1*2，a+b时候，a会复制成3*2，a会复制成3*2，然后进行相加。 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:1:0","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"数据预处理 对于缺失的数据可以选择删除，也可以选择插值，插值的方法就可以自己定了，比如可以插值其他元素的均值。 深度学习通常用64位浮点数。而不用32位。 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:2:0","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"线性代数 以下α是一个标量 A = torch.arange(20).reshape(5, 4) # 创建一个5行4列的矩阵 A.T # A矩阵的转置 对于对称矩阵A A = A的转置 # 给定具有相同形状的任何两个张量，任何按元素二元运算的结果都将是相同形状的张量 A = torch.arange(20, dtype=torch.float32).reshape(5, 4) B = A.clone() # 通过内存分配，将A的一个副本分配给B C = A + B # 两个矩阵的按元素乘法称为 哈达玛积 数学符号是个圆中间是个点 A * B # 一个标量和一个矩阵做相加，或相乘，就是这个标量加在每个元素上，或乘上每个元素 a = 2 X = torch.arange(24, dtype=torch.float32).reshape(2, 3, 4) a + X, (a * X).shape X.shape # 输出torch.size([2, 5, 4]) X.sum() # 输出 tensor(50) X_sum_axis0 = X.sum(axis=0) # 对第一个维度进行求和 就是把两个5*4的矩阵相加 结果的shape是 torch.Size([5, 4]) X_sum_axis1 = X.sum(axis=1) # 对第二个维度进行求和 就是把5个2*4的矩阵相加 结果的shape是 torch.Size([2, 4]) X.sum(axis= [0, 1]).shape # torch.Size([4]) X.mean # 求均值 等价于A.sum()/A.numel() X.mean(axis=0), X.sum(axis=0)/X.shape[0] # 也可以对某一个维度求均值 # 计算总和或均值时保持轴数不变，就是保持维度不变，因为有的时候需要进行广播机制的运算，如果维度不一致，那么无法计算 A = torch.arange(24).reshape(5, 4) sum_A = A.sum(axis=1, keepdims=True) # 保持了A的维度 例如如果A是(2, 5, 4)对0这个维度求和 那么结果的shape应该是(1, 5, 4)而不会变成(5, 4) 总结一下就是会把求和那个维度上的值变为1 A / sum_A # 这时可以进行广播运算 A.cumsum(axis=0) # 累计求和 输出如下，这个例子就是每一行的每个元素是上一行该位置的累加 tensor([[0., 1., 2., 3.], [4., 6., 8., 10.], [12., 15., 18., 21.], [40., 45., 50., 55.]]) # 点积 相同位置的按元素乘积的和 x = torch.arange(4) # tensor([0., 1., 2., 3.]) y = torch.ones(4, dtype=torch.float32)# tensor([1., 1., 1., 1.]) z = torch.dot(x, y) # 输出 tensor(6.) # 我们也可以通过执行按元素乘法，然后进行求和来表示两个向量的点积。 torch.sum(x*y) # torch.Size([5, 4]) torch.Size([4]) tensor([14.,38.,62.,86,110.]) A.shape, x.shape, torch,mv(A, x) # 这里做的是向量乘矩阵 torch.mm(A, B) # 两个矩阵做乘法 mm就是matmul # L2范数 是向量元素平方和的平方根，也就是欧式距离 u = torch.tensor([3.0, -4.0]) torch.norm(u) # 输出tensor(5.) # L1范数 向量元素的绝对值之和 torch.abs(u).sum() # 输出tensor(7.) # 矩阵的F范数 是矩阵元素的平方和的平方根 torch.norm(torch.ones((4, 9))) # 输出 tensor(6.) ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:3:0","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"矩阵计算 各种导数计算的结果是什么。 梯度指向的是值最大的方向 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:4:0","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"自动求导 # 对y=2XTX 求导 x = torch.arange(4.0) # 在我们计算导数之前，需要一个地方来存储梯度 x.requires_grad_(True) # 通过x.grad可以访问他的梯度（y关于x的导数）也可以写成x = torch.arange(4.0, requires_grad=True) y = 2 * torch.dot(x, x) # 打印这里y，tensor(28., grad_fn=\u003cMulBackward0\u003e) # 通过调用反向传播函数自动计算y关于x每个分量的梯度 y.backward() x.grad # 输出tensor([0., 4., 8., 12.]) # 测试一下是不是算对了，我们y=2xx，自己算一下 结果就是4x x.grad == 4 * x # 输出 tensor([True, True, True, True]) # 现在让我们计算x的另一个函数 # 在默认情况下，pytorch会累计梯度，我们需要清除之前的值 x.grad.zero_() y = x.sum() y.backward() x.grad # 输出 tensor([1., 1., 1., 1.]) # 在深度学习中，我们的目的不是计算微分矩阵，而是批量中每个样本单独计算的偏导数之和。 x.grad.zero_() y = x * x y.sum().backward() # 这里y.sum()没有特别理解，说是让他变成一个标量，对标量进行求导。在深度学习中，向量和矩阵，矩阵和矩阵的求导用到的很少。深度学习中 loss都是标量，所以是用这个标量对向量或矩阵进行求导。 x.grad # 下面这个例子也没有很懂，用于将某一部分的参数固定住。阻止梯度回传 x.grad.zero_() y = x * x u = y.detach() # 让这个导数不在和 y有关系 z = u * x z.sum().backward() x.grad == u # 输出 tensor([True, True, True, True]) # 情况2 x.grad_zero_() y.sum().backward() x.grad == 2 * x # 输出 tensor([True, True, True, True]) ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:5:0","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"线性回归 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:6:0","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"线性回归 1/2 应该是为了求导方便 等号最后一项是L2的平方 只有线性模型才会有最优解。其他的模型都没有最优解。除以2的目的是为了求导方便，平方的导数下来个2，和分母上的2约掉。 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:6:1","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"基础优化算法 当一个模型没有显示解的时候怎么办呢，用梯度下降的方法进行优化。右图是一个二次函数的等高图。每一个圈就是函数值等于一个值的曲线。梯度方向是指向函数的值增加的最快的方向，负梯度方向就是使函数的值下降的最快的方向。最中心的地方是我们想去的地方。 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:6:2","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"线性回归的从零实现 根据带有噪声的线性模型构造一个人造数据集。我们使用线性模型参数 W = [2, -3. 4]T 、b = 4.2 和噪声项 生成数据集及标签 定义一个data_iter函数，该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为batch_size的小批量 定义初始化模型参数 定义模型 定义损失函数 定义优化算法 开始训练 import random import torch # 根据带有噪声的线性模型构造一个人造数据集。我们使用线性模型参数 W = [2, -3. 4]T 、b = 4.2 和噪声项 生成数据集及标签 def synthetic_data(w, b, num_examples): # 生成 y = Xw + b + 噪声 X = torch.normal(0, 1, (num_examples, len(w))) # 生成均值为0，标准差为1，样本量（多少个样本）和样本长度（多少个属性）这里X的大小是1000*2的 y = torch.matmul(X, w) + b # 这里y的大小是1000 是一个一维张量 y += torch.normal(0, 0.01, y.shape) # 加入的噪声，均值为0，标准差为0.01 return X, y.reshape((-1, 1)) # -1表示自动计算维度,第二个维度是1，第一个是自动计算出来的，最终大小变成了[1000, 1]变成了二维张量，一个列向量 true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) # print('features:', features[0], '\\nlabel:', lables[0]) # 定义一个data_iter函数，该函数接收批量大小、特征矩阵和标签向量作为输入，生成大小为batch_size的小批量 def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # [0, 1, 2, 3......] # 这些样本是随机读取的，没有特定的顺序 random.shuffle(indices) # 打乱下标 for i in range(0, num_examples, batch_size): # 表示从 0 到 num_examples 每次跳batch_size大小 batch_indices = torch.tensor(indices[i:min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] batch_size = 10 # for X, y in data_iter(batch_size, features, labels): # print(X, '\\n', y) # break # 定义初始化模型参数 w = torch.normal(0, 0.01, size=(2, 1), requires_grad=True) b = torch.zeros(1, requires_grad=True) # 定义模型 def linreg(X, w, b): # 线性回归模型 return torch.matmul(X, w) + b # 定义损失函数 def squard_loss(y_hat, y): # 均方损失 return (y_hat - y.reshape(y_hat.shape))**2/2 # 定义优化算法 def sgd(params, lr, batch_size): # 小批量随机梯度下降 with torch.no_grad(): # 指的是更新的时候不需要进行梯度计算 for param in params: param -= lr * param.grad / batch_size param.grad.zero_() # 训练过程 lr = 0.03 num_epochs = 3 net = linreg loss = squard_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) # X 和 y的小批量损失 # 因为 l 的size 是 ['batch_size', 1] 而不是一个标量，l中的所有元素被加到一起 # 并以此计算关于[w, b]的梯度 l.sum().backward() sgd([w, b], lr, batch_size) # 使用参数的梯度更新 with torch.no_grad(): # 这块是训练完这一段之后，评估一下当前训练的情况 train_l = loss(net(features, w, b), labels) print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}') print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}') print(f'b的估计误差: {true_b - b}') 我们可以自己调整学习率，比如将学习率调整为0.001时，如果只训练3轮，误差非常大。如果将学习率调大，也不行。 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:6:3","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"线性回归的简洁实现 import numpy as np import torch from torch.utils import data from torch import nn def synthetic_data(w, b, num_examples): # 生成 y = Xw + b + 噪声 X = torch.normal(0, 1, (num_examples, len(w))) # 生成均值为0，标准差为1，样本量（多少个样本）和样本长度（多少个属性）这里X的大小是1000*2的 y = torch.matmul(X, w) + b # 这里y的大小是1000 是一个一维张量 y += torch.normal(0, 0.01, y.shape) # 加入的噪声，均值为0，标准差为0.01 return X, y.reshape((-1, 1)) # -1表示自动计算维度,第二个维度是1，第一个是自动计算出来的，最终大小变成了[1000, 1]变成了二维张量，一个列向量 # 生成数据集 true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) # 调用框架中现有的API来实现读取数据 def load_array(data_arrays, batch_size, is_train=True): #@save \"\"\"构造一个PyTorch数据迭代器\"\"\" dataset = data.TensorDataset(*data_arrays) # * 表示与list进行解开入参数 给元组解包 return data.DataLoader(dataset, batch_size, shuffle=is_train) batch_size = 10 data_iter = load_array((features, labels), batch_size) # 定义模型 net = nn.Sequential(nn.Linear(2, 1)) # 指定的是输入的维度是多少，输出的维度是多少 # 初始化模型参数 net[0].weight.data.normal_(0, 0.01) net[0].bias.data.fill_(0) # 定义损失函数 loss = nn.MSELoss() # 定义优化算法 trainer = torch.optim.SGD(net.parameters(), lr=0.03) # 训练 num_epochs = 3 for epoch in range(num_epochs): for X, y in data_iter: l = loss(net(X) ,y) trainer.zero_grad() l.backward() trainer.step() l = loss(net(features), labels) print(f'epoch {epoch + 1}, loss {l:f}') # w = net[0].weight.data # print('w的估计误差：', true_w - w.reshape(true_w.shape)) # b = net[0].bias.data # print('b的估计误差：', true_b - b) ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:6:4","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"Softmax回归 ","date":"2023-07-28","objectID":"/posts/dl/limu/01/:7:0","tags":["draft"],"title":"1","uri":"/posts/dl/limu/01/"},{"categories":["draft"],"content":"DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation DreamBooth:微调文本到图像的扩散模型，用于主题驱动的生成 环境和主题，让主题更好的融入环境之中。 梦幻的照相亭 语义漂移：只知道了特定的狗是什么，而忘记了一个dog是什么了。 本文发现prompt模板使用“a [identifier] [class noun]”方式效果最好。identifier的选取方法是在词汇表中找到相对稀有的token，采样后映射成相应字符串。实验发现， 提取T5-XXL 分词器范围 {5000, …, 10000} 中的token效果很好，使用随机抽样而不替换的方式，采样 3 个或更少的 Unicode 字符的对应的token组成identifier字符串。class noun选择要符合图像语义，效果最好。 finetune会产生两个关键问题：过拟合（Overfitting）（需要增加多样性）和语言漂移（ Language Drift） dreambooth——我们的 AI-powered photo booth——只需要几张主题的图片(通常是3-5张)(左图)，就可以在文本提示的引导下，在不同的背景下(右图)生成大量特定主题的图片。结果展示了与环境的自然相互作用，以及新颖的衔接和照明条件的变化，同时保持了对主体关键视觉特征的高保真度。 dreambooth的核心是用一个唯一标识符将用户想要的输入主体编码进输出域，并且在编码的过程中要避免overfitting和language drift，在推理时，当输入唯一标识符时，扩散模型就会去输出域的键值对中找出之前的主体。在操作中，同时对带有标识符的text和不带标识符的text进行finetune，主要是对text侧的编码能力的一次微调。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:0:0","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"Abstracrt 大型文本到图像模型在人工智能的发展中实现了显著的飞跃，从给定的文本提示中实现了高质量和多样化的图像合成。然而，这些模型缺乏模仿给定参考集中subject的外观和在不同上下文中合成新图片的能力。在这项工作中，我们提出了一种新的文本到图像扩散模型的“个性化”方法。给定一个主题的几张图像作为输入，我们对预训练的文本到图像模型进行微调，使其学会将唯一标识符identifier与特定subject绑定。一旦subject嵌入到模型的输出域中，就可以使用唯一标识符合成在不同场景中背景化的主题的新颖逼真图像。通过利用嵌入在模型中的语义先验和新的autogenous class-specific prior preservation loss（自生类特定先验保存损失），我们的技术能够综合参考图像中未出现的不同场景、姿势、视图和光照条件下的主体。我们将我们的技术应用于几个以前无坚不摧的任务，包括subject重新语境化，文本引导视图合成和艺术渲染，都能保留subject的关键特征。我们还为subject驱动生成的新任务提供了新的数据集和评估协议。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:1:0","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"1.Introduction 你能想象自己的狗在世界各地旅行，或者你最喜欢的包在巴黎最高档的陈列室展出吗?你的鹦鹉成为一本插图故事书的主角怎么样?渲染这样的虚构场景是一项具有挑战性的任务，需要在新的环境中合成特定主题(例如，对象，动物)的实例，以便它们自然无缝地融入场景。 最近开发的大型文本到图像模型显示出前所未有的能力，通过基于以自然语言编写的文本提示实现高质量和多样化的图像合成[51,58]。这种模型的主要优点之一是从大量图像标题对中学习到的强语义先验。例如，这样的先验学习将“狗”这个词与可以在图像中以不同姿势和上下文出现的狗的各种实例绑定在一起。虽然这些模型的综合能力是前所未有的，但它们缺乏模仿给定参考集中主题外观的能力，以及在不同上下文中合成相同主题的新表现的能力。主要原因是其输出域的表达性有限；即使是对一个物体最详细的文字描述也可能产生具有不同外观的实例。（我的理解是，prompt的描述 描述不明白）此外，即使是文本嵌入在共享语言视觉空间中的模型[50]也不能准确地重建给定主题的外观，而只能创建图像内容的变体(图2)。 图2：Subject-driven 生成。给定一个特定的时钟(左)，很难在保持其关键视觉特征的高保真度的情况下生成它(第二列和第三列显示DALLE2[51]图像引导生成和Imagen[58]文本引导生成;用于Imagen的文本提示:“复古风格的黄色闹钟，时钟面为白色，时钟面右侧为黄色数字3，位于丛林中”)retro style yellow alarm clock with a white clock face and a yellow number three on the right part of the clock face in the jungle。我们的方法(右)可以在新的环境中以高保真度合成时钟(文本提示:“丛林中的一个[V]时钟”a [V] clock in the jungle)。 在这项工作中，我们提出了一种“个性化”文本到图像扩散模型的新方法(使其适应用户特定的图像生成需求)。我们的目标是扩展模型的语言视觉词典，这样它就可以将新单词与用户想要生成的特定主题绑定在一起。一旦新字典被嵌入到模型中，它就可以使用这些单词合成新的逼真的主题图像，将其置于不同的场景中，同时保留其关键的识别特征。这种效果类似于一个“神奇的照相亭”——一旦拍摄了几张被摄者的照片，在简单直观的文字提示的引导下，照相亭就会生成被摄者在不同条件和场景下的照片(图1)。 更正式地说，给定主题的一些图像(3到5张)，我们的目标是将主题植入模型的输出域，以便它可以用唯一标识符unique identifier合成。为此，我们提出了一种技术，用罕见的令牌标识符来表示给定的主题，并对预训练的、基于扩散的文本到图像框架进行微调。To that end, we propose a technique to represent a given subject with rare token identifiers and fine-tune a pre-trained, diffusion-based text-to-image framework. 我们对文本到图像模型进行微调，输入图像和文本提示包含一个唯一标识符和主题的类名(例如，“a [V] dog”)。后者使模型能够使用其关于主题类的先验知识，而特定于类的实例则与唯一标识符绑定。为了防止语言漂移[32,38]导致模型将类名(例如“dog”)与特定实例相关联，我们提出了一种自生的、特定于类的先验保存损失autogenous, class-specific prior preservation loss，它利用嵌入在模型中的类的语义先验，并鼓励它生成与我们的主题相同的类的不同实例。 我们将我们的方法应用于无数基于文本的图像生成应用程序，包括主题的重新语境化，修改其属性，原始艺术再现等等，为以前无懈可击的任务的新流铺平了道路。我们通过消融研究强调了我们方法中每个组成部分的贡献，并与其他基线和相关工作进行了比较。与其他方法相比，我们还进行了一项用户研究，以评估我们合成图像中的主题和提示保真度。 据我们所知，我们的技术是第一个解决主题驱动生成这一新的挑战问题的技术，允许用户从一些随意捕获的主题图像中，在不同的背景下合成主题的新版本，同时保持其独特的特征。 为了评估这个新任务，我们还构建了一个新的数据集，包含了在不同环境中捕获的各种subject，并提出了一种新的评估方案，测量生成结果的subject保真度和prompt保真度。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:2:0","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"2.Related work ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:3:0","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"Image Composition 图像合成技术[13,36,67]旨在将给定的主体克隆到新的背景中，从而使主体融入场景。为了考虑新姿势的构图，人们可以应用3D重建技术[6,8,39,47,65]，这些技术通常适用于刚性物体，需要更多的视图。一些缺点包括场景集成(照明，阴影，接触)和无法生成新的场景。相比之下，我们的方法能够在新姿势和新环境中生成主体。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:3:1","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"Text-to-Image Editing and Synthesis 文本驱动的图像处理最近取得了重大进展，使用gan[9,22,27 - 29]结合图像-文本表示，如CLIP[50]，产生使用文本的逼真操作[2,7,21,41,46,68]。这些方法在结构化场景中（例如人脸编辑）工作得很好，但是在不同的主题不同的数据集中应用起来有一点困难。Crowson等人[14]使用VQ-GAN[18]并在更多样化的数据上进行训练来缓解这种担忧。其他工作[4,30]利用了最近的扩散模型[25,25,43,55,57,59 - 63]，这些模型在高度多样化的数据集上实现了最先进的生成质量，通常超过了gan[15]。虽然大多数只需要文本的工作仅限于全局编辑[14,31]，但Bar-Tal等[5]提出了一种不使用maks的基于文本的局部编辑技术，结果令人印象深刻。虽然这些编辑方法中的大多数都允许修改给定图像的全局属性或本地编辑，但没有一种方法能够在新的上下文中生成给定主题的新版本。 也有关于文本到图像合成的研究[14,16,19,24,26,33,34,48,49,52,55,64,71]。最近的大型文本到图像模型，如Imagen[58]、DALL-E2[51]、Parti[69]、CogView2[17]和Stable Diffusion[55]展示了前所未有的语义生成。这些模型不提供对生成的图像的细粒度控制，并且只使用文本引导。具体来说，在合成图像中始终保持subject的特点是具有挑战性或不可能的。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:3:2","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"Controllable Generative Models 有各种各样的方法来控制生成模型，其中一些可能被证明是主题驱动、提示引导图像合成的可行方向。Liu等人[37]提出了一种基于扩散的技术，允许在参考图像或文本的指导下进行图像变化。为了克服主题修改，一些工作[3,42]通过用户提供的掩码来限制修改的区域。Inversion[12,15,51]可用于在修改上下文的同时保留主题。Prompt-to-prompt[23]允许在没有输入掩码的情况下进行局部和全局编辑。这些方法不能保证subject的新样本生成的特点。 在GAN的背景下，Pivotal Tuning[54]允许通过使用inverted latent code anchor（倒置的潜在代码锚）来微调模型来进行真实的图像编辑，Nitzan等人[44]将这项工作扩展到人脸上的GAN微调以训练个性化先验，这需要大约100张图像，并且仅限于人脸域。Casanova等人[11]提出了一种实例条件GAN，它可以生成实例的变体，尽管它可以处理唯一的主题，并且不能保留所有主题的细节。 最后，Gal等人[20]的并行工作提出了一种方法，通过固定文本到图像模型的嵌入空间中的新标记来表示视觉概念，如对象或风格，从而产生小型个性化标记嵌入。这种方法受到冻结扩散模型的表现力的限制，但我们的微调方法使我们能够将subject嵌入模型的输出域中，从而生成subject的新图像，并保留其关键视觉特征。（这段讲的是textual inversion这种方法受到冻结扩散模型的表现力的限制，因为把扩散模型冻住了） ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:3:3","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"3.Method 给定只有少数(通常3-5)随意捕获的特定subject的图像，没有任何文本描述，我们的目标是生成具有高细节保真度的主题的新图像，并由文本提示引导变化。这种变化如包括更改主体位置、更改主体属性(如颜色或形状)、修改主体的姿势、视点和其他语义修改。我们不会对输入图像捕获设置施加任何限制（随意捕获），并且主题图像可以具有不同的上下文。接下来，我们提供了一些关于文本-图像扩散模型的背景知识(第3.1节)，然后介绍了我们的微调技术，将唯一标识符与少数图像中描述的主题绑定在一起(第3.2节)，最后提出了一个class-specific prior-preservation loss特定于类别的先验保存损失，使我们能够克服我们微调模型中的语义漂移(第3.3节)。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:4:0","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"3.1. Text-to-Image Diffusion Models 扩散模型是一种概率生成模型，通过对从高斯分布中采样的变量进行逐渐去噪来学习数据分布。具体来说，我们对预训练的文本到图像扩散模型(xθ)感兴趣，该模型给定初始噪声映射λ ~ N (0, I)和使用文本编码器Γ和文本提示符P生成的条件向量c = Γ(P)，生成图像xgen = φ xθ(λ， c)。它们使用平方误差损失进行训练以去噪变噪图像或潜在代码zt:= αtx + σ t，如下所示： 这里loss没有明白，-号之前的指的的加噪后的图像，利用加噪后的图像和c预测加噪之前的图像。 其中x是真实图像，c是条件向量(例如，从文本提示符获得)，αt， σt, wt是控制noise schedule和sample quality的项，和扩散过程时间t ~ U([0,1])的函数。在补充材料中给出了更详细的描述。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:4:1","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"3.2. Personalization of Text-to-Image Models 我们的第一个任务是将subject实例植入到模型的输出域中，这样我们就可以在模型中查询主题的各种新图像。一个自然的想法是使用主体的few-shot数据集来微调模型。在微调生成模型(如GANs)时，必须非常小心，因为它可能导致过拟合和模型崩溃，以及不能很好地捕获目标分布。已经有一些技术研究可以避免这些陷阱[35,40,45,53,66]，尽管与我们的工作相反，这方面的工作主要是寻求生成与目标分布相似但不需要主体保存的图像。关于这些陷阱，我们观察到一个奇特的发现，给予一个仔细的微调设置通过使用公式1中的扩散损失，大型文本到图像的扩散模型似乎擅长于将新信息整合到他们的领域，而不会忘记先验或过度拟合到一小组训练图像。 Designing Prompts for Few-Shot Personalization 为few-shot个性化设计提示。 我们的目标是在扩散模型的“字典”中“植入”一个新的(unique identifier，subject)对。为了绕过为给定图像集编写详细图像描述的开销，我们选择了一种更简单的方法，并将主题的所有输入图像标记为“一个a [identifier] [class noun]”，其中[identifier]是链接到主题的唯一标识符，[类名词]是主题的粗略类描述符(例如猫，狗，手表等)。class noun可以由用户提供，也可以使用分类器获得。**我们在句子中使用class noun是为了将类的先验性与我们唯一的主题联系起来，并发现使用错误的类描述符或没有类描述符会增加训练时间和语言漂移，同时降低性能。**从本质上讲，我们寻求利用特定类的模型的先验，并将其与我们主题的唯一标识符的嵌入纠缠在一起，这样我们就可以利用视觉先验来生成不同背景下主题的新姿势和新样子。 Rare-token Identifiers Rare-token标识符。 我们通常发现现有的英语单词(例如“unique”，“special”)不是最优的，因为模型必须学会将它们从原始含义中解脱出来，并重新纠缠它们以引用我们的主题。就是说我这里的唯一标识符必须没有什么异议，举个极端的例子说，如果这里是yellow，他本来就有自己的语义了，我们不想这样，或者说慢慢的就任务yellow就是了。这激发了对在语言模型和扩散模型中都具有弱先验的标识符的需求。这样做的一个危险的方法（就是说下面这个方法是不可取的）是在英语语言中选择随机字符并将它们连接起来以生成一个罕见的标识符(例如“xxy5syt00”)。实际上，标记器可能会单独标记每个字母（分词器把每个字母分开），扩散模型的先验对这些字母是强的。我们经常发现这些标记会产生与使用普通英语单词相似的弱点。我们的方法是在词汇表中找到罕见的标记，然后将这些标记倒转到文本空间中，以最小化具有强先验的标识符的概率（对于文本模型来讲，输入的text和token是一一对应的，找到稀有的token再反向得到文本）。我们在词汇表中对rare-token查找，并获得 rare token序列f(V)，其中f是tokenizer；一个将字符序列character sequences映射到tokens的函数，V是从标记f(V)中得到解码后的文本。序列长度为k，并且发现k ={1，…， 3}工作得很好。然后，通过使用f(V)上的去标记器反转词汇表，我们获得了定义唯一标识符V的字符序列。对于Imagen，我们发现对对应于3个或更少的Unicode字符(不含空格)的标记进行统一随机抽样，并使用T5-XXL标记器范围内的标{5000，…， 10000}效果很好。 Fine-tuning. Given ∼ 3−5 images of a subject we finetune a text-to-image diffusion model with the input images paired with a text prompt containing a unique identifier and the name of the class the subject belongs to (e.g., “A [V] dog”), in parallel, we apply a class-specific prior preservation loss, which leverages the semantic prior that the model has on the class and encourages it to generate diverse instances belong to the subject’s class using the class name in a text prompt (e.g., “A dog”). ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:4:2","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"3.3. Class-specific Prior Preservation Loss（创新点） 根据我们的经验，通过微调模型的所有层能获得最大主体保真度的最佳结果。这包括以文本嵌入为条件的微调层，这导致了语义漂移Language drift的问题。语言漂移一直是语言模型中观察到的一个问题[32,38]，语义漂移是说模型在大型文本语料库上进行预训练，然后针对特定任务进行微调，逐渐失去语言的语法和语义知识。据我们所知，我们是第一个发现影响扩散模型的类似现象的人，在扩散模型中，模型慢慢地忘记了如何生成与目标主体相同类别的主体。（就比如我们这个任务中，训练他生成黄色的闹钟，如果你再让他生成一个闹钟，他就不会生成闹钟了。所有语义信息都集中到了V上。） 另一个问题是产出多样性降低的可能性。文本到图像扩散模型具有大量的输出多样性。当对一小部分图像进行微调时，我们希望能够以新颖的视角，姿势和清晰度生成主题。因此，有一个风险是，减少了多样性，在拍摄对象的输出姿势和视角中存在减少可变性的风险(例如，捕捉到少数镜头的视角)。我们观察到，这种情况经常发生，特别是当模型训练时间过长时。 为了缓解上述两个问题，我们提出了一种autogenous class-specific prior preservation loss ，以鼓励多样性并防止语言漂移。从本质上讲，我们的方法是用自己生成的样本来监督模型，以便在几次微调开始后保持先验。这使它能够生成类先验的不同图像，并保留关于类先验的知识，它可以将这些知识与关于主题实例的知识结合使用。 其中第二项是先验保存项，它用自己生成的图像监督模型，λ控制这一项的相对权重。图3演示了使用类生成的样本和先验保存损失进行的模型微调。尽管很简单，但我们发现这种先验保存损失在鼓励输出多样性和克服语言漂移方面是有效的。我们还发现，我们可以训练模型进行更多的迭代，而不会有过拟合的风险。我们发现，对于Imagen [58]， λ = 1，学习率为10−5，对于Stable Diffusion[56]，学习率为5 × 10−6，并且使用3-5张图像的主题数据集大小足以获得良好的结果。这是什么意思在此过程中，生成约1000个“a[类名词]”样本-但可以使用的更少。Imagen的TPUv4训练过程大约需要5分钟，NVIDIA A100的稳定扩散训练过程大约需要5分钟。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:4:3","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"4. Experiments 在本节中，我们将展示实验和应用程序。我们的方法能够对我们的主题实例进行大量的文本引导语义修改，包括重新语境化、主题属性(如材料和物种)的修改、艺术再现和观点修改。重要的是，在所有这些修改中，我们能够保留赋予主题身份和本质的独特视觉特征。如果任务是重新语境化，那么主题特征是不变的，但外观(例如，姿势)可能会改变。如果任务是一个更强的语义修饰，例如我们的主语和另一个物种/对象之间的交叉，那么主语的关键特征在修饰后被保留。在本节中，我们使用[V]引用主体的唯一标识符。我们在素材中包含了具体的Imagen和Stable Diffusion实现细节。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:5:0","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"4.1. Dataset and Evaluation Dataset 我们收集了30个主题的数据集，包括独特的物品和宠物，如背包、毛绒玩具、狗、猫、太阳镜、卡通等。该数据集的图像由作者收集或来自Unsplash[1]。我们还收集了25个提示：20个重新上下文化提示和5个subject属性修改提示，10个重新语境化，10个配饰，5个属性修改提示。完整的图像和提示列表可以在补充材料中找到。 对于评估套件，我们为每个主题和每个提示生成四张图像，总共3,000（30*25*4）张图像。这允许我们稳健地度量方法的性能和泛化能力。我们在项目网页上公开了我们的数据集和评估协议，以便将来在评估主题驱动生成时使用。 Evaluation Metrics subject 保真度：用DINO和CLIP都去提取生成图像和原图的特征，对比特征的余弦相似度，相似度高就代表相似。为什么用这种方法，就是基于对比学习的思想，他俩都是同一个类别不同样本之间都是负样本，这样能更好的去代表subject的一个特征。 propmpt 保真度：输入的图片和文本的保真度，也是用CLIP去计算，余弦相似度。 要评估的一个重要方面是主体保真度：在生成的图像中保留主体细节。为此，我们计算了两个指标：CLIP-I和DINO[10]。CLIP- I是生成图像与真实图像的CLIP[50]嵌入之间的平均两两余弦相似度。尽管这一指标已在其他工作中使用[20]，但它并不是用来区分可能具有高度相似文本描述的不同主题的。（例如：两个不同的黄色时钟)。我们提出的DINO度量是生成图像和真实图像的ViTS/16 DINO嵌入之间的平均两两余弦相似度。这是我们首选的度量，因为，通过构造和与有监督网络相比，DINO不会被训练为忽略同一类主题之间的差异（DINO不会忽略同一subject的差距）。相反，自我监督训练目标鼓励区分主题或图像的独特特征。要评估的第二个重要方面是提示保真度，以提示和图像CLIP嵌入之间的平均余弦相似度来衡量。我们把它记作CLIP-T。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:5:1","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"4.2. Comparisons 我们使用Gal等人[20]中提供的超参数，将我们的结果与Textual Inversion进行比较。我们发现这项工作是在文献中唯一可与之相比的工作是主题驱动的，文本引导的，并产生了新颖的图像。我们使用Imagen为DreamBooth生成图像，使用稳定扩散为DreamBooth生成图像，使用稳定扩散为文本反转生成图像。我们计算DINO和CLIP-I受试者保真度指标和CLIP-T提示保真度指标。在表1中，我们显示了DreamBooth和Textual Inversion的主题和提示保真度指标的巨大差距。我们发现DreamBooth (Imagen)在主题保真度和提示保真度方面都比DreamBooth (Stable Diffusion)得分更高，接近真实图像主题保真度的上限。我们认为这是由于Imagen的表现力更强，输出质量更高。（笑死，Imagen是谷歌团队的） 此外，我们通过进行用户研究比较了Textual Inversion(SD)和DreamBooth(SD)。对于subject保真度，我们要求72名用户回答25个比较问题的问卷(每个问卷3名用户)，共计1800个答案。样本是从一个大的池中随机选择的。每个问题都展示一个主题的真实图像集，以及通过每种方法生成的该主题的一个图像(随机提示)。用户被要求回答这样一个问题:“两张图片中哪一张最能再现参考物品的身份(例如，物品类型和细节)?”，我们还包含了一个“不确定/两者相等”选项。类似地，对于提示保真度，我们问“两幅图像中哪一幅最适合参考文本描述?”我们使用多数投票对结果进行平均，并将其呈现在表2中。我们发现DreamBooth对于主题保真度和提示保真度都有压倒性的偏好。这有助于解释表1中的结果，在用户偏好方面，DINO差异约为0.1,CLIP-T差异为0.05（呵呵哒）就是数据上差了0.1，但是感官上更好，6啊。最后，我们在图4中展示了定性比较。我们观察到，DreamBooth更好地保留了主体身份，更忠实于提示。我们在供应材料中展示了用户研究的样本。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:5:2","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"4.3. Ablation Studies Prior Preservation Loss Ablation 我们对来自数据集的15个subject的Imagen进行了微调，有和没有我们提出的先验保存损失(PPL)。PPL旨在对抗语言漂移并保留先验。我们计算一个PRES标准（prior preservation metric），这个标准是计算先验类随机subject的生成图像（普通闹钟）与我们特定对象的真实图像（黄3闹钟）之间的平均成对DINO嵌入。这个度量越高，即类中的随机subject与我们的特定subject越相似，这表明先验崩溃。（就是说这个值越低越好，越不相似越好）我们在表3中报告了结果，并观察到PPL实质上抵消了语言漂移，并有助于保留生成前一类不同图像的能力。此外，我们计算一个多样性度量DIV，计算方式是同一subject，同一prompt生成的图片平均LPIPS余弦相似度，（越不相似越好，说明多样性好，这里DIV值越大表示距离越远，就是越不相似。） 我们观察到，使用PPL训练的模型实现了更高的多样性(subject保真度略有降低)，这也可以从图5中定性地观察到，其中使用PPL训练的模型对参考图像环境的过拟合较少，并且可以生成更多样化的姿态和关节的狗。（为什么会这样呢，我的理解是，用了PPL，更能让模型记住dog是什么，防止了所有的信息全到了V上，而忘记了dog是什么，这样的话我知道dog是什么，我生成的dog的样子就会更多一些。）其实这不就是一种权衡嘛，你到底让我去学这个特殊的黄色小闹钟，还是去让我学会生成一个闹钟。但是我觉得，按照应用上来讲，我就是想生成我独特subject在不同场景下的图片，那dreambooth是肯定没有问题的，对吧。带了PPL保真度下降，是因为不带这个ppl的话，肯定会更加拟合到目标训练集上，所以保真度会更好。有可以这么理解，这有可能是一种过拟合哦 Class-Prior Ablation 这里说的是a [V] [class noun] 后面的class noun。这个理解起来很直观。 我们在数据集主题的一个子集(5个主题)上对Imagen进行微调，其中没有类名词，随机抽样一个不正确的类名词和正确的类名词。有了subject,的正确类名词，我们就能忠实地适应subject,，利用类先验，使我们能够在各种上下文中生成subject。当一个不正确的类名词(例如，“can”表示一个背包)被使用时，我们就会遇到subject和先前的类之间的争论——有时会得到圆柱形的背包，或者其他畸形的subject。如果我们在没有类名词的情况下训练，模型就不会利用类先验，难以学习subject、难以收敛，并且可能产生错误的样本。subject保真度结果如表4所示，我们提出的方法具有更高的subject保真度。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:5:3","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"4.4. Applications Recontextualization 我们可以用描述性提示(“a 【V】【类名词】【上下文描述】”)为不同上下文中的特定主题生成新的图像(图6)。重要的是，我们能够以新的姿势和关节生成主体，具有以前未见过的场景结构和场景中主体的现实集成(例如。接触，阴影，反射) Art Renditions 给我们提示“一幅[V][类名词]的画，具有[著名画家]的风格”或“一尊[V][类名词]的雕像，具有[著名雕塑家]的风格”，我们就能够生成我们主题的艺术再现。与**风格转移不同，在风格转移中，源结构被保留，只有风格被转移，我们能够根据艺术风格产生有意义的，新颖的变化，同时保持主体身份。**例如，如图7所示，“米开朗基罗”，我们生成了一个在输入图像中没有见过的新姿势。 Novel View Synthesis 我们能够在新的视角下渲染主题。在图7中，我们生成输入猫的新图像(具有一致的复杂皮毛图案)在新视角下。我们强调，该模型没有从后面、下面或上面看到这只特定的猫，但它能够从之前的类中推断出知识，从而生成这些新的视图，仅给出4张主体的正面图像。 Property Modification 我们可以修改主题属性。例如，我们在图7的底部一行显示了特定的松狮犬与不同动物物种之间的杂交。我们用以下结构的句子提示模型:“[V]狗和[目标物种]的杂交”。特别是，我们可以在这个例子中看到，即使物种发生了变化，狗的身份也被很好地保存了下来——狗的脸上有一些独特的特征，这些特征被很好地保存下来，并与目标物种融合在一起。其他属性修改是可能的，例如材料修改(例如图6中的“透明[V]茶壶”)。有些比其他的更难，并且依赖于基本生成模型的先验。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:5:4","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"4.5. Limitations ISS国际空间站。 我们在图8中说明了我们的方法的一些失效模型。第一个问题与不能准确地生成提示上下文有关。可能的原因是这些上下文的弱先验，或者由于训练集中共现的概率低，难以同时生成主题和指定概念。第二种是上下文-外观纠缠，即受试者的外观因提示的上下文而改变，如图8所示，背包的颜色发生了变化。第三，我们还观察到，当提示与看到受试者的原始设置相似时，会发生对真实图像的过度拟合。 其他限制是一些subject比其他subject更容易学习(例如狗和猫)。偶尔，对于较少的主题，该模型无法支持尽可能多的主题变化。最后，受试者的保真度也存在可变性，根据模型先验的强度和语义修改的复杂性，一些生成的图像可能包含幻觉的受试者特征。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:5:5","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"5. Conclusions 我们提出了一种方法，用于综合的新版本的主题使用主题的一些图像和文本提示的指导。我们的关键思想是通过将主题绑定到唯一标识符，将给定的主题实例嵌入到文本到图像扩散模型的输出域中。值得注意的是，这种微调过程可以只给3-5个主题图像，使技术特别容易使用。我们演示了在生成的逼真场景中对动物和物体的各种应用，在大多数情况下与真实图像无法区分。 ","date":"2023-07-24","objectID":"/posts/dl/diffusion/dreambooth/:6:0","tags":["draft"],"title":"Dreambooth","uri":"/posts/dl/diffusion/dreambooth/"},{"categories":["draft"],"content":"Day61 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:1:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"1.下面这段代码输出什么？ func main() { var k = 1 var s = []int{1, 2} k, s[k] = 0, 3 fmt.Println(s[0] + s[1]) } 参考答案及解析：4。知识点：多重赋值。 多重赋值分为两个步骤，有先后顺序： 计算等号左边的索引表达式和取址表达式，接着计算等号右边的表达式； 赋值； 所以本例，会先计算 s[k]，等号右边是两个表达式是常量，所以赋值运算等同于 k, s[1] = 0, 3。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:1:1","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"2.下面代码输出什么？ func main() { var k = 9 for k = range []int{} {} fmt.Println(k) for k = 0; k \u003c 3; k++ { } fmt.Println(k) for k = range (*[3]int)(nil) { } fmt.Println(k) } 参考答案及解析：932。 第一个第三个有待研究。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:1:2","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day62 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:2:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"1.下面哪一行代码会编译出错，请说明。 func main() { nil := 123 fmt.Println(nil) var _ map[string]int = nil } 参考答案及解析：第 4 行，当前作用域中，预定义的 nil 被覆盖，此时 nil 是 int 类型值，不能赋值给 map 类型。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:2:1","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"2.下面代码输出什么？ func main() { var x int8 = -128 var y = x/-1 fmt.Println(y) } 参考答案及解析：-128。因为溢出。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:2:2","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day63 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:3:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"1.下面选项正确的是？ A. 类型可以声明的函数体内； B. Go 语言支持 ++i 或者 –i 操作； C. nil 是关键字； D. 匿名函数可以直接赋值给一个变量或者直接执行； 参考答案及解析：AD。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:3:1","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"2.下面的代码输出什么？ func F(n int) func() int { return func() int { n++ return n } } func main() { f := F(5) defer func() { fmt.Println(f()) }() defer fmt.Println(f()) i := f() fmt.Println(i) } 参考答案及解析：768。知识点：匿名函数、defer()。defer() 后面的函数如果带参数，会优先计算参数，并将结果存储在栈中，到真正执行 defer() 的时候取出。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:3:2","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day64 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:4:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"1.下面列举的是 recover() 的几种调用方式，哪些是正确的？ A. func main() { recover() panic(1) } B. func main() { defer recover() panic(1) } C. func main() { defer func() { recover() }() panic(1) } D. func main() { defer func() { defer func() { recover() }() }() panic(1) } 参考答案及解析：C。recover() 必须在 defer() 函数中直接调用才有效。上面其他几种情况调用都是无效的：直接调用 recover()、在 defer() 中直接调用 recover() 和 defer() 调用时多层嵌套。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:4:1","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"2.下面代码输出什么，请说明？ func main() { defer func() { fmt.Print(recover()) }() defer func() { defer fmt.Print(recover()) panic(1) }() defer recover() panic(2) } 参考答案及解析：21。recover() 必须在 defer() 函数中调用才有效，所以第 9 行代码捕获是无效的。在调用 defer() 时，便会计算函数的参数并压入栈中，所以执行第 6 行代码时，此时便会捕获 panic(2)；此后的 panic(1)，会被上一层的 recover() 捕获。所以输出 21。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:4:2","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day65 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:5:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"1.flag 是 bool 型变量，下面 if 表达式符合编码规范的是？ A. if flag == 1 B. if flag C. if flag == false D. if !flag 参考答案及解析：BCD。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:5:1","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"2.下面的代码输出什么，请说明？ func main() { defer func() { fmt.Print(recover()) }() defer func() { defer func() { fmt.Print(recover()) }() panic(1) }() defer recover() panic(2) } 参考答案及解析：12。同Day64。 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:5:2","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day66 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:6:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day67 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:7:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day68 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:8:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day69 ","date":"2023-07-18","objectID":"/posts/go/day61-70/:9:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Day70","date":"2023-07-18","objectID":"/posts/go/day61-70/:10:0","tags":["draft"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day61-70/"},{"categories":["draft"],"content":"Low-level任务：常见的包括 Super-Resolution，denoise， deblur， dehze， low-light enhancement， deartifacts等。简单来说，是把特定降质下的图片还原成好看的图像，现在基本上用end-to-end的模型来学习这类 ill-posed问题的求解过程，客观指标主要是PSNR，SSIM，大家指标都刷的很高。目前面临以下几点问题： 泛化性差，换个数据集，同种任务变现就很差 客观指标与主观感受存在，GAP，指标刷很高，人眼观感不佳，用GAN可缓解 落地的问题，SOTA模型运算量很(上百G Flops)，但实际不可能这么用 主要是为人眼服务，缺乏与High-level之间的联系 High-level任务：分类（classification），检测（detection），分割（segmentation）等。一般公开训练数据都是高品质的图像，当送入降质图像时，性能会有下降，即使网络已经经过大量的数据增强（形状，亮度，色度等变换） 真实应用场景是不可能像训练集那样完美的，采集图像的过程中会面临各种降质问题，需要两者来结合。简单来说，结合的方式分为以下几种 直接在降质图像上fine-tuning 先经过low-level的增强网络，再送入High-level的模型，两者分开训练 将增强网络和高层模型（如分类）联合训练 ———————————————— 原文链接：https://blog.csdn.net/qq_20880415/article/details/117225213 ","date":"2023-07-15","objectID":"/posts/dl/diffusion/low-level/:0:0","tags":["draft"],"title":"Low Level","uri":"/posts/dl/diffusion/low-level/"},{"categories":["draft"],"content":"Denoising Diffusion Models for Plug-and-Play Image Restoration(即插即用图像恢复的去噪扩散模型) ","date":"2023-07-15","objectID":"/posts/dl/diffusion/low-level/:1:0","tags":["draft"],"title":"Low Level","uri":"/posts/dl/diffusion/low-level/"},{"categories":["draft"],"content":"Abstract 即插即用图像恢复(IR)被广泛认为是一种灵活且可解释的方法，它利用任何现成的去噪器作为隐式图像先验来解决各种逆问题。然而，现有的方法大多集中在判别高斯去噪上。 尽管扩散模型在高质量图像合成方面表现出了令人印象深刻的性能，但它们在即插即用图像恢复方法之前作为生成降噪器的潜力仍有待进一步探索。虽然已经有其他一些尝试采用扩散模型进行图像恢复，但它们要么无法获得令人满意的结果，要么通常需要在推理过程中进行不可接受的神经功能评估(nfe)。本文提出了DiffPIR方法，将传统的即插即用方法集成到扩散采样框架中的。与依赖于判别高斯去噪的即插即用图像恢复方法相比，DiffPIR有望继承扩散模型的生成能力。 在三个代表性的图像恢复任务(包括超分辨率、图像去模糊和涂漆)上的实验结果表明，在不超过100个nfe的情况下，DiffPIR在FFHQ和ImageNet数据集上的重建信度和感知质量都达到了最先进的水平。 ","date":"2023-07-15","objectID":"/posts/dl/diffusion/low-level/:1:1","tags":["draft"],"title":"Low Level","uri":"/posts/dl/diffusion/low-level/"},{"categories":["draft"],"content":"Introduction 最近的研究表明，即插即用的图像恢复(IR)方法可以有效地处理各种低层次的视觉任务，如图像去噪[5]、图像超分辨率(SR)[16,17,37]、图像去模糊[12]和图像补画[27]，并取得了优异的效果[6,11,54,57,58]。 借助变量分割算法，如乘法器的交替方向法(ADMM)和半次二分裂（HQS）即插即用图像恢复方法将高斯去噪集成到迭代过程中，从而提高了性能和收敛性。即插即用IR方法的主要思想是将以下优化问题的数据项和先验项分开。 式中，y为给定退化模型y = H(x0) + n下的ground truth x0的测量值，H为已知退化算子，σn为已知高斯噪声n的标准差，λ p(·)为正则化参数λ的先验项。具体地说，数据项确保解决方案遵循退化过程，而前一项则强制解决方案遵循所需的数据分布。 ","date":"2023-07-15","objectID":"/posts/dl/diffusion/low-level/:1:2","tags":["draft"],"title":"Low Level","uri":"/posts/dl/diffusion/low-level/"},{"categories":["draft"],"content":"扩散模型 ","date":"2023-07-15","objectID":"/posts/cvpr2023/01/:1:0","tags":["draft"],"title":"CVPR2023","uri":"/posts/cvpr2023/01/"},{"categories":["draft"],"content":"DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation（用于主题驱动生成的文本到图像扩散模型的微调） ","date":"2023-07-15","objectID":"/posts/cvpr2023/01/:1:1","tags":["draft"],"title":"CVPR2023","uri":"/posts/cvpr2023/01/"},{"categories":["draft"],"content":"GAN ","date":"2023-07-15","objectID":"/posts/cvpr2023/01/:2:0","tags":["draft"],"title":"CVPR2023","uri":"/posts/cvpr2023/01/"},{"categories":["draft"],"content":"Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space Viewpoint（挖掘图像编辑中GAN反演：一种基础的潜在空间观） StyleGAN：将输入图像映射到嵌入空间(W, W+和F)中，同时保持图像保真度和有意义的操作，利用StyleGAN能生成图像和编辑图像。 GAN反演的关键部分是在保证可编辑性的同时，找到避免失真的反演空间。这方向的研究就是保持重建保真度，同时提高图像的可编辑性。 常用的反演空间包括潜在空间W+[1]和特征空间F[29]。W+被证明可以平衡失真和可编辑性[58,74]。许多编辑方法[1,2,5,21,26,55]将真实图像映射到这个潜在空间中。 现有方法：StyleGAN中从潜空间W到扩展潜空间W+再到特征空间F。而最近的研究是在W+和F而不是W。 本文的方法：退回W考虑，在基础潜空间W中获得一个合适的潜码。引入对比学习来对齐W和图像空间，以便发现合适的潜码。然后，利用交叉注意编码器将W中获得的潜在码相应地转换为W+和F。 具体步骤： Step1：提出了一个对比学习范式来对齐W和图像空间。这个范例来源于CLIP[53]，其中我们将文本分支与W交换。具体来说，我们使用预训练的StyleGAN构建由一个图像I及其潜在代码w∈w组成的配对数据。在对比学习过程中，我们训练两个编码器分别获得I和w的两个特征表示。这两个特征在训练过程之后是一致的。在GAN反演过程中，我们固定了这个对比学习模块，并将其视为一个损失函数。这个损失函数被设置为使一个真实图像和它的潜在代码w足够接近。本设计改进了现有研究[32]对W的损失函数设置在图像空间上(即输入图像与其重构图像之间的相似性度量)，而不是统一图像和潜在空间。对图像空间的监督并不能很好地保证输入图像和W中的潜在代码之间的对齐。 把对比学习中的文字换成W，之前也有做研究，但是损失函数是在图像和重建图像之上，本文说对图像空间的监督并不能很好地保证输入图像和W中的潜在代码之间的对齐，所以说本文对齐的是图像和潜在空间W。 在W中发现合适的潜在码后，我们利用交叉注意编码器将W变换为W+∈W+和f∈f。在计算W+时，我们将W设置为查询，将W+设置为值和键。然后，我们计算交叉注意映射来重建w+。这种交叉关注映射使w+的值接近查询w，使w+的可编辑性与w相似，并且w+有效地保留了重构能力。在计算f时，我们将w设置为值和键，同时将f设置为查询。所以w将指导f进行特征细化。最后，我们使用StyleGAN中的w+和f来生成重建结果。 这里用设计交叉注意力来生成w+，注意上面提到的计算出w+和f的时候用的q、k、v，目的是保留重构能力。最后还是使用StyleGAN中的w+和f来生成重建结果。 ","date":"2023-07-15","objectID":"/posts/cvpr2023/01/:2:1","tags":["draft"],"title":"CVPR2023","uri":"/posts/cvpr2023/01/"},{"categories":["draft"],"content":"模型剪枝 ","date":"2023-07-15","objectID":"/posts/cvpr2023/01/:3:0","tags":["draft"],"title":"CVPR2023","uri":"/posts/cvpr2023/01/"},{"categories":["draft"],"content":"VIT的剪枝 Global Vision Transformer Pruning with Hessian-Aware Saliency 具有hessian感知显著性的全局VIT剪枝 前提知识： 而过参数化是指训练阶段我们需要大量的参数来捕捉数据中的微小信息，而一旦训练完成到了推理阶段，我们并不需要这么多的参数。 黑塞矩阵（Hessian Matrix），又译作海森矩阵、海瑟矩阵、海塞矩阵等，是一个多元函数的二阶偏导数构成的方阵，描述了函数的局部曲率。在工程实际问题的优化设计中，所列的目标函数往往很复杂，为了使问题简化，常常将目标函数在某点邻域展开成泰勒多项式来逼近原函数。 解决的问题：VIT的计算成本。大量的计算成本和大量的内存需求，使得它们不适合部署在边缘平台上。 解决办法：对全局结构修剪，在变压器块之间和块内不同结构之间重新分配参数。处理不同的ViT结构组件，我们推导了一种新的基于hessian的结构修剪标准，可用于所有层和结构，并使用延迟感知正则化来直接降低延迟。 我们通过延迟感知的全局结构修剪来分析DeiT模型中不同组件的重要性和冗余度，利用这些见解来重新分配参数，以提高准确性和效率之间的权衡。从分析ViT计算图中的块开始，找出所有可以独立控制的维度。 对ViT进行全局剪枝是非常具有挑战性的。以往的方法只尝试以相同的剪枝比率进行性能剪枝[5]，不能导致参数在组件和块之间重新分布。**我们基于全局结构剪枝损失的Hessian矩阵范数导出了一个新的重要分数，首次提供了所有可剪枝分量之间的可比性。**此外，我们将估计的延迟减少合并到重要性评分中。这将引导最终修剪的架构在目标设备上运行得更快。 全局结构修剪算法由延迟感知、基于hessian的基于重要性的标准实现，并针对ViT架构进行了定制。 迈向高效视觉变压器模型。从ViT开始，特别是DeiT，我们在3.1节中确定了剪枝的设计空间(i)嵌入大小E， (ii)头数H， (iii)查询/键大小QK， (iv)值大小V和(V) MLP隐藏维度M。然后，我们利用延迟感知重要性评分的全局排名，在第3.2节中执行迭代的全局结构修剪，获得修剪的NViT模型。最后，我们分析了NViT模型中各分量的参数再分布趋势，如第5.1节所示。 X-Pruner: eXplainable Pruning for Vision Transformers X-Pruner:可解释的VIT修剪 用一种新的可解释性感知掩码测量重要性，阈值不是手工设置的，也是通过添加一个可微的正则化器。 现有方法：无法解释、忽略了模型内部单位与目标类之间的关系，从而导致性能较差。 解决办法：我们提出了一种新的可解释修剪框架，称为X-Pruner，该框架考虑了修剪标准的可解释性。具体来说，为了测量每个可预测单元对预测每个目标类的贡献，提出了一种新的可解释性感知掩码，并以端到端方式学习。然后，为了保留信息量最大的单元并学习分层修剪率，我们根据 可解释性感知掩码值 自适应搜索区分 未修剪和已修剪单元的分层阈值。 可解释AI (eXplainable AI, XAI)字段[2]中所述，模型中的重要权重通常捕获语义类特定信息。受这一理论的启发，我们建议以类明智的方式有效地量化每个权重的重要性。 首先，我们为每个可预测的单元(例如，线性层中的注意头或矩阵)设计了一个可解释性感知掩膜，它测量单元对预测每个类的贡献，并且是完全可微的（看重不重要）。其次，我们使用每个输入的ground-truth标签作为先验知识来指导掩码学习，从而充分利用每个输入的类级信息。我们的直觉是，如果一个单元生成对目标类有积极贡献的特征表示，它的掩码值将被积极激活，否则将被停用。第三，我们提出了一个带有阈值正则化器的可微剪枝操作。这使得搜索阈值通过梯度为基础的优化，并优于大多数以前的研究（通过手工设置的标准）。同时，所提出的剪枝过程可以自动完成，即保留高于学习阈值的判别单元。通过这种方式，我们以可解释的方式自动有效地实现了分层修剪算法。 我们提出的X-Pruner框架的管道。我们首先用提出的可解释性感知掩模训练一个变压器，目标是量化每个单元对预测每个类别的贡献。然后，我们在预定义的成本约束下探讨了分层剪枝阈值。最后，对修剪后的模型执行一个微调过程。 与之前使用二进制掩模来量化每个单元对所有类的贡献的工作不同，本文使用可微掩模来捕获每个单元的重要性。训练后，每个学习到的掩码的总和明确表示其对识别所有类的贡献。通过这种方式学习的可解释性Mask获得了以端到端方式揭示transformer内部推理过程的表示能力，这基本上以直观可解释的方式提供了对每个单个单元重要性的全局检查。值得注意的是，在训练过程中，预训练模型的权值保持固定。因此，从经验上观察到，只需要几个epoch来训练我们提出的可解释性感知掩模。 以前的工作是通过手动选择每层阈值来衡量单个单元的重要性，由于参数搜索空间是穷举的，这在计算上很棘手。这项工作提出通过设计一个可微修剪操作和一个阈值正则化器来学习分层阈值，这优于大多数先前的研究，可以更好地控制非均匀稀疏性。 ","date":"2023-07-15","objectID":"/posts/cvpr2023/01/:3:1","tags":["draft"],"title":"CVPR2023","uri":"/posts/cvpr2023/01/"},{"categories":["draft"],"content":"模型优化 ","date":"2023-07-15","objectID":"/posts/cvpr2023/01/:4:0","tags":["draft"],"title":"CVPR2023","uri":"/posts/cvpr2023/01/"},{"categories":["draft"],"content":"Run, Don’t Walk: Chasing Higher FLOPS for Faster Neural Networks 为更快的神经网络追求更高的FLOPS 为了设计快速的神经网络，许多工作都集中在减少浮点运算(FLOPs)的数量上。然而，我们观察到FLOPs的这种减少并不一定会导致类似程度的延迟减少。这主要源于低效率的每秒浮点操作数(FLOPS)。 提出了一种新的部分卷积，和FasterNet。 ","date":"2023-07-15","objectID":"/posts/cvpr2023/01/:4:1","tags":["draft"],"title":"CVPR2023","uri":"/posts/cvpr2023/01/"},{"categories":["Go每日一练"],"content":"Day51 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:1:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.下面的代码能否正确输出？ func main() { var fn1 = func() {} var fn2 = func() {} if fn1 != fn2 { println(\"fn1 not equal fn2\") } } 参考答案及解析：编译错误 invalid operation: fn1 != fn2 (func can only be compared to nil) **函数只能与 nil 比较。**func是不可比较类型，不能用来比较是否相等。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:1:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ type T struct { n int } func main() { m := make(map[int]T) m[0].n = 1 fmt.Println(m[0].n) } A. 1 B. compilation error 参考答案及解析：B。编译错误： cannot assign to struct field m[0].n in map map[key]struct 中 struct 是不可寻址的，所以无法直接赋值。 修复代码： type T struct { n int } func main() { m := make(map[int]T) t := T{1} m[0] = t fmt.Println(m[0].n) } ","date":"2023-07-12","objectID":"/posts/go/day51-60/:1:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day52 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:2:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.下面的代码有什么问题？ type X struct {} func (x *X) test() { println(x) } func main() { var a *X a.test() X{}.test() } 参考答案及解析：X{} 是不可寻址的，不能直接调用方法。知识点：在方法中，指针类型的接收者必须是合法指针（包括 nil）,或能获取实例地址。 修复代码： func main() { var a *X a.test() // 相当于 test(nil) var x = X{} x.test() } ","date":"2023-07-12","objectID":"/posts/go/day51-60/:2:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面代码有什么不规范的地方吗？ func main() { x := map[string]string{\"one\":\"a\",\"two\":\"\",\"three\":\"c\"} if v := x[\"two\"]; v == \"\" { fmt.Println(\"no entry\") } } 参考答案及解析：检查 map 是否含有某一元素，直接判断元素的值并不是一种合适的方式。**最可靠的操作是使用访问 map 时返回的第二个值。**用ok去判断 修复代码如下： func main() { x := map[string]string{\"one\":\"a\",\"two\":\"\",\"three\":\"c\"} if _,ok := x[\"two\"]; !ok { fmt.Println(\"no entry\") } } ","date":"2023-07-12","objectID":"/posts/go/day51-60/:2:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day53 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:3:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.关于 channel 下面描述正确的是？ A. 向已关闭的通道发送数据会引发 panic； B. 从已关闭的缓冲通道接收数据，返回已缓冲数据或者零值； C. 无论接收还是接收，nil 通道都会阻塞； 参考答案及解析：ABC。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:3:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面的代码有几处问题？请详细说明。 type T struct { n int } func (t *T) Set(n int) { t.n = n } func getT() T { return T{} } func main() { getT().Set(1) } 参考答案及解析：有两处问题： 1.直接返回的 T{} 不可寻址； 2.不可寻址的结构体不能调用带结构体指针接收者的方法； 修复代码： type T struct { n int } func (t *T) Set(n int) { t.n = n } func getT() T { return T{} } func main() { t := getT() t.Set(2) fmt.Println(t.n) } ","date":"2023-07-12","objectID":"/posts/go/day51-60/:3:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day54 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:4:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.下面的代码有什么问题？ type N int func (n N) value(){ n++ fmt.Printf(\"v:%p,%v\\n\",\u0026n,n) } func (n *N) pointer(){ *n++ fmt.Printf(\"v:%p,%v\\n\",n,*n) } func main() { var a N = 25 p := \u0026a p1 := \u0026p p1.value() p1.pointer() } 参考答案及解析：编译错误： calling method value with receiver p1 (type **N) requires explicit dereference calling method pointer with receiver p1 (type **N) requires explicit dereference 不能使用多级指针调用方法。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:4:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面的代码输出什么？ type N int func (n N) test(){ fmt.Println(n) } func main() { var n N = 10 fmt.Println(n) n++ f1 := N.test f1(n) n++ f2 := (*N).test f2(\u0026n) } 参考答案及解析：10 11 12。知识点：方法表达式。通过类型引用的方法表达式会被还原成普通函数样式，接收者是第一个参数，调用时显示传参。类型可以是 T 或 *T，只要目标方法存在于该类型的方法集中就可以。 还可以直接使用方法表达式调用： func main() { var n N = 10 fmt.Println(n) n++ N.test(n) n++ (*N).test(\u0026n) } ","date":"2023-07-12","objectID":"/posts/go/day51-60/:4:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day55 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:5:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.关于 channel 下面描述正确的是？ A. close() 可以用于只接收通道； B. 单向通道可以转换为双向通道； C. 不能在单向通道上做逆向操作（例如：只发送通道用于接收）； 参考答案及解析：C。 单向通道不能转换为双向通道，双向通道可以转为单向通道。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:5:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面的代码有什么问题？ type T struct { n int } func getT() T { return T{} } func main() { getT().n = 1 } 参考答案及解析：编译错误： cannot assign to getT().n 直接返回的 T{} 无法寻址，不可直接赋值。 修复代码： type T struct { n int } func getT() T { return T{} } func main() { t := getT() p := \u0026t.n // \u003c=\u003e p = \u0026(t.n) *p = 1 fmt.Println(t.n) } ","date":"2023-07-12","objectID":"/posts/go/day51-60/:5:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day56 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:6:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.下面的代码有什么问题？ package main import \"fmt\" func main() { s := make([]int, 3, 9) fmt.Println(len(s)) s2 := s[4:8] fmt.Println(len(s2)) } 参考答案及解析：代码没问题，输出 3 4。从一个基础切片派生出的子切片的长度可能大于基础切片的长度。假设基础切片是 baseSlice，使用操作符 [low,high]，有如下规则：0 \u003c= low \u003c= high \u003c= cap(baseSlice)，只要上述满足这个关系，下标 low 和 high 都可以大于 len(baseSlice)。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:6:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ type N int func (n N) test(){ fmt.Println(n) } func main() { var n N = 10 p := \u0026n n++ f1 := n.test n++ f2 := p.test n++ fmt.Println(n) f1() f2() } 参考答案及解析：13 11 12。知识点：方法值。当指针值赋值给变量或者作为函数参数传递时，会立即计算并复制该方法执行所需的接收者对象，与其绑定，以便在稍后执行时，能隐式第传入接收者参数。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:6:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day57 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:7:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.下面哪一行代码会 panic，请说明原因？ package main func main() { var x interface{} var y interface{} = []int{3, 5} _ = x == x _ = x == y _ = y == y } 参考答案及解析：第 8 行。因为两个比较值的动态类型为同一个不可比较类型。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:7:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面的代码输出什么？ var o = fmt.Print func main() { c := make(chan int, 1) for range [3]struct{}{} { select { default: o(1) case \u003c-c: o(2) c = nil case c \u003c- 1: o(3) } } } 参考答案及解析：321。第一次循环，写操作已经准备好，执行 o(3)，输出 3；第二次，读操作准备好，执行 o(2)，输出 2 并将 c 赋值为 nil；第三次，由于 c 为 nil，走的是 default 分支，输出 1。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:7:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day58 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:8:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.下面的代码输出什么？ type T struct { x int y *int } func main() { i := 20 t := T{10,\u0026i} p := \u0026t.x *p++ *p-- t.y = p fmt.Println(*t.y) } 参考答案及解析：10。知识点：运算符优先级。如下规则：递增运算符 ++ 和递减运算符 – 的优先级低于解引用运算符 * 和取址运算符 \u0026，解引用运算符和取址运算符的优先级低于选择器 . 中的属性选择操作符。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:8:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面哪一行代码会 panic，请说明原因？ package main func main() { x := make([]int, 2, 10) _ = x[6:10] _ = x[6:] _ = x[2:] } 参考答案：第 6 行，截取符号 [i:j]，如果 j 省略，默认是原切片或者数组的长度，x 的长度是 2，小于起始下标 6 ，所以 panic。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:8:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day59 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:9:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.下面的代码输出什么？ type N int func (n *N) test(){ fmt.Println(*n) } func main() { var n N = 10 p := \u0026n n++ f1 := n.test n++ f2 := p.test n++ fmt.Println(n) f1() f2() } 参考答案及解析：13 13 13。知识点：方法值。**当目标方法的接收者是指针类型时，那么被复制的就是指针。**注意和day56 题2的区别。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:9:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面哪一行代码会 panic，请说明原因？ package main func main() { var m map[int]bool // nil _ = m[123] var p *[5]string // nil for range p { _ = len(p) } var s []int // nil _ = s[:] s, s[0] = []int{1, 2}, 9 } 参考答案及解析：第 12 行。因为左侧的 s[0] 中的 s 为 nil。 不是很懂哦。 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:9:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"Day60 ","date":"2023-07-12","objectID":"/posts/go/day51-60/:10:0","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"1.下面哪一行代码会 panic，请说明原因？ package main type T struct{} func (*T) foo() { } func (T) bar() { } type S struct { *T } func main() { s := S{} _ = s.foo s.foo() _ = s.bar } 参考答案及解析：第 19 行，因为 s.bar 将被展开为 (*s.T).bar，而 s.T 是个空指针，解引用会 panic。 不懂啊 那为什么第17行不会报错呢。 可以使用下面代码输出 s： func main() { s := S{} fmt.Printf(\"%#v\",s) // 输出：main.S{T:(*main.T)(nil)} } ","date":"2023-07-12","objectID":"/posts/go/day51-60/:10:1","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["Go每日一练"],"content":"2.下面的代码有什么问题？ type data struct { sync.Mutex } func (d data) test(s string) { d.Lock() defer d.Unlock() for i:=0;i\u003c5 ;i++ { fmt.Println(s,i) time.Sleep(time.Second) } } func main() { var wg sync.WaitGroup wg.Add(2) var d data go func() { defer wg.Done() d.test(\"read\") }() go func() { defer wg.Done() d.test(\"write\") }() wg.Wait() } 参考答案及解析：锁失效。将 Mutex 作为匿名字段时，相关的方法必须使用指针接收者，否则会导致锁机制失效。 修复代码： func (d *data) test(s string) { // 指针接收者 d.Lock() defer d.Unlock() for i:=0;i\u003c5 ;i++ { fmt.Println(s,i) time.Sleep(time.Second) } } 或者可以通过嵌入 *Mutex 来避免复制的问题，但需要初始化。 type data struct { *sync.Mutex // *Mutex } func (d data) test(s string) { // 值方法 d.Lock() defer d.Unlock() for i := 0; i \u003c 5; i++ { fmt.Println(s, i) time.Sleep(time.Second) } } func main() { var wg sync.WaitGroup wg.Add(2) d := data{new(sync.Mutex)} // 初始化 go func() { defer wg.Done() d.test(\"read\") }() go func() { defer wg.Done() d.test(\"write\") }() wg.Wait() } ","date":"2023-07-12","objectID":"/posts/go/day51-60/:10:2","tags":["go","面试"],"title":"Go Exercises(Day51-60)","uri":"/posts/go/day51-60/"},{"categories":["draft"],"content":"\rmethod mission 模型大小 数据集大小 模型结构特点 code paper Fullfinetune 全部微调 和原模型一样，十几G 较大 直接微调原模型 https://github.com/compvis/stable-diffusion https://arxiv.org/pdf/2112.10752v2.pdf ControlNet 添加额外的控制条件 约1G 较大 冻结原模型，添加一个新的网络 https://github.com/lllyasviel/controlnet https://arxiv.org/pdf/2302.05543v1.pdf T2I Adaptor 添加额外的控制条件 几百M 较大 冻结原模型，添加一个新的网络 https://github.com/tencentarc/t2i-adapter https://arxiv.org/pdf/2302.08453v2.pdf DreamBooth 保真的同时，加强可编辑性 十几G 几张或几十张图片 利用稀有的token，让模型将这个token与图像进行绑定，subject-driven的生成 https://github.com/XavierXiao/Dreambooth-Stable-Diffusion https://arxiv.org/pdf/2208.12242v2.pdf Textual Inversion 保真的同时，加强可编辑性 几十K 几张或几十张图片 从少量示例图像中捕获新概念的技术。使用少量的图片训练出一个反转文本 https://arxiv.org/pdf/2208.01618.pdf https://github.com/rinongal/textual_inversion Hypernetwork 几十M Lora 适用于所有特定的微调，主要是用来减少参数量的 几十M 几张或几十张图片 在transformer的attention上SVD https://arxiv.org/pdf/2106.09685v2.pdf https://github.com/Akegarasu/lora-scripts AdaLora 适用于所有特定的微调，主要是用来减少参数量的 几十M 几张或几十张图片 SVD的秩不是人为设定的，而是学出来的，自适应的 https://arxiv.org/pdf/2303.10512.pdf https://github.com/KohakuBlueleaf/LyCORIS LoCon 适用于所有特定的微调，主要是用来减少参数量的 几十M 几张或几十张图片 在卷积层上进行SVD https://github.com/KohakuBlueleaf/LyCORIS diffusion的人脸生成 从LLM上找灵感 从GAN上 ","date":"2023-07-03","objectID":"/posts/dl/diffusion/finetune/:0:0","tags":["draft"],"title":"DiffusionFinetune","uri":"/posts/dl/diffusion/finetune/"},{"categories":["draft"],"content":"加了好多太服务器做web，也并不管用，因为瓶颈又来到了数据库。可扩展性。 性能和容错。大型分布式系统的一个大问题是我们把一个罕见的错误转变成了一个在一千台机器的分布式系统中。一台电脑365天出一次问题，等效于1000台电脑每天会有3台出问题。 ","date":"2023-07-02","objectID":"/posts/6824/01/:0:0","tags":["draft"],"title":"Lecture01","uri":"/posts/6824/01/"},{"categories":["draft"],"content":"RPC ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:0:0","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"什么是RPC RPC（Remote Procedure Call），即远程过程调用。它允许像调用本地服务一样调用远程服务。RPC是一种服务器-客户端（Client/Server）模式，经典实现是一个通过发送请求-接受回应进行信息交互的系统。首先与RPC（远程过程调用）相对应的是本地调用。 ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:1:0","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"本地调用 package main import \"fmt\" func add(x, y int)int{ return x + y } func main(){ // 调用本地函数add a := 10 b := 20 ret := add(x, y) fmt.Println(ret) } 将上述程序编译成二进制文件——app1后运行，会输出结果30。 在app1程序中本地调用add函数的执行流程，可以理解为以下四个步骤。 将变量 a 和 b 的值分别压入堆栈上 执行 add 函数，从堆栈中获取 a 和 b 的值，并将它们分配给 x 和 y 计算 x + y 的值并将其保存到堆栈中 退出 add 函数并将 x + y 的值赋给 ret ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:1:1","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"RPC调用 本地过程调用发生在同一进程中——定义add函数的代码和调用add函数的代码共享同一个内存空间，所以调用能够正常执行。 但是我们无法直接在另一个程序——app2中调用add函数，因为它们是两个程序——内存空间是相互隔离的。（app1和app2可能部署在同一台服务器上也可能部署在互联网的不同服务器上。） RPC就是为了解决类似远程、跨内存空间、的函数/方法调用的。要实现RPC就需要解决以下三个问题。 如何确定要执行的函数？ 在本地调用中，函数主体通过函数指针函数指定，然后调用 add 函数，编译器通过函数指针函数自动确定 add 函数在内存中的位置。但是在 RPC 中，调用不能通过函数指针完成，因为它们的内存地址可能完全不同。因此，调用方和被调用方都需要维护一个{ function \u003c-\u003e ID }映射表，以确保调用正确的函数。 如何表达参数？ 本地过程调用中传递的参数是通过堆栈内存结构实现的，但 RPC 不能直接使用内存传递参数，因此参数或返回值需要在传输期间序列化并转换成字节流，反之亦然。 如何进行网络传输？ 函数的调用方和被调用方通常是通过网络连接的，也就是说，function ID 和序列化字节流需要通过网络传输，因此，只要能够完成传输，调用方和被调用方就不受某个网络协议的限制。.例如，一些 RPC 框架使用 TCP 协议，一些使用 HTTP。 以往实现跨服务调用的时候，我们会采用RESTful API的方式，被调用方会对外提供一个HTTP接口，调用方按要求发起HTTP请求并接收API接口返回的响应数据。下面的示例是将add函数包装成一个RESTful API。 ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:1:2","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"HTTp调用RESTful API 首先，我们编写一个基于HTTP的server服务，它将接收其他程序发来的HTTP请求，执行特定的程序并将结果返回。 // server/main.go package main import ( \"encoding/json\" \"io/ioutil\" \"log\" \"net/http\" ) type addParam struct { X int `json:\"x\"` Y int `json:\"y\"` } type addResult struct { Code int `json:\"code\"` Data int `json:\"data\"` } func add(x, y int) int { return x + y } func addHandler(w http.ResponseWriter, r *http.Request) { // 解析参数 b, _ := ioutil.ReadAll(r.Body) var param addParam json.Unmarshal(b, \u0026param) // 业务逻辑 ret := add(param.X, param.Y) // 返回响应 respBytes , _ := json.Marshal(addResult{Code: 0, Data: ret}) w.Write(respBytes) } func main() { http.HandleFunc(\"/add\", addHandler) log.Fatal(http.ListenAndServe(\":9090\", nil)) } 我们编写一个客户端来请求上述HTTP服务，传递x和y两个整数，等待返回结果。 // client/main.go package main import ( \"bytes\" \"encoding/json\" \"fmt\" \"io/ioutil\" \"net/http\" ) type addParam struct { X int `json:\"x\"` Y int `json:\"y\"` } type addResult struct { Code int `json:\"code\"` Data int `json:\"data\"` } func main() { // 通过HTTP请求调用其他服务器上的add服务 url := \"http://127.0.0.1:9090/add\" param := addParam{ X: 10, Y: 20, } paramBytes, _ := json.Marshal(param) resp, _ := http.Post(url, \"application/json\", bytes.NewReader(paramBytes)) defer resp.Body.Close() respBytes, _ := ioutil.ReadAll(resp.Body) var respData addResult json.Unmarshal(respBytes, \u0026respData) fmt.Println(respData.Data) // 30 } 这种模式是我们目前比较常见的跨服务或跨语言之间基于RESTful API的服务调用模式。 既然使用API调用也能实现类似远程调用的目的，为什么还要用RPC呢？ 使用 RPC 的目的是让我们调用远程方法像调用本地方法一样无差别。并且基于RESTful API通常是基于HTTP协议，传输数据采用JSON等文本协议，相较于RPC 直接使用TCP协议，传输数据多采用二进制协议来说，RPC通常相比RESTful API性能会更好。 RESTful API多用于前后端之间的数据传输，而目前微服务架构下各个微服务之间多采用RPC调用。 ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:1:3","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"go语言标准库实现rpc ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:2:0","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"基础RPC示例 Go语言的 rpc 包提供对通过网络或其他 i/o 连接导出的对象方法的访问，服务器注册一个对象，并把它作为服务对外可见（服务名称就是类型名称）。注册后，对象的导出方法将支持远程访问。服务器可以注册不同类型的多个对象(服务) ，但是不支持注册同一类型的多个对象。 在下面的代码中我们定义一个ServiceA类型，并为其定义了一个可导出的Add方法。 // rpc demo/service.go package main type Args struct { X, Y int } // ServiceA 自定义一个结构体类型 type ServiceA struct{} // Add 为ServiceA类型增加一个可导出的Add方法 func (s *ServiceA) Add(args *Args, reply *int) error { *reply = args.X + args.Y return nil } 通过下面的代码将上面定义的ServiceA类型注册为一个服务，其Add方法就支持RPC调用了。 // rpc demo/server.go package main import ( \"log\" \"net\" \"net/http\" \"net/rpc\" ) func main() { service := new(ServiceA) rpc.Register(service) // 注册RPC服务 rpc.HandleHTTP() // 基于HTTP协议 l, e := net.Listen(\"tcp\", \":9091\") if e != nil { log.Fatal(\"listen error:\", e) } http.Serve(l, nil) } 此时，client 端便能看到一个拥有“Add”方法的“ServiceA”服务，想要调用这个服务需要使用下面的代码先连接到server端再执行远程调用。 // rpc demo/client.go package main import ( \"fmt\" \"log\" \"net/rpc\" ) type Args struct { X, Y int } func main() { // 建立HTTP连接 client, err := rpc.DialHTTP(\"tcp\", \"127.0.0.1:9091\") if err != nil { log.Fatal(\"dialing:\", err) } // 同步调用 args := \u0026Args{10, 20} var reply int err = client.Call(\"ServiceA.Add\", args, \u0026reply) if err != nil { log.Fatal(\"ServiceA.Add error:\", err) } fmt.Printf(\"ServiceA.Add: %d+%d=%d\\n\", args.X, args.Y, reply) // 异步调用 var reply2 int divCall := client.Go(\"ServiceA.Add\", args, \u0026reply2, nil) replyCall := \u003c-divCall.Done // 接收调用结果 fmt.Println(replyCall.Error) fmt.Println(reply2) } 执行上述程序，查看 RPC 调用的结果。 先启动 server 端。 go run server.go service.go 再启动 client 端。 go run client.go service.go 会看到如下输出结果。 ServiceA.Add: 10+20=30 \u003cnil\u003e 30 这个RPC调用过程可以简化如下图所示。 ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:2:1","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"基于TCP协议的RPC 当然 rpc 包也支持直接使用 TCP 协议而不使用HTTP协议。 server 端代码修改如下。 // rpc_demo/server2.go package main import ( \"log\" \"net\" \"net/rpc\" ) func main() { service := new(ServiceA) rpc.Register(service) // 注册RPC服务 l, e := net.Listen(\"tcp\", \":9091\") if e != nil { log.Fatal(\"listen error:\", e) } for { conn, _ := l.Accept() rpc.ServeConn(conn) } } client 端代码修改如下。 // rpc demo/client2.go package main import ( \"fmt\" \"log\" \"net/rpc\" ) func main() { // 建立TCP连接 client, err := rpc.Dial(\"tcp\", \"127.0.0.1:9091\") if err != nil { log.Fatal(\"dialing:\", err) } // 同步调用 args := \u0026Args{10, 20} var reply int err = client.Call(\"ServiceA.Add\", args, \u0026reply) if err != nil { log.Fatal(\"ServiceA.Add error:\", err) } fmt.Printf(\"ServiceA.Add: %d+%d=%d\\n\", args.X, args.Y, reply) // 异步调用 var reply2 int divCall := client.Go(\"ServiceA.Add\", args, \u0026reply2, nil) replyCall := \u003c-divCall.Done // 接收调用结果 fmt.Println(replyCall.Error) fmt.Println(reply2) } ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:2:2","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"使用JSON协议的RPC rpc 包默认使用的是 gob 协议对传输数据进行序列化/反序列化，比较有局限性。下面的代码将尝试使用 JSON 协议对传输数据进行序列化与反序列化。 server 端代码修改如下。 // rpc demo/server3.go package main import ( \"log\" \"net\" \"net/rpc\" \"net/rpc/jsonrpc\" ) func main() { service := new(ServiceA) rpc.Register(service) // 注册RPC服务 l, e := net.Listen(\"tcp\", \":9091\") if e != nil { log.Fatal(\"listen error:\", e) } for { conn, _ := l.Accept() // 使用JSON协议 rpc.ServeCodec(jsonrpc.NewServerCodec(conn)) } } client 端代码修改如下。 // rpc demo/client3.go package main import ( \"fmt\" \"log\" \"net\" \"net/rpc\" \"net/rpc/jsonrpc\" ) func main() { // 建立TCP连接 conn, err := net.Dial(\"tcp\", \"127.0.0.1:9091\") if err != nil { log.Fatal(\"dialing:\", err) } // 使用JSON协议 client := rpc.NewClientWithCodec(jsonrpc.NewClientCodec(conn)) // 同步调用 args := \u0026Args{10, 20} var reply int err = client.Call(\"ServiceA.Add\", args, \u0026reply) if err != nil { log.Fatal(\"ServiceA.Add error:\", err) } fmt.Printf(\"ServiceA.Add: %d+%d=%d\\n\", args.X, args.Y, reply) // 异步调用 var reply2 int divCall := client.Go(\"ServiceA.Add\", args, \u0026reply2, nil) replyCall := \u003c-divCall.Done // 接收调用结果 fmt.Println(replyCall.Error) fmt.Println(reply2) } ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:2:3","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"Python调用RPC 下面的代码演示了如何使用 python client 远程调用上面 Go server中 serviceA的Add方法。 import socket import json request = { \"id\": 0, \"params\": [{\"x\":10, \"y\":20}], # 参数要对应上Args结构体 \"method\": \"ServiceA.Add\" } client = socket.create_connection((\"127.0.0.1\", 9091),5) client.sendall(json.dumps(request).encode()) rsp = client.recv(1024) rsp = json.loads(rsp.decode()) print(rsp) ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:2:4","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"RPC原理 RPC 让远程调用就像本地调用一样，其调用过程可拆解为以下步骤。 ① 服务调用方（client）以本地调用方式调用服务； ② client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体； ③ client stub找到服务地址，并将消息发送到服务端； ④ server 端接收到消息； ⑤ server stub收到消息后进行解码； ⑥ server stub根据解码结果调用本地的服务； ⑦ 本地服务执行并将结果返回给server stub； ⑧ server stub将返回结果打包成能够进行网络传输的消息体； ⑨ 按地址将消息发送至调用方； ⑩ client 端接收到消息； ⑪ client stub收到消息并进行解码； ⑫ 调用方得到最终结果。 使用RPC框架的目标是只需要关心第1步和最后1步，中间的其他步骤统统封装起来，让使用者无需关心。例如社区中各式RPC框架（grpc、thrift等）就是为了让RPC调用更方便。 ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:3:0","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"gRPC是什么 gRPC是一种现代化开源的高性能RPC框架，能够运行于任意环境之中。最初由谷歌进行开发。它使用HTTP/2作为传输协议。 在gRPC里，客户端可以像调用本地方法一样直接调用其他机器上的服务端应用程序的方法，帮助你更容易创建分布式应用程序和服务。与许多RPC系统一样，gRPC是基于定义一个服务，指定一个可以远程调用的带有参数和返回类型的的方法。在服务端程序中实现这个接口并且运行gRPC服务处理客户端调用。在客户端，有一个stub提供和服务端相同的方法。 ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:4:0","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"为什么用gRPC 使用gRPC， 我们可以一次性的在一个.proto文件中定义服务并使用任何支持它的语言去实现客户端和服务端，反过来，它们可以应用在各种场景中，从Google的服务器到你自己的平板电脑—— gRPC帮你解决了不同语言及环境间通信的复杂性。使用protocol buffers还能获得其他好处，包括高效的序列化，简单的IDL以及容易进行接口更新。总之一句话，使用gRPC能让我们更容易编写跨语言的分布式代码。 IDL（Interface description language）是指接口描述语言，是用来描述软件组件接口的一种计算机语言，是跨平台开发的基础。IDL通过一种中立的方式来描述接口，使得在不同平台上运行的对象和用不同语言编写的程序可以相互通信交流；比如，一个组件用C++写成，另一个组件用Go写成。 ","date":"2023-07-02","objectID":"/posts/rpc_protobuf/day01/:5:0","tags":["draft"],"title":"Day01","uri":"/posts/rpc_protobuf/day01/"},{"categories":["draft"],"content":"Abstract 大模型的预训练，重新训练所有模型参数的完全微调不太可行。Low-Rank Adaptation，即LoRA，它冻结了预先训练好的模型权重，并将可训练的秩解矩阵注入到Transformer架构的每一层，大大减少了下游任务的可训练参数的数量。与用Adam微调的GPT-3 175B相比，LoRA可以将可训练参数的数量减少10,000倍 ，对GPU内存的要求减少3倍 。推理的时间也和原模型保持一致，不会让推理时间边长。我们还对语言模型适配中的rank-deficiency进行了实证调查，这说明了LoRA的功效。 ","date":"2023-06-29","objectID":"/posts/dl/diffusion/lora/:1:0","tags":["draft"],"title":"Lora","uri":"/posts/dl/diffusion/lora/"},{"categories":["draft"],"content":"Introduce 自然语言处理中的许多应用都依赖于将一个大规模的、预先训练好的语言模型适应于多个下游应用。这种适应通常是通过微调完成的，微调会更新预训练模型的所有参数。微调的主要缺点是，新模型包含的参数与原模型一样多。随着更大的模型每隔几个月就被训练一次，这对GPT-2（Radford等人，b）或 RoBERTa large（Liu等人，2019）来说仅仅是一个 “不便”，而对于有着175B参数的GPT-3（Brown等人，2020）来说则是一个关键的挑战。 许多人试图通过只调整一些参数或为新任务学习外部模块来缓解这一问题。这样，我们只需要在每个任务的预训练模型的基础上，存储和加载少量特定任务的参数，大大提升了部署时的运行效率。然而，现有的技术往往通过扩展模型深度或减少模型的可用序列长度（Li \u0026 Liang，2021；Lester等，2021； Ham-bardzumyan等，2020；Liu等，2021）引入推理延迟（Houlsby等，2019；Rebuffi等， 2017）（第3节）。更重要的是，这些方法往往不能与微调基线相匹配，造成了效率和模型质量之间的权衡，很难兼顾。现有的一些微调方法具有局限性，比如推理时间会边长。这些方法的效果也不如全部进行微调好。 我们从Li等人（2018a）；Aghajanyan等人（2020）那里得到启发，他们表明学到的过度参数化模型实际上位于一个低的内在维度上。我们假设模型适应过程中权重的变化也具有较低的\"内在秩\"，从而导致我们提出的低秩适应（LoRA）方法。LoRA允许我们通过优化密集层在适应过程中的变化的秩分解矩阵来间接地训练神经网络中的一些密集层，而保持预训练的权重冻结，如图1所示。以GPT-3 175B为例，我们表明，即使全秩（即d） 高达12288，一个非常低的秩（即图1中的r可以是1或2）也足够了，这使得LoRA既有存储又有计算效率。 模型学到的知识，不需要那么高的维度去表达，可能很少一部分参数就够了，从矩阵的角度去讲，就是一个低秩的矩阵就能表达出特征，学到这个信息了。 在代码中，AB矩阵是可以先乘起来一步完成的，代码的实现是两个全连接层 LoRA拥有几个关键优势。 一个预先训练好的模型可以被共享，并用于为不同的任务建立许多小的LoRA模块 。我们可以冻结共享模型，并通过替换图1中的矩阵A和B来有效地切换任务，从而大大降低存储需求和任务切换的难度。可以很轻松的切换下游任务，不同的下游任务只需要改变右边矩阵参数，因为左边是冻住的。 LoRA使训练更加有效，在使用自适应优化器时，硬件门槛降低了3倍，因为我们不需要计算梯度或维护大多数参数的优化器状态。相反，我们只优化注入的、小得多的低秩矩阵。 我们简单的线性设计允许我们在部署时将可训练矩阵与冻结权重合并，与完全微调的模型相比，在结构上没有引入推理延迟。 LoRA与许多先前的方法是正交的，并且可以与许多方法相结合，例如前缀调整。 我们在附录E中提供了一个例子。 ","date":"2023-06-29","objectID":"/posts/dl/diffusion/lora/:2:0","tags":["draft"],"title":"Lora","uri":"/posts/dl/diffusion/lora/"},{"categories":["draft"],"content":"problem statement ","date":"2023-06-29","objectID":"/posts/dl/diffusion/lora/:3:0","tags":["draft"],"title":"Lora","uri":"/posts/dl/diffusion/lora/"},{"categories":["draft"],"content":"现有工作 adding adapter layer 会造成inference latency optimize input activation 很难。会reduce sequence length ","date":"2023-06-29","objectID":"/posts/dl/diffusion/lora/:4:0","tags":["draft"],"title":"Lora","uri":"/posts/dl/diffusion/lora/"},{"categories":["draft"],"content":"method ","date":"2023-06-29","objectID":"/posts/dl/diffusion/lora/:5:0","tags":["draft"],"title":"Lora","uri":"/posts/dl/diffusion/lora/"},{"categories":["draft"],"content":"低秩参数化的更新矩阵 矩阵的低秩分解 A的初始化是随机的高斯，B是零。好处和controlNet一样，在网络刚开始训练之前，让输出和源网络保持一致。 完全微调的一般化：就是说比如我的r很大，那么就是完全微调了。 没有额外的推理延迟：计算的时候W0先加上BA，最后再乘x。那么和原来的W0乘x没有区别。 其他层也做了试验，用于transform层最有效。 大语言模型的一种低秩的调节方法，做微调是为了适应下游任务 为了适配不同的下游任务，训练模型。lora是一个fine-tune的分支，只是他的这个规模要小很多。即使说是有prompt去提示，模型还是需要去训练，要不还是学不到内容。 实现细节 adaptor 是小的 pretrained model是大的 冻结预训练模型权重 在transform中self-attention的每个layer上注入可学习的低秩的矩阵 基本思想： transformer中self attention 的Wq、Wk、Wv、Wo（是多头里面的）是可学习的矩阵，将他们记为Φ 如果全部参数都进行微调的话，每次Φ+ΔΦ，每一个下游任务都需要学习ΔΦ，规模是|Φ| 而LORA 将ΔΦ编码，为ΔΦ=ΔΦ(Θ)，参数Θ规模更小，编码的方式是低秩的表示。 ΔW=BA W0冻结住不接受梯度的更新，AB是可学习的矩阵。 经典的finetune过程 LORA，左侧灰色的W是冻结住的。 d^2 —-\u003e 2dr r是一个超参，需要平衡模型的复杂能力，适应下游任务的能力和过拟合、欠拟合。显然，如果r更小，学习的参数量就越小，训练更快，减少计算硬件的要求，但是他捕捉下游任务相关的信息的能力也随之变小。 对A使用随机高斯初始化(uniform)，对B使用零初始化 ","date":"2023-06-29","objectID":"/posts/dl/diffusion/lora/:5:1","tags":["draft"],"title":"Lora","uri":"/posts/dl/diffusion/lora/"},{"categories":["draft"],"content":"数学角度： 3个问题探究LORA的本质 固定参数量大小，如何把我的参数分配到我需要微调的模块上去 ？ rank选多少合适？ ΔW和W的关系? 固定参数量大小，如何把我的参数分配到我需要微调的模块上去 ？给不同的矩阵加LORA，设的r值不一样，这样保证总参数量是一致的。 r选多少 相似矩阵 对矩阵进行奇异值分解(SVD) ΔW和W的关系? ","date":"2023-06-29","objectID":"/posts/dl/diffusion/lora/:6:0","tags":["draft"],"title":"Lora","uri":"/posts/dl/diffusion/lora/"},{"categories":["draft"],"content":"SVD","date":"2023-06-29","objectID":"/posts/dl/diffusion/lora/:7:0","tags":["draft"],"title":"Lora","uri":"/posts/dl/diffusion/lora/"},{"categories":["draft"],"content":"Abstract ControlNet控制预训练好的扩散模型，让他们能支持额外的输入控制条件。ControlNet能端到端地学习task-specific conditions，鲁棒性非常好，数据集小的情况下，比如50k以内，也可以。ControlNet的训练和微调一个diffusion模型一样快，并且允许在个人设备上进行训练。像SD这种模型，就可以使用ControlNet让他有更多的控制条件去控制图像的生成，比如edge map，segementation maps，keypoints等等。 ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:1:0","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Introduction 几个问题： 这种基于prompt的控制满足了我们的需求吗？例如，在图像处理中，考虑到许多具有清晰问题表述的长期任务，这些大型模型能否应用于促进这些特定任务。 我们应该创建什么样的framework去广泛的问题条件和用户控制？ 在特定的任务中，大模型能否保留从数十亿张图像中获得的优势和能力？ 针对这几个问题，调查了很多图像生成的应用，有了如下发现： 在特定任务领域可用的数据规模并不总是像图像文本领域那样大。许多特定问题（例如对象形状/法线、姿态理解等）的最大数据集大小通常不到100k，即比LAION5B小5×104倍。这将需要稳健的神经网络训练方法，以避免过拟合，并在大型模型针对特定问题进行训练时保留泛化能力。 在处理图像处理任务时，不总是有大型计算集群可用的数据驱动解决方案。这使得快速训练方法对于在可接受的时间和内存空间内针对特定任务优化大型模型非常重要（例如，在个人设备上）。这将进一步要求利用预训练权重，以及微调策略或迁移学习。 各种图像处理问题具有不同形式的问题定义、用户控制或图像注释。在解决这些问题时，尽管可以以“程序化”的方式调节图像扩散算法，例如约束去噪过程、编辑多头注意力激活等，但是这些手工制定的规则的行为本质上是由人类指令所规定的。考虑一些特定任务，例如深度到图像、姿态到人体等，这些问题本质上需要将原始输入解释为对象级别或场景级别的理解，使得手工制定的程序化方法不太可行。为了在许多任务中实现学习的解决方案，端到端学习是不可或缺的。 图1：使用Canny边缘图对Stable Diffusion进行控制。Canny边缘图被输入，而源图像在生成右侧的图像时未被使用。输出是通过一个默认提示“高质量、详细和专业的图像”来实现的。本文中，此提示作为默认提示使用，不提及图像内容和对象名称。本文中的大多数图像都是高分辨率图像，在放大后查看效果最佳。 本文提出了ControlNet，一种端到端的神经网络架构，可控制大型图像扩散模型（如Stable Diffusion）来学习特定任务的输入条件进行控制。ControlNet将大型扩散模型的权重复制到一个“可训练副本”和一个“锁定副本”中：锁定副本保留了从数十亿图像中学到的网络能力，而可训练副本则在特定任务的数据集上进行训练，以学习条件控制。可训练和锁定的神经网络块通过一种称为“零卷积”的独特卷积层连接，其中卷积权重以一种学习的方式逐步从零增长到优化的参数。由于lock层权重被保留，因此训练在不同规模的数据集上具有鲁棒性。由于零卷积不会向深层特征添加新的噪声，因此与从头开始训练新层相比，训练速度与微调扩散模型一样快。 我们使用不同条件的数据集（例如，Canny边缘、Hough线、用户涂鸦、人体关键点、分割图、形状法线、深度等）训练了几个ControlNet。我们还在不同规模的数据集上实验了ControlNet，包括样本少于50k甚至1k的小数据集和数百万样本的大数据集。我们还展示了在某些任务中（例如深度到图像），使用个人电脑（一块Nvidia RTX 3090TI）训练ControlNet可以达到与在大型计算集群上训练的商业模型相竞争的结果。 ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:2:0","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Related Work ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:3:0","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"HyperNetwork and Neural Network Structure HyperNetwork起源于一种神经语言处理方法[14]，用于训练一个小型循环神经网络来影响一个更大的神经网络的权重。HyperNetwork在使用生成对抗网络[1,10]和其他机器学习任务[51]生成图像时也取得了成功的结果。受到这些想法的启发，[15]提供了一种方法将一个较小的神经网络连接到Stable Diffusion [44]上，以改变其输出图像的艺术风格。在[28]提供了预训练权重后，这种方法变得更加流行。ControlNet和HyperNetwork在它们影响神经网络行为的方式上有相似之处。 ControlNet使用了一种特殊的卷积层称为“zero convolution”。早期神经网络研究[31,47,32]已经广泛讨论了网络权重的初始化，包括使用高斯分布初始化权重的合理性以及使用零初始化权重可能带来的风险。最近，[37]讨论了一种在扩散模型中缩放多个卷积层的初始权重以改进训练的方法，这与零卷积的思想相似（他们的代码包含一个名为“zero_module”的函数）。ProGAN [21]和StyleGAN [22]，以及Noise2Noise [33]和[65]也讨论了操作初始卷积权重的方法。Stability的模型卡[55]也提到了在神经层中使用零权重的方法。 ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:3:1","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Diffusion Probabilistic Model ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:3:2","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Text-to-Image Diffusion 扩散模型可以应用于文本到图像生成任务中，以实现最先进的图像生成结果。通常通过使用预训练的语言模型，如CLIP [41]，将文本输入编码为潜在向量来实现。例如，Glide [38]是一个支持图像生成和编辑的文本引导扩散模型。Disco Diffusion是一个基于[9]的Clip引导实现，用于处理文本提示。Stable Diffusion是潜在扩散的大规模实现[44]，用于实现文本到图像的生成。Imagen [49]是一种文本到图像的结构，不使用潜在图像，而是使用金字塔结构直接扩散像素。 ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:3:3","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Personalization,Customization, and Control of Pretrained Diffusion Model ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:3:4","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Image-to-Image Translation ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:3:5","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Method ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:4:0","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"ControlNet 推导了一下，即使w和b都初始为0，也是可以进行梯度回传的。 ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:4:1","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"ControlNet in Image Diffusion Model 该模型基本上是一个具有编码器、中间块和跳跃连接解码器的U-net。编码器和解码器均有12个块，完整模型共有25个块（包括中间块）。在这些块中，有8个块是下采样或上采样的卷积层，17个块是主要块，每个块包含四个ResNet层和两个Vision Transformer（ViT）。每个ViT都包含几个交叉注意力和/或自注意力机制。文本由OpenAI CLIP编码，扩散时间步由位置编码编码。 Stable Diffusion使用了类似于VQ-GAN [11] 的预处理方法，将整个512×512图像数据集转换为更小的64×64“潜在图像”，以实现稳定训练。这需要ControlNets将基于图像的条件转换为64×64的特征空间以匹配卷积大小。我们使用一个小型网络，它由四个带有4×4卷积核和2×2步幅（通过ReLU激活，通道为16、32、64、128，初始化为高斯权重，与完整模型联合训练）的卷积层组成。 如图3所示，我们使用ControlNet来控制U-net的每个级别。请注意，我们连接ControlNet的方式在计算上是高效的：由于原始权重被锁定，因此不需要对原始编码器进行梯度计算来进行训练。这可以加快训练速度并节省GPU内存，因为可以避免对原始模型的一半梯度计算。使用ControlNet训练稳定扩散模型仅需要约23%的额外GPU内存和34%的更长时间的每次训练迭代（在单个Nvidia A100 PCIE 40G上测试）。 具体而言，我们使用ControlNet创建Stable Diffusion的12个编码块和1个中间块的可训练副本。这12个块在4个分辨率（64×64、32×32、16×16、8×8）中每个都有3个块。输出被添加到U-net的12个跳跃连接和1个中间块。由于SD是典型的U-net结构，因此该ControlNet架构很可能可用于其他扩散模型。 ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:4:2","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Training 在训练期间，我们随机替换50%的文本提示ct为空字符串。这有助于ControlNet从输入条件映射中识别语义内容，例如Canny边缘映射或人类涂鸦等。这主要是因为当SD模型看不到提示时，编码器倾向于从输入控制映射中学习更多的语义作为提示的替代品。 ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:4:3","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Improved Training 我们讨论了几种策略来改善ControlNets的训练，尤其是在计算设备非常有限（例如在笔记本电脑上）或非常强大（例如在具有大规模GPU的计算集群上）的极端情况下。在我们的实验中，如果使用了这些策略中的任何一个，我们将在实验设置中提到。 小规模训练：当计算设备有限时，我们发现部分断开ControlNet和稳定扩散之间的连接可以加速收敛。默认情况下，我们将ControlNet连接到“SD Middle Block”和“SD Decoder Block 1,2,3,4”中，如图3所示。我们发现，断开与 decoder 1,2,3,4的连接，只连接Middle Block，可以将训练速度提高约1.6倍（在RTX 3070TI笔记本电脑GPU上测试）。当模型在结果和条件之间显示出合理的关联后，这些断开的连接可以再次连接，以便在继续训练时实现精确的控制。 大规模训练：在这里，大规模训练是指同时具有强大计算集群（至少8个Nvidia A100 80G或同等配置）和大型数据集（至少100万个训练图像对）的情况。这通常适用于数据容易获得的任务，例如Canny检测的边缘映射。在这种情况下，由于过拟合的风险相对较低，我们可以先训练ControlNets足够多的迭代次数（通常超过50k步），然后解锁所有稳定扩散的权重，共同训练整个模型。这将导致更具问题特定性的模型。 ","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:4:4","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"Implementation","date":"2023-06-27","objectID":"/posts/dl/diffusion/controlnet/:4:5","tags":["draft"],"title":"Controlnet","uri":"/posts/dl/diffusion/controlnet/"},{"categories":["draft"],"content":"remote-ssh .ssh/config # Read more about SSH config files: https://linux.die.net/man/5/ssh_config Host 473_7000_Sunhy_Lz HostName 150.158.17.239 Port 7000 User sunhaoyu IdentityFile C:\\Users\\李哲\\.ssh\\id_rsa_Sunhy ","date":"2023-06-27","objectID":"/posts/dl/vscode-ssh/:1:0","tags":["draft"],"title":"Vscode Ssh","uri":"/posts/dl/vscode-ssh/"},{"categories":["draft"],"content":"创建环境 source /home/env.sh 切换students nvidia-smi ps aux | grep python export CUDA_VISIBLES_DEVICES=1 ","date":"2023-06-27","objectID":"/posts/dl/vscode-ssh/:2:0","tags":["draft"],"title":"Vscode Ssh","uri":"/posts/dl/vscode-ssh/"},{"categories":["draft"],"content":"Abstract 之前的DM，在pixel上扩散，耗费的资源多，时间非常长。 sd的做法，使用预训练好的autoencoder，在latent空间上做扩散。 引入cross-attention，使文字、bbox更好的作为控制条件引导图像生成。 ","date":"2023-06-26","objectID":"/posts/dl/diffusion/sd/:1:0","tags":["draft"],"title":"Sd","uri":"/posts/dl/diffusion/sd/"},{"categories":["draft"],"content":"Introduction 图像生成的方法：基于likelihood的方法多了起来；autore-gressive (AR) transformers : billions of params; gan：能生成的图片的多样性有限制，因为他的这个对抗学习的过程不容易使用在更复杂的模型上，在多模态的数据分布上也不大行。 diffusion在class-conditional image synthesis（beat gan这篇文章）和super-resolution sota了 diffusion作为likelihood模型，不像gan一样mode-collapse和instabilities，也不像AR那样参数那么多。 Democratizing High-Resolution Image Synthesis 大众化、不昂贵、普通人也用得起。 对于这个消耗资源多DDPM解决了一点点，但是还是耗费资源a reweighted ob- jective。Al-though the reweighted variational objective [30] aims to ad-dress this by undersampling the initial denoising steps, DMs are still computationally demanding, since training and evaluating such a model requires repeated function evalu-ations (and gradient computations) in the high-dimensional space of RGB images. beat gan 这篇文章中用V100训练了100天。在单个A100 GPU上生成50k个样本大约需要5天 Departure to Latent Space 探索latent space 先分析了pixel space的扩散模型。发现作为任何的likelihood生成模型，都能分成两步：semantic compression、perceptual compression 。We thus aim to first find a perceptually equivalent, but compu-tationally more suitable space, in which we will train diffu-sion models for high-resolution image synthesis.这个空间就是latent Soace。 train 分成两步 训练一个autoencoder产生a lower-dimensional (and thereby efficient) representational space which is perceptually equivalent to the data space，但是和以往的工作不同的是，不需要依赖过度的压缩空间。 扩散。 这种方法的好处是，我们只训练一次，训练出一个autoencoder层，把他用于多个DM的train并探索其他可能的任务。 总结一下贡献： 多个任务（无条件图像合成、修复、随机超分辨率）和数据集上实现了有竞争力的性能，同时显著降低了计算成本。与基于像素的扩散方法相比，我们还显著降低了推理成本。 此外，我们设计了一种基于交叉注意力的通用条件机制，实现了多模态的训练。我们使用它来训练类别作为条件的模型、文本到图像模型和布局到图像模型。 ","date":"2023-06-26","objectID":"/posts/dl/diffusion/sd/:2:0","tags":["draft"],"title":"Sd","uri":"/posts/dl/diffusion/sd/"},{"categories":["draft"],"content":"Related Work GAN：生成对抗性网络（GAN）[27]允许以良好的感知质量对高分辨率图像进行有效采样[3，42]，但难以优化[2，28，54]，并且难以捕获完整的数据分布[55]。 VAE\u0026flow-based：能够合成高分辨率的图像，但是样本质量和GAN没法比。 Autoregressive model：虽然自回归模型（ARM）[6，10，94，95]在密度估计方面实现了强大的性能，但计算要求高的架构[97]和顺序采样过程将其限制在低分辨率图像上。 两阶段方法[23，67101103]使用ARM对压缩的潜像空间而不是原始像素进行建模。 DDPM-\u003eLDM Two-Stage Image Synthesis:VQ-VAE、VQGAN 参数太多了 我们的工作：我们的工作防止了这种权衡，因为我们提出的LDM由于其卷积主干而更温和地扩展到更高维的潜在空间。因此，我们可以自由选择在学习强大的第一阶段之间最佳中介的压缩级别，而不会将太多的感知压缩留给生成扩散模型，同时保证高保真度重建 虽然存在联合[93]或单独[80]学习编码/解码模型以及基于分数的先验的方法，但前者仍然需要在重建和生成能力之间进行艰难的加权[11]，并且我们的方法优于前者（第4节），后者侧重于高度结构化的图像，如人脸。 ","date":"2023-06-26","objectID":"/posts/dl/diffusion/sd/:3:0","tags":["draft"],"title":"Sd","uri":"/posts/dl/diffusion/sd/"},{"categories":["draft"],"content":"Method 我们建议通过引入压缩学习阶段与生成学习阶段的明确分离来规避这一缺点（见图2）。为了实现这一点，我们使用了一种autoencoding，该模型学习一个在感知上与图像空间等效的空间，但提供了显著降低的计算复杂度。 这种方法提供了几个优点： （i）通过离开高维图像空间，我们获得了计算效率高得多的DM，因为采样是在低维空间上执行的。 不解（ii）我们利用了继承自其UNet架构的DM的归纳偏差[71]，这使得它们对具有空间结构的数据特别有效，从而缓解了对先前方法所需的激进、降低质量的压缩级别的需求[23，66]。（iii）最后，我们获得了通用压缩模型，其潜在空间可用于训练多个生成模型，也可用于其他下游应用，如单图像CLIP引导合成[25]。 ","date":"2023-06-26","objectID":"/posts/dl/diffusion/sd/:4:0","tags":["draft"],"title":"Sd","uri":"/posts/dl/diffusion/sd/"},{"categories":["draft"],"content":"Perceptual Image Compression 我们的感知压缩模型基于先前的工作[23]，由感知损失[106]和基于补丁的[33]对抗性目标[20，23103]组合训练的自动编码器组成。这确保了通过增强局部真实性将重建限制在图像流形内，并避免了仅依赖于像素空间损失（如L2或L1物镜）而引入的模糊性。 ","date":"2023-06-26","objectID":"/posts/dl/diffusion/sd/:4:1","tags":["draft"],"title":"Sd","uri":"/posts/dl/diffusion/sd/"},{"categories":["draft"],"content":"Latent Diffusion Models ","date":"2023-06-26","objectID":"/posts/dl/diffusion/sd/:4:2","tags":["draft"],"title":"Sd","uri":"/posts/dl/diffusion/sd/"},{"categories":["draft"],"content":"Conditioning Mechanisms cross-attention，为了预处理来自各种模态（如语言提示）的y，我们引入了一个特定于领域的编码器τθ，（y就是条件） Autoencoder训练： �1/�2����来作为重建损失，用���来做对抗攻击？，用KL loss来把latent space拉到正态分布，防止搜索空间过大。 用了encoder降维后，就可以使用latent space diffusion了~ 具体扩散过程其实没有变，只不过现在扩散和重建的目标为latent space的向量了。Diffusion model具体实现为 time-conditional UNet。 为了引入conditioning的信息，提出了domain specific encoder ��(�)不同模态的（比如text, class, image…）转成中间表达(intermediate representation)，再利用cross-attention来嵌入到UNet中去。 ","date":"2023-06-26","objectID":"/posts/dl/diffusion/sd/:4:3","tags":["draft"],"title":"Sd","uri":"/posts/dl/diffusion/sd/"},{"categories":["Transfomer"],"content":"attention的缺点就是这个矩阵算起来花销很大。所以就有系列的方法加速attention的计算。 self-attention在其他网络中只是一个模块，比如transformer，有时加快self-attention并不能很明显的加快整个网络，因为网络还有其他部分。当我们的seq的长度很大的时候，加速的过程会比较好。 人为的再attention矩阵中添加一些内容，以减少计算。 ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:0:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Local Attention/Truncated Attention 例如在有些任务中，attention只关注他相邻的位置，其他位置不重要，那么我们就可以像下图这样，把矩阵中其余位置的值设为0，不进行计算，只计算其他区域，这样就可以加速运算了。我们可以发现，这种时候和cnn很像。所以Local Attention能加快运算，但是有时候结果并不一定好。 ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:1:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Stride Attention 相比于localattention只看邻居的信息，stride看的稍微远一些，隔了几个位置。具体隔几个位置由自己决定。 ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:2:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Global Attention 在向量中选取几个合适的token，把他们标记为特殊的token，他们关注整个向量的语义信息，同时被整个向量关注着。 attention 矩阵的计算效果如下图，只有与头两个位置有关的位置才做attention。其余位置不计算。 怎么选择，我们可以每个head做不同的attention。 以上是通过人工的行为去定义哪些位置不去进行计算，有时候并不一定很好，以下介绍不靠人为去定义。 我们看看有没有办法直接去估计一个attention里面，哪些位置更重要，哪些位置不重要，把不重要的部分变成0，这样对整体的结果影响比较小。 接下来我们就考虑怎么快速的去估计哪些位置的权重小。 ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:3:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Reformer\u0026Routing Transformer 把query和key拿出来，根据query和key相近的程度做聚类。如下图就分成了4类 如果query和key是属于同一类的才去做attention，否则不计算。 其实这种我们人为也参与了一下，那么要不要计算这件事情能不能learn出来呢？ ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:4:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Sinkhorn Sorting Network 下图中的方法实际上learn nn时，好几个input会公用一个vector，要不然的话不也没有很快。 ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:5:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Linformer n*n的矩阵中有很多信息都是重复的，并不是极大无关组，我们完全可以只用一部分。 做法是从key中选出K个来做“代表”（怎么选，看下面），value中也挑出K个来。 新的问题，为啥选key的代表，而不选query的代表？如果q也选代表的话计算确实会快，但是会影响输出的向量的大小，也会缩短了，对于有些任务就会有负面影响了。 ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:6:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Reduce Number of Keys 接下来看，怎么选出具有代表性的key。左图是过一个CNN，右图是做一个线性变换，得到的矩阵肯定包含着原来的信息了， 我们来思考一下这个计算过程的加速： 原理：按照上面的方法做运算量是N×d×N + d'×N×N = (d+d')N^2，下面的运算量是d'×N×d + d'×d×N =2(d+d')N ，N是很大的数字哦。 ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:7:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Synthesizer 权重矩阵的计算不需要q和v 有一个版本这个矩阵是也是通过a算出来的，另一个版本是这个矩阵是network的参数 ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:8:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"Attention-free ","date":"2023-06-24","objectID":"/posts/dl/transformer/attention/:9:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Attention","uri":"/posts/dl/transformer/attention/"},{"categories":["Transfomer"],"content":"transformer就是一个seq2seq的问题。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:0:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"Encoder 我们先来看一下encoder做的事情，输入一串向量，输出相同长度的向量。 transformer中的encoder详解：Add\u0026Norm就是一个残差加上layer norm的过程。 一个encoder是由n个block组成的。每一个block又有几层。 当然后来还有人更改transformer的原始架构。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:1:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"Decoder encoder做的事情就是输入一串向量，产生一串向量，decoder要做的就是根据encoder生成的向量去产生最终我们要的输出。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:2:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"autoregressive 接下来我们来看decoder的部分。先看第一种autoregressive的decoder： 第一次 根据一个特殊的begin起始符号会输出一个字机，选择得分最高的那个字输出（是经过softmax后的）。 第二次我们的输入是 begin和机，根据这两个输入经过decoder算出下一个字输出什么，然后得到器的概率最大，依次类推，把每一次得到的输出加起来当做下一次的输入…… 接下来看一下transformer中decoder的具体结构： 通过对比，发现decoder比encoder中间多了一次注意力AddNorm的操作，同时第一层使用的是masked的多头注意力，那么masked的多头是什么呢？ 下图是原始的self-attention，而masked后，每一个向量的产生不再和他右边的向量有关。 例如，在生成b1时，只关注a1： 在生成b2时，只关注a1、a2： 在生成b3时，只关注a1、a2、a3： 在生成b4时，才关注a1、a2、a3、a4： 设计成masked的原因？ 那么接下来的问题就是，这种一次次的迭代何时停止呢，因为seq2seq的问题，我们并不能知道最后输出的向量的长度是多少。 解决方法是我们还需要准备一个特殊的符号End，当End的得分最大时，就停止输出了。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:2:1","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"non-autoregressive 接下来看另一种decoder，non-autoregressive的。 NAT不同于AT的一个个输出，而是一次性输入n个begin，一次性产生n个输出。而n的数量，可以单独的train出来，预测一下输出的长度，这个model的输入是encoder的输出，输出就是decoder应该输出的长度n。还有一种做法是，输入足够多的begin，然后观察输出，截取到end左边的部分，右边的就不要了。显而易见NAT的速度更快，同时输出的长度可控。缺点就是效果有时不如AT好。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:2:2","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"Encoder和Decoder之间的信息传递 q来自decoder，k来自encoder。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:3:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"Transformer的训练 训练的过程其实和分类任务相似，和ground truth做一个loss，最小化这个loss 另外一个地方，需要注意的是，我们在训练的时候，给decoder的输入是groundtruth。这个思想叫做Teacher Forcing。当然测试的时候不给他看正确答案。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:4:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"Copy Mechanism 有些场景，decoder的输出内容是可以从输入内容中复制过来的，比如聊天机器人，输入的内容有些在机器人的回答中是有的。或者在做摘要的时候。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:4:1","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"Guided Attention 引导注意力，要求机器在做attention的时候是有固定的方式的。例如以语音合成为例，注意的部分应该是从左向右的，我们应该强迫他从左向右看。 Monotonic Attetion``location-aware attention ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:4:2","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"Beam Search 看下图，考虑一个问题，我们应该怎么选择一条正确的道路呢，策略应该是什么样的？方法就是Beam Search。 训练的时候loss是看的每一个向量的，而测试时候计算的是整个句子的bluescore。为什么训练的时候不用bluescore，是不好微分，不好调优。 之前讲过一个问题，train的时候给decoder看的全是正确答案，训练出来的结果不一定好，因为一旦一步错，就步步错了。解决办法是给正确答案加入一些错误的信息。 ","date":"2023-06-23","objectID":"/posts/dl/transformer/transformer/:4:3","tags":["深度学习","注意力机制","Transfomer"],"title":"Transformer","uri":"/posts/dl/transformer/transformer/"},{"categories":["Transfomer"],"content":"self-attention最初想解决的问题是，输入变成一个向量的集合（输入是一个长度可以改变的序列）而不再仅仅只能是一个向量。比如：给一句英文进行翻译。那这样的例子我们怎么实现呢，比如有一句话this is a cat怎么把他编码成向量的序列呢。最简单的方法就是通过One-hot Enconding，假如世界上有10w个单词，我们就卡一个10w的向量，每一个维度表示一个单词，例如apple=[1 0 0 0 0 ……] bag=[ 0 1 0 0 0 ……] cat=[ 0 0 1 0 0 ……] dog=[ 0 0 0 1 0 ……]等等，但是这样出现的一个问题是，每个单词之间没有任何的关系，我们并不能看出cat和dog都是动物，这样设置的向量没有任何语义的信息。那么还有一种方法是Word Embedding，将有语义相关联的单词放在一起。除了单词构成的句子意外，表示声音信号也是一个序列的向量。一个图信息也是一个序列的向量。以上的这种序列向量作为模型输入的情况，输出的情况有以下几种：1.一一对应的，输入4个向量就输出4个向量，如对文字的处理；2.一整个输入只输出一个label，如评价一句话是正面的还是负面的；3.不知道输出向量的个数是多少，这种任务叫叫做seq2seq，如翻译。 接下来我们看输入和输出的向量的数目一样多的情况。这种情况又叫做Sequence Labeling。 如果我们有一个任务，判断句子中每个单词的词性，如果我们用普通的全连接网络，会出很大的问题，因为同样是一个saw，其实是有不同的词性的。所以就引出了考虑上下文语义的self-attention。（当然也可以通过下下图，意思就是说考虑一个窗口内的词，但这样也有问题，就是考虑的范围只局限于一个window内） self-attention的模型。 self-attention也可以叠加，如下图。 接下来看一看self-attention是怎么运作的，他是怎么让一个向量考虑到全部向量的语义信息的。 self-attention的向量是一串向量，这些向量可以是输入，也可以是一个hidden layer的输出，就是对输入进行了一次处理得到的隐层特征。最终的每一个输出b都考虑到了全部的a。 首先找到这个序列中和a1最相关的一个向量，也就是该向量对a1的影响是最大的，每两个向量之间的相关程度是通过一个计算方式能算出来的。 计算α(相关程度)的方法有很多，比如Dot-product，也就是内积（对应位置相乘再相加），还比如Additive。transform用到的方法就是左面这种。 下图中的 α’ 就是他们之间的相关程度了。 利用这个相关程度得到一个b1，这个b1就是a1考虑了全局的语义后的一个输出了。以此类推，我们可以得到b2，b3，b4。需要注意的是b1到b4的顺序不是依次生成的，而是同时算出来的。 可以发现Wk、Wv、Wq三个矩阵是未知的，是需要学习的。 接下来是self-attention进阶的版本，多头注意力机制。多头指的是查询的时候，看两个向量的相关性，不能只通过一个q或k来判断，不同的q可能表示不同种类的相关性。操作如下（2头）： 用另一头求出bi2 最后： 到目前为止，其实我们的self-attention少了一个很重要的信息，那就是位置信息，我们之前标的1 2 3 4都是便于理解标注的，实际上模型中并没有考虑到他们的位置，都是同时进行一个计算的。接下来讲如何进行位置编码： 上图展示的ei是人为定义的，是通过一个sin、cos规则产生的。位置编码也可以是学出来的，这一点有人在研究，哪种方法最好。 sa 语音方面的应用。 sa 图像方面的应用。 CNN只考虑了局部。 ","date":"2023-06-20","objectID":"/posts/dl/transformer/self_attention/:0:0","tags":["深度学习","注意力机制","Transfomer"],"title":"Self_attention","uri":"/posts/dl/transformer/self_attention/"},{"categories":["论文"],"content":"Diffusion Models for Imperceptible and Transferable Adversarial Attack 不可感知和可转移对抗性攻击的扩散模型 ","date":"2023-06-19","objectID":"/posts/papers/0619-1/:0:0","tags":["diffusion","Adversarial Attack"],"title":"DiffAttack","uri":"/posts/papers/0619-1/"},{"categories":["论文"],"content":"Abstract 许多现有的对抗攻击在图像RGB空间上产生Lp范数扰动。尽管在可迁移性和攻击成功率方面取得了一些成就，但精心制作的对抗样本很容易被人眼感知。对于视觉的不可感知性，最近的一些研究探索了不受Lp范数约束的无限制攻击，但缺乏攻击黑盒模型的可迁移性。在这项工作中，我们通过利用扩散模型的生成和判别能力，提出了一种新的难以察觉和可迁移的攻击。具体来说，我们不是在像素空间中直接操作，而是在扩散模型的潜在空间中进行扰动。结合精心设计的内容保存结构，我们可以生成嵌入语义线索的人类不敏感的扰动。为了更好的可迁移性，我们进一步“欺骗”扩散模型，它可以被视为一个额外的识别代理，通过将其注意力从目标区域转移开。据我们所知，我们提出的方法DiffAttack是第一个将扩散模型引入对抗攻击领域的方法。在各种模型结构(包括cnn, Transformers, mLp)和防御方法上的大量实验，证明了我们的攻击方法优于其他攻击方法。 （可迁移性指的是什么？不受Lp范数约束的无限制攻击又是什么？） ","date":"2023-06-19","objectID":"/posts/papers/0619-1/:1:0","tags":["diffusion","Adversarial Attack"],"title":"DiffAttack","uri":"/posts/papers/0619-1/"},{"categories":["论文"],"content":"Introduction 此外，这些对抗性样本在不同模型架构之间的可转移性[9]对实际实现构成了更大的危险。(Nicolas Papernot, Patrick McDaniel, and Ian Goodfellow. Transferability in machine learning: from phenomena to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277, 2016. 1, 3) 与攻击者可以访问目标模型的结构和参数的白盒攻击[10–12，7]相比，黑盒攻击[13–26，9]无法获取目标模型的信息，因此更接近真实世界的场景。在黑箱方向中，我们在这里关注基于转移的攻击[15，19–23，9]，这些攻击直接应用在代理模型上构建的对抗性样本来欺骗目标模型。通过采用不同的优化策略[27，23]，设计各种损失函数[16，17，19，22]，利用多种数据扩充[13，14，20，21]等，现有方法取得了很大成功，并很好地提高了攻击的可转移性。 基于Lp范数的方法。上述大多数方法都采用RGB颜色空间中的Lp范数作为人类感知的指标，同时约束对抗性扰动的幅度在一个特定范围。尽管付出了努力，但这些基于像素的攻击仍然很容易被人眼感知，最近发现Lp范数不适合测量两幅图像之间的感知距离[28，29]。从图1中显示的例子来看，尽管L∞值较低，但通过Lp损失优化的扰动是明显的，并且看起来类似于高频噪声（表示替代模型上的过拟合），这可能会阻碍向其他黑匣子模型的转移[30，31]，并且很容易通过净化防御进行防御。 面向难以察觉的攻击最近的工作[34，30，35，36，28，37]探索了在不使用Lp范数约束（也称为无限制攻击）的情况下欺骗人类感知的新方法。通过对诸如对象属性[36，30]、颜色映射矩阵[35]、图像纹理[37]等空间应用扰动，尽管RGB空间中的Lp范数值很大，但对抗性示例是很难察觉的。此外，最近的工作[30，37，35]表明，无限制攻击产生的扰动更多地集中在具有高级语义的相对大规模的模式上，而不是操纵像素级的强度，从而有利于攻击向其他黑匣子模型甚至防御黑匣子模型的可转移性。然而，这些方法的可转移性仍然落后于基于像素的方法。 在这项工作中，我们提出了一种新的基于扩散模型的无限制攻击[38-42]。我们不是直接操纵像素，而是优化现成的预训练扩散模型的潜层空间[42]。除了上述高level的扰动的可转移性优势外，我们将扩散模型引入对抗性攻击领域的动机主要源于其两个有益的特性。1） 良好的隐蔽性。扩散模型倾向于对符合人类感知的自然图像进行采样，这自然满足了对抗性攻击所需的不可感知性。最近对真实图像编辑的研究[43-45]进一步支持了我们的观点，即扰动可以应用于高级语义，而不会影响图像的真实性。2） 强代理的近似。一方面，正如[32]所指出的，扩散模型的去噪过程可以作为一种强大的净化防御。另一方面，扩散模型在大规模数据集上训练的扩散模型天生具有强大的判别能力[46，47]（why？？？），并且可以近似为基于转移的攻击的强代理模型。如果攻击能够欺骗这个“强大的模型”，那么我们可能会期望良好的可转移性到其他模型和防御。为了有效地利用扩散模型的上述良好性质，我们从三个方面进行了工作。首先，我们按照DDIM[43，44]构建了基本框架，该方法将图像反转为噪声，然后在潜在空间中应用修改。与改变引导文本以实现内容编辑的方法[48，49]相比，我们专注于对隐层空间的直接操作，这对攻击的成功有很大好处。其次，我们建议偏离文本和图像像素之间的交叉注意力映射，通过这种方式，我们可以将扩散模型转换为一个可以在实际中被欺骗和攻击的代理模型。最后，为了避免扭曲初始语义，我们考虑了具体的措施，包括自注意约束和反转强度。我们将提出的无限制攻击称为DiffAttack。 据我们所知，我们是第一个揭示扩散模型潜力的人，可以制作出具有令人满意的不可感知性和可转移性的对抗性例子。 我们提出了DiffAttack，这是一种新的无限制攻击，其中扩散模型的良好特性被特定的设计所利用。 对各种架构（如细胞神经网络、变压器和MLPMixer）和防御（包括最近的扩散纯化）的广泛实验表明，我们的工作优于现有的基于转移的方法 ","date":"2023-06-19","objectID":"/posts/papers/0619-1/:2:0","tags":["diffusion","Adversarial Attack"],"title":"DiffAttack","uri":"/posts/papers/0619-1/"},{"categories":["论文"],"content":"Method ","date":"2023-06-19","objectID":"/posts/papers/0619-1/:3:0","tags":["diffusion","Adversarial Attack"],"title":"DiffAttack","uri":"/posts/papers/0619-1/"},{"categories":["论文"],"content":"Problem Formulation 给定一个干净的图像x和它对应的标签y，攻击者的目标是制造扰动，使分类器的决策Fθ (θ表示模型的参数)从正确变为错误: 其中Attack(·)为攻击方法，x’表示精心制作的对抗样本。由于Fθ的信息在黑盒场景中是不可访问的，因此对抗样本是在替代模型Gφ上制作的。与对扰动应用Lp范数进行约束的基于像素的攻击[7，10，23]不同，我们在扩散模型的隐层空间中施加扰动，并依赖于扩散模型的特性实现视觉上的自然和成功的攻击。我们将在下面详细描述我们的设计。 ","date":"2023-06-19","objectID":"/posts/papers/0619-1/:3:1","tags":["diffusion","Adversarial Attack"],"title":"DiffAttack","uri":"/posts/papers/0619-1/"},{"categories":["论文"],"content":"Basic Framework of Destruction and Reconstruction 利用SD，DDIM将图片加噪。优化隐层空间去欺骗分类器。交叉注意力映射(是什么？)被用来欺骗扩散模型，我们使用自注意力机制来保留结构。 由于对抗性攻击旨在通过干扰初始图像来欺骗目标模型，因此可以将其近似为一种特殊的真实图像编辑。受最近扩散编辑方法[44，43，49]的启发，我们的框架还利用了DDIM反演技术[59]（详细信息见附录B），即通过反演确定性采样过程，将干净图像映射回扩散隐层空间。 其中Inverse(·)表示DDIM反演操作，我们对从x0(初始图像)到xt的几个时间步进行反演。 现有的许多方法[44，43，49]都提出了修改文本嵌入进行图像编辑，通过这种方式，在文本引导的迭代去噪过程中，图像潜在文本可以逐渐转移到目标语义空间。然而，在我们的探索中（见附录C），我们发现引导文本嵌入上的扰动很难在其他黑匣子模型上工作，导致可转移性较弱。因此，与编辑方法不同，我们在这里建议直接扰动潜在的xt 其中J(·)为交叉熵损失，Denoise(·)为扩散去噪过程。 一个可能的问题是，这种直接的方法可能会导致不自然的结果，然而，我们可以在图1中观察到，从扰动的潜影重建的图像和初始的干净图像之间的差异几乎无法区分。此外，我们可以注意到，在使用基于像素的攻击时，差异图像可能包含许多高级语义线索，而不是高频噪声。我们将这些归因于稳定扩散模型的去噪过程，以及其自动编码器强大的映射能力。这些语义丰富的扰动不仅可以增强不可感知性，而且对攻击的可转移性也有很大好处[30，37，35]。 ","date":"2023-06-19","objectID":"/posts/papers/0619-1/:3:2","tags":["diffusion","Adversarial Attack"],"title":"DiffAttack","uri":"/posts/papers/0619-1/"},{"categories":["论文"],"content":"“Deceive“Strong Diffusion Model 扩散模型的反向过程是一种很强的对抗性净化防御。因此，我们的扰动潜信号在解码为最终图像之前经历了净化，从而确保了精心制作的对抗样本的自然性以及对其他净化降噪的鲁棒性。 除了避开去噪部分外，我们还进一步提高了攻击的可迁移性。给定一张图像及其对应的标题，从图3中我们可以看到，在反演的重建过程中，交叉注意图显示出了引导文本与图像像素之间的强关系，这说明了预训练扩散模型的强大识别能力。赫兹等人[48]也验证了这种关系，其识别能力最近被用于下游任务[46，47]。因此，在海量数据上训练的扩散模型可以近似为一个强识别模型，我们的动机是，如果我们精心设计的攻击可以“欺骗”这个强大的模型，我们可能会期望向其他黑匣子模型的可转移性有很大提高。 C表示为干净图像的类别，我们将其设置为groundtruth类别的名称(我们也可以简单地使用预测类别Gφ，因此不依赖于真实标签)。我们在所有去噪步骤中累积图像像素与C之间的交叉注意映射并得到平均值。为了“欺骗”预训练的扩散模型，我们建议最小化以下公式: 其中Var(·)计算输入的方差，Cross(·)表示去噪过程中所有交叉注意图的累加，SDM为稳定扩散。这种洞察力是为了分散扩散模型对标记对象的注意力。通过将交叉注意力均匀地分布到图像的每个像素上，我们可以破坏原始的强语义关系，确保我们精心制作的对抗样本很好地“欺骗”了强扩散模型。 ","date":"2023-06-19","objectID":"/posts/papers/0619-1/:3:3","tags":["diffusion","Adversarial Attack"],"title":"DiffAttack","uri":"/posts/papers/0619-1/"},{"categories":["论文"],"content":"Preserve Content Structure 如第3.2节所述，我们的无限制攻击可以近似为图像编辑方法，因此内容结构的变化是不可避免的。如果变化的程度没有得到控制，那么由此产生的对抗性示例可能会失去初始干净图像的大部分语义（见图5），从而失去对抗性攻击的重要性，这不是我们想要的。因此，我们在这里主要从两个角度来保留内容结构。 Self-Attention Control. 研究发现，基于自相似的描述符可以在忽略图像外观的情况下捕获结构信息。根据这个想法，我们可以从图3中观察到，扩散模型中的自注意也嵌入了这个属性，这与主要关注高级语义的交叉注意形成对比。因此，我们建议利用自注意图进行结构保留。我们设定了逆潜函数的一个副本xt(fix)，它是固定的，没有扰动。通过分别计算xt(f)和xt的自注意映射(记为St(f)和St)，我们强迫St接近St(f)，方法如下: 我们在这里将自注意约束应用于所有去噪步骤。由于xt(f)很好地重建了原始的干净图像，我们可以通过这种方式保留结构。 Inversion Strength Trade-off. 随着DDIM反演强度的增加，潜函数xt将更接近于纯高斯分布，对其的扰动会受到更多去噪步骤的影响而造成严重的失真。而有限的反演无法提供足够的攻击空间，因为潜函数先验太强。我们在去噪过程的后面控制反转以保留高级语义，并减少DDIM样本的总步骤以获得更多的编辑空间。 一般情况下，DiffAttack的最终目标函数如下，其中α、β、γ分别表示各损失的权重因子: ","date":"2023-06-19","objectID":"/posts/papers/0619-1/:3:4","tags":["diffusion","Adversarial Attack"],"title":"DiffAttack","uri":"/posts/papers/0619-1/"},{"categories":["项目"],"content":"vue + fiber ","date":"2023-06-19","objectID":"/posts/projects/pro05/:0:0","tags":["go web"],"title":"Pro05","uri":"/posts/projects/pro05/"},{"categories":["项目"],"content":"Vue文件布局 Vue 提供了一种单文件组件（Single-File Component）的开发方式，允许将模板、JavaScript 逻辑和样式都集中在一个文件中，使组件的开发更加模块化和可维护。 然而，你可以根据项目的要求和个人的偏好进行组件的布局。以下是一些常见的布局方式： 单文件组件布局（推荐）：将模板、JavaScript 逻辑和样式都放在一个 .vue 文件中，按照上述示例中的布局进行开发。这种方式适合大多数情况，特别是在大型项目中使用。 拆分文件布局：将模板、JavaScript 逻辑和样式分别放在不同的文件中，然后在组件的主文件中进行引入。例如，可以将模板放在一个 .html 或 .vue 文件中，JavaScript 逻辑放在一个 .js 或 .vue 文件中，样式放在一个 .css 或 .vue 文件中。这种方式适合简单的组件或需要更细粒度的控制的情况。 组件库布局：如果你正在开发一个组件库或可复用的组件，可以将每个组件的模板、JavaScript 逻辑和样式都放在一个独立的文件夹中，使每个组件成为一个单独的模块。 总之，Vue 并没有严格规定组件的布局方式，你可以根据项目的需求和个人的喜好来选择合适的布局方式。重要的是确保组件的结构清晰、易于维护，并符合项目的整体设计和组织准则。 \u003ctemplate\u003e \u003c!-- 模板部分 --\u003e \u003cdiv\u003e \u003ch1\u003e{{ message }}\u003c/h1\u003e \u003cp\u003e{{ description }}\u003c/p\u003e \u003c/div\u003e \u003c/template\u003e \u003cscript\u003e export default { // JavaScript 部分 data() { return { message: 'Hello, Vue!', description: 'This is a Vue component.' }; } } \u003c/script\u003e \u003cstyle scoped\u003e /* 样式部分 */ h1 { color: blue; } p { font-size: 14px; } \u003c/style\u003e ","date":"2023-06-19","objectID":"/posts/projects/pro05/:1:0","tags":["go web"],"title":"Pro05","uri":"/posts/projects/pro05/"},{"categories":["项目"],"content":"JavaScript部分 常见的属性和钩子函数 1.name name 属性用于指定组件的名称，它在组件定义中是可选的。名称可以用于调试和组件之间的通信，也可以在递归组件中使用。例如： export default { name: 'MyComponent', // 组件的其他属性和方法 } 2.data data 属性是一个函数，用于定义组件的初始数据。这个函数返回一个对象，包含了组件的数据属性。这些属性可以在组件的模板中使用，并且可以通过 this 关键字在组件的其他方法中访问和修改。例如： export default { data() { return { message: 'Hello, Vue!', count: 0 }; }, // 组件的其他属性和方法 } 3.computed computed 属性用于定义计算属性，它是基于组件的响应式数据进行计算得出的属性值。计算属性会缓存计算结果，并在依赖的响应式数据发生变化时自动更新。例如： export default { data() { return { firstName: 'John', lastName: 'Doe' }; }, computed: { fullName() { return this.firstName + ' ' + this.lastName; } }, // 组件的其他属性和方法 } 4.created created 是一个生命周期钩子函数，它在组件实例创建完成后立即被调用。在这个阶段，组件的响应式数据已经初始化，可以进行数据的获取、初始化操作或与外部进行交互。例如： export default { created() { console.log('Component created'); }, // 组件的其他属性和方法 } 5.methods methods 属性用于定义组件的方法。这些方法可以在组件的模板中绑定并触发，也可以在组件的其他方法中调用。方法中可以访问组件的数据和其他方法。例如： export default { data() { return { count: 0 }; }, methods: { increment() { this.count++; }, decrement() { this.count--; } }, // 组件的其他属性和方法 } 6.mounted mounted 是一个生命周期钩子函数，在组件挂载到 DOM 后调用。在这个阶段，组件已经被实例化，并且可以访问 DOM 元素。可以在 mounted 钩子函数中进行 DOM 操作、获取数据等。例如： export default { mounted() { console.log('Component mounted'); }, // 组件的其他属性和方法 } 7.props props 属性用于接收父组件传递的数据。通过 props，父组件可以向子组件传递数据，并在子组件中使用这些数据。子组件可以对接收到的属性进行验证和处理。例如： export default { props: { message: String, count: { type: Number, default: 0 } }, // 组件的其他属性和方法 } 8.watch watch 属性用于监听组件中的数据变化，并在数据变化时执行相应的操作。可以监听单个属性或多个属性的变化。例如： export default { data() { return { message: 'Hello, Vue!', count: 0 }; }, watch: { message(newValue, oldValue) { console.log('Message changed:', newValue, oldValue); }, count(newValue, oldValue) { console.log('Count changed:', newValue, oldValue); } }, // 组件的其他属性和方法 } 9.filters filters 属性用于定义 Vue 过滤器，用于对模板中的数据进行格式化或处理。过滤器可以用在双花括号插值或指令表达式中。例如： export default { data() { return { message: 'Hello, Vue!' }; }, filters: { uppercase(value) { return value.toUpperCase(); } }, // 组件的其他属性和方法 } import和export import 和 export 是 JavaScript 中用于模块导入和导出的语法。 import 语句用于导入其他模块的内容。它可以用于导入单个项、默认导出项或命名导出项。例如： import { namedExport1, namedExport2 } from './module'; import defaultExport from './module'; export 语句用于将模块中的内容导出，以便其他模块可以导入和使用。它可以用于导出单个项、默认导出项或命名导出项。例如： export const namedExport1 = 'value1'; export const namedExport2 = 'value2'; export default defaultValue; 这些语法是 ECMAScript 6 (ES6) 引入的模块系统的一部分，可以在现代的 JavaScript 环境中使用。在 Vue 组件开发中，通常会使用这些语法来导入和导出组件、工具函数、样式文件等。 需要注意的是，import 和 export 语句通常用于支持模块化开发，需要在支持 ES6 模块的环境中运行，或者通过工具（如 Babel）进行转换和打包，以在目标环境中正常运行。 ","date":"2023-06-19","objectID":"/posts/projects/pro05/:2:0","tags":["go web"],"title":"Pro05","uri":"/posts/projects/pro05/"},{"categories":["项目"],"content":"Vue CLI 脚手架 npm install -g @vue/cli 要使用管理员权限才能安装 vue create my-project ","date":"2023-06-19","objectID":"/posts/projects/pro05/:3:0","tags":["go web"],"title":"Pro05","uri":"/posts/projects/pro05/"},{"categories":["Go每日一练"],"content":"Day31 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:1:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？ func change(s ...int) { s = append(s,3) } func main() { slice := make([]int,5,5) slice[0] = 1 slice[1] = 2 change(slice...) fmt.Println(slice) change(slice[0:2]...) fmt.Println(slice) } 参考答案及解析： [1 2 0 0 0] [1 2 3 0 0] 知识点：可变函数、append()操作。Go 提供的语法糖…，可以将 slice 传进可变函数，不会创建新的切片。第一次调用 change() 时，append() 操作使切片底层数组发生了扩容，原 slice 的底层数组不会改变；第二次调用change() 函数时，使用了操作符[i,j]获得一个新的切片，假定为 slice1，它的底层数组和原切片底层数组是重合的，不过 slice1 的长度、容量分别是 2、5，所以在 change() 函数中对 slice1 底层数组的修改会影响到原切片。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:1:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ func main() { var a = []int{1, 2, 3, 4, 5} var r [5]int for i, v := range a { if i == 0 { a[1] = 12 a[2] = 13 } r[i] = v } fmt.Println(\"r = \", r) fmt.Println(\"a = \", a) } 参考答案及解析： r = [1 12 13 4 5] a = [1 12 13 4 5] 这道题是 第30天 的第二题的一个解决办法，这的 a 是一个切片，那切片是怎么实现的呢？切片在 go 的内部结构有一个指向底层数组的指针，当 range 表达式发生复制时，副本的指针依旧指向原底层数组，所以对切片的修改都会反应到底层数组上，所以通过 v 可以获得修改后的数组元素。（day30中的a是一个数组） 引自：https://tonybai.com/2015/09/17/7-things-you-may-not-pay-attation-to-in-go/ ","date":"2023-06-19","objectID":"/posts/go/day31-40/:1:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day32 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:2:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出结果正确嘛？ type Foo struct { bar string } func main() { s1 := []Foo{ {\"A\"}, {\"B\"}, {\"C\"}, } s2 := make([]*Foo, len(s1)) for i, value := range s1 { s2[i] = \u0026value } fmt.Println(s1[0], s1[1], s1[2]) fmt.Println(s2[0], s2[1], s2[2]) } 输出： {A} {B} {C} \u0026{A} \u0026{B} \u0026{C} 参考答案及解析：s2 的输出结果错误。s2 的输出是 \u0026{C} \u0026{C} \u0026{C}，在 第 30 天 的答案解析第二题，我们提到过，for range 使用短变量声明(:=)的形式迭代变量时，变量 i、value 在每次循环体中都会被重用，而不是重新声明。所以 s2 每次填充的都是临时变量 value 的地址，而在最后一次循环中，value 被赋值为{c}。因此，s2 输出的时候显示出了三个 \u0026{c}。 可行的解决办法如下： for i := range s1 { s2[i] = \u0026s1[i] } ","date":"2023-06-19","objectID":"/posts/go/day31-40/:2:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.下面代码里的counter的输出值 func main() { var m = map[string]int{ \"A\": 21, \"B\": 22, \"C\": 23, } counter := 0 for k, v := range m { if counter == 0 { delete(m, \"A\") } counter++ fmt.Println(k, v) } fmt.Println(\"counter is \", counter) } A. 2 B. 3 C. 2 或 3 参考答案及解析：C。for range map 是无序的，如果第一次循环到 A，则输出 3；否则输出 2。第一次遍历出来的kv如果是A的话，那不就3个全能遍历到，如果第一次遍历的是其他的，然后又把A删除了，以后就遍历不到A了，只能遍历出其余两个。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:2:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day33 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:3:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.关于协程，下面说法正确的是（） A. 协程和线程都可以实现程序的并发执行； B. 线程比协程更轻量级； C. 协程不存在死锁问题； D. 通过 channel 来进行协程间的通信； 参考答案及解析：AD。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:3:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.关于循环语句，下面说法正确的是（） A. 循环语句既支持 for 关键字，也支持 while 和 do-while； B. 关键字 for 的基本使用方法与 C/C++ 中没有任何差异； C. for 循环支持 continue 和 break 来控制循环，但是它提供了一个更高级的 break，可以选择中断哪一个循环； D. for 循环不支持以逗号为间隔的多个赋值语句，必须使用平行赋值的方式来初始化多个变量； 参考答案及解析：CD。a[i], a[j] = a[j], a[i]，平行赋值。Go语言中支持使用 “break” 语句以及 “continue” 语句来控制循环，同时也支持使用 “label” 来标记循环，从而可以使用 “break” 语句中断指定的循环。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:3:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"3.下面代码输出正确的是？ func main() { i := 1 s := []string{\"A\", \"B\", \"C\"} i, s[i-1] = 2, \"Z\" fmt.Printf(\"s: %v \\n\", s) } A. s: [Z,B,C] B. s: [A,Z,C] 参考答案及解析：A。知识点：多重赋值。 多重赋值分为两个步骤，有先后顺序： 计算等号左边的索引表达式和取址表达式，接着计算等号右边的表达式； 赋值； 所以本例，会先计算 s[i-1]，等号右边是两个表达式是常量，所以赋值运算等同于 i, s[0] = 2, “Z”。 在Go语言中，i, j = j, i 是一种用于交换两个变量的常见技巧，通常称为元组赋值或平行赋值（Tuple Assignment）。 该语法的原理是同时进行多个变量的赋值操作，并且右边的表达式会在赋值之前进行求值。在这种情况下，右边的表达式 j, i 是一个元组（tuple），它包含两个值，分别是变量 j 和 i 的当前值。 具体的执行过程如下： 首先，将元组 (j, i) 中的值读取出来。 接着，将右边元组中的第一个值 j 赋给左边的第一个变量 i。 最后，将右边元组中的第二个值 i 赋给左边的第二个变量 j。 这样就实现了变量 i 和 j 之间的值交换。 这种交换技巧的优势是在不需要引入额外的临时变量的情况下，完成了两个变量的交换操作。在某些情况下，这可以提高代码的可读性和简洁性。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:3:3","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day34 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:4:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.关于类型转化，下面选项正确的是？ A. type MyInt int var i int = 1 var j MyInt = i B. type MyInt int var i int = 1 var j MyInt = (MyInt)i C. type MyInt int var i int = 1 var j MyInt = MyInt(i) D. type MyInt int var i int = 1 var j MyInt = i.(MyInt) 参考答案及解析：C。知识点：强制类型转化。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:4:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.关于switch语句，下面说法正确的有？ A. 条件表达式必须为常量或者整数； B. 单个case中，可以出现多个结果选项； C. 需要用break来明确退出一个case； D. 只有在case中明确添加fallthrough关键字，才会继续执行紧跟的下一个case； 参考答案及解析：BD。 switch i { case 0: fmt.Printf(\"0\") case 1: fmt.Printf(\"1\") case 2: fallthrough case 3: fmt.Printf(\"3\") // 单个case中，可以出现多个结果选项 case 4, 5, 6: fmt.Printf(\"4, 5, 6\") default: fmt.Printf(\"Default\") } switch后面的表达式甚至不是必需的 switch { case 0 \u003c= Num \u0026\u0026 Num \u003c= 3: fmt.Printf(\"0-3\") case 4 \u003c= Num \u0026\u0026 Num \u003c= 6: fmt.Printf(\"4-6\") case 7 \u003c= Num \u0026\u0026 Num \u003c= 9: fmt.Printf(\"7-9\") } 总结： 左花括号{必须与switch处于同一行； 条件表达式不限制为常量或者整数； 单个case中，可以出现多个结果选项； 与C语言等规则相反，Go语言不需要用break来明确退出一个case； 只有在case中明确添加fallthrough关键字，才会继续执行紧跟的下一个case； 可以不设定switch之后的条件表达式，在此种情况下，整个switch结构与多个if…else…的逻辑作用等同。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:4:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"3.如果Add()函数的调用代码为： func main() { var a Integer = 1 var b Integer = 2 var i interface{} = \u0026a sum := i.(*Integer).Add(b) fmt.Println(sum) } 则Add函数定义正确的是() A. type Integer int func (a Integer) Add(b Integer) Integer { return a + b } B. type Integer int func (a Integer) Add(b *Integer) Integer { return a + *b } C. type Integer int func (a *Integer) Add(b Integer) Integer { return *a + b } D. type Integer int func (a *Integer) Add(b *Integer) Integer { return *a + *b } 参考答案及解析：AC。知识点：类型断言、方法集。（查书再看看） go 中有些的变量不可以寻址，指的是不能通过\u0026获得其地址。 所以 func( *A ) 只能接收 *A, func( A ) 可以接收 A 或者 *A ,通过指针一定能得到变量的值 *A -\u003e A 还比如 map 里面 的 value 也是不可寻地址的，因为 map 扩容后，value 地址就会改变。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:4:3","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day35 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:5:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.关于bool变量b的赋值，下面错误的用法是？ A. b = true B. b = 1 C. b = bool(1) D. b = (1 == 2) 参考答案及解析：BC。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:5:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.关于变量的自增和自减操作，下面语句正确的是？ A. i := 1 i++ B. i := 1 j = i++ C. i := 1 ++i D. i := 1 i-- 参考答案及解析：AD。知识点：自增自减操作。i++ 和 i– 在 Go 语言中是语句，不是表达式，因此不能赋值给另外的变量。此外没有 ++i 和–i。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:5:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"3.关于GetPodAction定义，下面赋值正确的是 type Fragment interface { Exec(transInfo *TransInfo) error } type GetPodAction struct { } func (g GetPodAction) Exec(transInfo *TransInfo) error { ... return nil } A. var fragment Fragment = new(GetPodAction) B. var fragment Fragment = GetPodAction C. var fragment Fragment = \u0026GetPodAction{} D. var fragment Fragment = GetPodAction{} 参考答案及解析：ACD。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:5:3","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day36 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:6:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.关于函数声明，下面语法正确的是？ A. func f(a, b int) (value int, err error) B. func f(a int, b int) (value int, err error) C. func f(a, b int) (value int, error) D. func f(a int, b int) (int, int, error) 参考答案及解析：ABD。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:6:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.关于整型切片的初始化，下面正确的是？ A. s := make([]int) B. s := make([]int, 0) C. s := make([]int, 5, 10) D. s := []int{1, 2, 3, 4, 5} 参考答案及解析：BCD ","date":"2023-06-19","objectID":"/posts/go/day31-40/:6:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"3.下面代码会触发异常吗？请说明。 func main() { runtime.GOMAXPROCS(1) int_chan := make(chan int, 1) string_chan := make(chan string, 1) int_chan \u003c- 1 string_chan \u003c- \"hello\" select { case value := \u003c-int_chan: fmt.Println(value) case value := \u003c-string_chan: panic(value) } } 参考答案及解析：select 会随机选择一个可用通道做收发操作，所以可能触发异常，也可能不会。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:6:3","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day37 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:7:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.关于channel的特性，下面说法正确的是？ A. 给一个 nil channel 发送数据，造成永远阻塞 B. 从一个 nil channel 接收数据，造成永远阻塞 C. 给一个已经关闭的 channel 发送数据，引起 panic D. 从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零值 参考答案及解析：ABCD。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:7:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.下面代码有什么问题？ const i = 100 var j = 123 func main() { fmt.Println(\u0026j, j) fmt.Println(\u0026i, i) } 参考答案及解析：编译报错cannot take the address of i。知识点：常量。常量不同于变量的在运行期分配内存，常量通常会被编译器在预处理阶段直接展开，作为指令数据使用，所以常量无法寻址。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:7:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"3.下面代码能否编译通过？如果通过，输出什么？ func GetValue(m map[int]string, id int) (string, bool) { if _, exist := m[id]; exist { return \"exist\", true } return nil, false } func main() { intmap := map[int]string{ 1: \"a\", 2: \"b\", 3: \"c\", } v, err := GetValue(intmap, 3) fmt.Println(v, err) } 参考答案及解析：不能通过编译。知识点：函数返回值类型。nil 可以用作 interface、function、pointer、map、slice 和 channel 的“空值”。但是如果不特别指定的话，Go 语言不能识别类型，所以会报错:cannot use nil as type string in return argument. ","date":"2023-06-19","objectID":"/posts/go/day31-40/:7:3","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day38 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:8:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.关于无缓冲和有缓冲的channel，下面说法正确的是？ A. 无缓冲的channel是默认的缓冲为1的channel； B. 无缓冲的channel和有缓冲的channel都是同步的； C. 无缓冲的channel和有缓冲的channel都是非同步的； D. 无缓冲的channel是同步的，而有缓冲的channel是非同步的； 参考答案及解析：D。 无缓冲是同步的，例如 make(chan int)，就是一个送信人去你家门口送信，你不在家他不走，你一定要接下信，他才会走，无缓冲保证信能到你手上。 有缓冲是异步的，例如 make(chan int, 1)，就是一个送信人去你家仍到你家的信箱，转身就走，除非你的信箱满了，他必须等信箱空下来，有缓冲的保证信能进你家的邮箱。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:8:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.下面代码是否能编译通过？如果通过，输出什么？ func Foo(x interface{}) { if x == nil { fmt.Println(\"empty interface\") return } fmt.Println(\"non-empty interface\") } func main() { var x *int = nil Foo(x) } 参考答案及解析：non-empty interface 考点：interface 的内部结构，我们知道接口除了有静态类型，还有动态类型和动态值，当且仅当动态值和动态类型都为 nil 时，接口类型值才为 nil。这里的 x 的动态类型是 *int，所以 x 不为 nil。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:8:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"3.下面代码输出什么？ func main() { ch := make(chan int, 100) // A go func() { for i := 0; i \u003c 10; i++ { ch \u003c- i } }() // B go func() { for { a, ok := \u003c-ch if !ok { fmt.Println(\"close\") return } fmt.Println(\"a: \", a) } }() close(ch) fmt.Println(\"ok\") time.Sleep(time.Second * 10) } 参考答案及解析：程序抛异常。先定义下，第一个协程为 A 协程，第二个协程为 B 协程；当 A 协程还没起时，主协程已经将 channel 关闭了，当 A 协程往关闭的 channel 发送数据时会 panic，panic: send on closed channel。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:8:3","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day39 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:9:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.关于异常的触发，下面说法正确的是？ A. 空指针解析； B. 下标越界； C. 除数为0； D. 调用panic函数； 参考答案及解析：ABCD。 当指针变量没有指向时，也就是为 nil 时，不能对 *point 就行赋值操作，否则会报空指针异常。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:9:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ func main() { x := []string{\"a\", \"b\", \"c\"} for v := range x { fmt.Print(v) } } 参考答案及解析：012。注意区别下面代码段： func main() { x := []string{\"a\", \"b\", \"c\"} for _, v := range x { fmt.Print(v) //输出 abc } } ","date":"2023-06-19","objectID":"/posts/go/day31-40/:9:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"3.下面这段代码能否编译通过？如果通过，输出什么？ type User struct{} type User1 User // User1 是一种新的类型 type User2 = User // User2 是User的别名 完全等价于User func (i User1) m1() { fmt.Println(\"m1\") } func (i User) m2() { fmt.Println(\"m2\") } func main() { var i1 User1 var i2 User2 i1.m1() i2.m2() } 参考答案及解析：能，输出m1 m2，第 2 行代码基于类型 User 创建了新类型 User1，第 3 行代码是创建了 User 的类型别名 User2，注意使用 = 定义类型别名。因为 User2 是别名，完全等价于 User，所以 User2 具有 User 所有的方法。但是 i1.m2() 是不能执行的，因为 User1 没有定义该方法。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:9:3","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day40 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:10:0","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"1.关于select机制，下面说法正确的是? A. select机制用来处理异步IO问题； B. select机制最大的一条限制就是每个case语句里必须是一个IO操作； C. golang在语言级别支持select关键字； D. select关键字的用法与switch语句非常类似，后面要带判断条件； 参考答案及解析：ABC。 ","date":"2023-06-19","objectID":"/posts/go/day31-40/:10:1","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"2.下面的代码有什么问题？ func Stop(stop \u003c-chan bool) { close(stop) } 参考答案及解析：有方向的 channel 不可以被关闭。 单向channel变量的声明非常简单，如下： var ch1 chan int // ch1是一个正常的channel，不是单向的 var ch2 chan\u003c- float64 // ch2是单向channel，只用于写float64数据 var ch3 \u003c-chan int // ch3是单向channel，只用于读取int数据 chan\u003c- 表示数据进入管道，要把数据写进管道，对于调用者就是输出。 \u003c-chan 表示数据从管道出来，对于调用者就是得到管道的数据，当然就是输入。 可以将 channel 隐式转换为单向队列，只收或只发，不能将单向 channel 转换为普通 channel： c := make(chan int, 3) var send chan\u003c- int = c // send-only var recv \u003c-chan int = c // receive-only send \u003c- 1 //\u003c-send //invalid operation: \u003c-send (receive from send-only type chan\u003c- int) \u003c-recv //recv \u003c- 2 //invalid operation: recv \u003c- 2 (send to receive-only type \u003c-chan int) //不能将单向 channel 转换为普通 channel d1 := (chan int)(send) //cannot convert send (type chan\u003c- int) to type chan int d2 := (chan int)(recv) //cannot convert recv (type \u003c-chan int) to type chan int ","date":"2023-06-19","objectID":"/posts/go/day31-40/:10:2","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"3.下面这段代码存在什么问题？ type Param map[string]interface{} type Show struct { *Param } func main() { s := new(Show) s.Param[\"day\"] = 2 } 参考答案及解析：存在两个问题：1.map 需要初始化才能使用；2.指针不支持索引。修复代码如下： func main() { s := new(Show) // 修复代码 p := make(Param) p[\"day\"] = 2 s.Param = \u0026p tmp := *s.Param fmt.Println(tmp[\"day\"]) } ","date":"2023-06-19","objectID":"/posts/go/day31-40/:10:3","tags":["go","面试"],"title":"Go Exercises(Day31-40)","uri":"/posts/go/day31-40/"},{"categories":["Go每日一练"],"content":"Day41 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:1:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.下面代码编译能通过吗？ func main() { fmt.Println(\"hello world\") } 参考答案及解析：编译错误。 syntax error: unexpected semicolon or newline before { Go 语言中，大括号不能放在单独的一行。 正确的代码如下： func main(){ fmt.Println(\"hello world\") } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:1:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ var x = []int{2: 2, 3, 0: 1} func main() { fmt.Println(x) } 参考答案及解析：输出[1 0 2 3]，字面量初始化切片时候，可以指定索引，没有指定索引的元素会在前一个索引基础之上加一，所以输出[1 0 2 3]，而不是[1 3 2]。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:1:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"3.下面这段代码输出什么？ func incr(p *int) int { *p++ return *p } func main() { v := 1 incr(\u0026v) fmt.Println(v) } 参考答案及解析：2。知识点：指针。p 是指针变量，指向变量 v，*p++操作的意思是取出变量 v 的值并执行加一操作，所以 v 的最终值是 2。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:1:3","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day42 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:2:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.请指出下面代码的错误？ package main var gvar int func main() { var one int two := 2 var three int three = 3 func(unused string) { fmt.Println(\"Unused arg. No compile error\") }(\"what?\") } 参考答案及解析：变量 one、two 和 three 声明未使用。知识点：未使用变量。如果有未使用的变量代码将编译失败。但也有例外，函数中声明的变量必须要使用，但可以有未使用的全局变量。函数的参数未使用也是可以的。 如果你给未使用的变量分配了一个新值，代码也还是会编译失败。你需要在某个地方使用这个变量，才能让编译器愉快的编译。 修复代码： func main() { var one int _ = one two := 2 fmt.Println(two) var three int three = 3 one = three var four int four = four } 另一个选择是注释掉或者移除未使用的变量 。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:2:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ type ConfigOne struct { Daemon string } func (c *ConfigOne) String() string { return fmt.Sprintf(\"print: %v\", c) } func main() { c := \u0026ConfigOne{} c.String() } 参考答案及解析：运行时错误。如果类型实现 String() 方法，当格式化输出时会自动使用 String() 方法。上面这段代码是在该类型的 String() 方法内使用格式化输出，导致递归调用，最后抛错。 runtime: goroutine stack exceeds 1000000000-byte limit fatal error: stack overflow 3.下面代码输出什么？ func main() { var a = []int{1, 2, 3, 4, 5} var r = make([]int, 0) for i, v := range a { if i == 0 { a = append(a, 6, 7) } r = append(r, v) } fmt.Println(r) } 参考答案及解析：[1 2 3 4 5]。a 在 for range 过程中增加了两个元素 ，len 由 5 增加到 7，但 for range 时会使用 a 的副本 a’ 参与循环，副本的 len 依旧是 5，因此 for range 只会循环 5 次，也就只获取 a 对应的底层数组的前 5 个元素。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:2:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day43 1.下面的代码有什么问题？ import ( \"fmt\" \"log\" \"time\" ) func main() { } 参考答案及解析：导入的包没有被使用。如果引入一个包，但是未使用其中如何函数、接口、结构体或变量的话，代码将编译失败。 如果你真的需要引入包，可以使用下划线操作符，_，来作为这个包的名字，从而避免失败。下划线操作符用于引入，但不使用。 我们还可以注释或者移除未使用的包。 修复代码： import ( _ \"fmt\" \"log\" \"time\" ) var _ = log.Println func main() { _ = time.Now } 2.下面代码输出什么？ func main() { x := interface{}(nil) y := (*int)(nil) a := y == x b := y == nil _, c := x.(interface{}) println(a, b, c) } A. true true false B. false true true C. true true true D. false true false 参考答案及解析：D。知识点：类型断言。类型断言语法：i.(Type)，其中 i 是接口，Type 是类型或接口。编译时会自动检测 i 的动态类型与 Type 是否一致。但是，如果动态类型不存在，则断言总是失败。 3.下面代码有几处错误的地方？请说明原因。 func main() { var s []int s = append(s,1) var m map[string]int m[\"one\"] = 1 } 参考答案及解析：有 1 个错误，不能对 nil 的 map 直接赋值，需要使用 make() 初始化。但可以使用 append() 函数对为 nil 的 slice 增加元素。 修复代码： func main() { var m map[string]int m = make(map[string]int) m[\"one\"] = 1 } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:3:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day44 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:4:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.下面代码有什么问题？ func main() { m := make(map[string]int,2) cap(m) } 参考答案及解析：问题：使用 cap() 获取 map 的容量。1.使用 make 创建 map 变量时可以指定第二个参数，不过会被忽略。2**.cap() 函数适用于数组、数组指针、slice 和 channel，不适用于 map，可以使用 len() 返回 map 的元素个数**。 2.下面的代码有什么问题？ func main() { var x = nil _ = x } 参考答案及解析：nil 用于表示 interface、函数、maps、slices 和 channels 的“零值”。如果不指定变量的类型，编译器猜不出变量的具体类型，导致编译错误。 修复代码： func main() { var x interface{} = nil _ = x } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:4:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"3.下面代码能编译通过吗？ type info struct { result int } func work() (int,error) { return 13,nil } func main() { var data info data.result, err := work() fmt.Printf(\"info: %+v\\n\",data) } 参考答案及解析：编译失败。 non-name data.result on left side of := 不能使用短变量声明设置结构体字段值，修复代码： func main() { var data info var err error data.result, err = work() //ok if err != nil { fmt.Println(err) return } fmt.Println(data) } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:4:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day45 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:5:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.下面代码有什么错误？ func main() { one := 0 one := 1 } 参考答案及解析：变量重复声明。不能在单独的声明中重复声明一个变量，但在多变量声明的时候是可以的，但必须保证至少有一个变量是新声明的。 修复代码： func main() { one := 0 one, two := 1,2 one,two = two,one } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:5:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"2.下面代码有什么问题？ func main() { x := []int{ 1, 2 } _ = x } 参考答案及解析：编译错误，第四行代码没有逗号。用字面量初始化数组、slice 和 map 时，最好是在每个元素后面加上逗号，即使是声明在一行或者多行都不会出错。 修复代码： func main() { x := []int{ // 多行 1, 2, } x = x y := []int{3,4,} // 一行 no error y = y } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:5:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"3.下面代码输出什么？ func test(x byte) { fmt.Println(x) } func main() { var a byte = 0x11 var b uint8 = a var c uint8 = a + b test(c) } 参考答案及解析：34。与 rune 是 int32 的别名一样，byte 是 uint8 的别名，别名类型无序转换，可直接转换。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:6:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day46 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:7:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.下面的代码有什么问题？ func main() { const x = 123 const y = 1.23 fmt.Println(x) } 参考答案及解析：编译可以通过。知识点：常量。常量是一个简单值的标识符，在程序运行时，不会被修改的量。不像变量，常量未使用是能编译通过的。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:7:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ const ( x uint16 = 120 y s = \"abc\" z ) func main() { fmt.Printf(\"%T %v\\n\", y, y) fmt.Printf(\"%T %v\\n\", z, z) } 参考答案及解析：知识点：常量。 输出： uint16 120 string abc 常量组中如不指定类型和初始化值，则与上一行非空常量右值相同 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:7:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"3.下面代码有什么问题？ func main() { var x string = nil if x == nil { x = \"default\" } } 参考答案及解析：将 nil 分配给 string 类型的变量。这是个大多数新手会犯的错误。修复代码： func main() { var x string //defaults to \"\" (zero value) if x == \"\" { x = \"default\" } } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:7:3","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day47 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:8:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.下面的代码有什么问题？ func main() { data := []int{1,2,3} i := 0 ++i fmt.Println(data[i++]) } 参考答案及解析：对于自增、自减，需要注意： 自增、自减不在是运算符，只能作为独立语句，而不是表达式； 不像其他语言，Go 语言中不支持 ++i 和 –i 操作； 表达式通常是求值代码，可作为右值或参数使用。而语句表示完成一个任务，比如 if、for 语句等。表达式可作为语句使用，但语句不能当做表达式。 修复代码： func main() { data := []int{1,2,3} i := 0 i++ fmt.Println(data[i]) } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:8:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"2.下面代码最后一行输出什么？请说明原因。 func main() { x := 1 fmt.Println(x) { fmt.Println(x) i,x := 2,2 fmt.Println(i,x) } fmt.Println(x) // print ? } 参考答案及解析：输出1。知识点：变量隐藏。使用变量简短声明符号 := 时，如果符号左边有多个变量，只需要保证至少有一个变量是新声明的，并对已定义的变量尽进行赋值操作。但如果出现作用域之后，就会导致变量隐藏的问题，就像这个例子一样。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:8:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day48 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:9:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.下面代码有什么问题？ type foo struct { bar int } func main() { var f foo f.bar, tmp := 1, 2 } 参考答案及解析：编译错误： non-name f.bar on left side of := := 操作符不能用于结构体字段赋值。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:9:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"2.下面的代码输出什么？ func main() { fmt.Println(~2) } 参考答案及解析：编译错误。 invalid character U+007E '~' 很多语言都是采用 ~ 作为按位取反运算符，Go 里面采用的是 ^ 。**按位取反之后返回一个每个 bit 位都取反的数，对于有符号的整数来说，是按照补码进行取反操作的（快速计算方法：对数 a 取反，结果为 -(a+1) ），对于无符号整数来说就是按位取反。**例如： func main() { var a int8 = 3 var b uint8 = 3 var c int8 = -3 fmt.Printf(\"^%b=%b %d\\n\", a, ^a, ^a) // ^11=-100 -4 fmt.Printf(\"^%b=%b %d\\n\", b, ^b, ^b) // ^11=11111100 252 fmt.Printf(\"^%b=%b %d\\n\", c, ^c, ^c) // ^-11=10 2 } 另外需要注意的是，**如果作为二元运算符，^ 表示按位异或，即：对应位相同为 0，相异为 1。**例如： func main() { var a int8 = 3 var c int8 = 5 fmt.Printf(\"a: %08b\\n\",a) fmt.Printf(\"c: %08b\\n\",c) fmt.Printf(\"a^c: %08b\\n\",a ^ c) } 给大家重点介绍下这个操作符 \u0026^，按位置零，例如：z = x \u0026^ y，表示如果 y 中的 bit 位为 1，则 z 对应 bit 位为 0，否则 z 对应 bit 位等于 x 中相应的 bit 位的值。 不知道大家发现没有，我们还可以这样理解或操作符**| ，表达式 z = x | y，如果 y 中的 bit 位为 1，则 z 对应 bit 位为 1，否则 z 对应 bit 位等于 x 中相应的 bit 位的值，与 \u0026^ 完全相反。** var x uint8 = 214 var y uint8 = 92 fmt.Printf(\"x: %08b\\n\",x) fmt.Printf(\"y: %08b\\n\",y) fmt.Printf(\"x | y: %08b\\n\",x | y) fmt.Printf(\"x \u0026^ y: %08b\\n\",x \u0026^ y) 输出： x: 11010110 y: 01011100 x | y: 11011110 x \u0026^ y: 10000010 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:9:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day49 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:10:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.下面代码输出什么？ func main() { var ch chan int select { case v, ok := \u003c-ch: println(v, ok) default: println(\"default\") } } 参考答案及解析：default。ch 为 nil，读写都会阻塞。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:10:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ type People struct { name string `json:\"name\"` } func main() { js := `{ \"name\":\"seekload\" }` var p People err := json.Unmarshal([]byte(js), \u0026p) if err != nil { fmt.Println(\"err: \", err) return } fmt.Println(p) } 参考答案及解析：输出 {}。知识点：结构体访问控制，因为 name 首字母是小写，导致其他包不能访问，所以输出为空结构体。修复代码： type People struct { Name string `json:\"name\"` } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:10:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"Day50 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:11:0","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？ type T struct { ls []int } func foo(t T) { t.ls[0] = 100 } func main() { var t = T{ ls: []int{1, 2, 3}, } foo(t) fmt.Println(t.ls[0]) } A. 1 B. 100 C. compilation error 参考答案及解析：B。调用 foo() 函数时虽然是传值，但 foo() 函数中，字段 ls 依旧可以看成是指向底层数组的指针。 ","date":"2023-06-19","objectID":"/posts/go/day41-50/:11:1","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ func main() { isMatch := func(i int) bool { switch(i) { case 1: case 2: return true } return false } fmt.Println(isMatch(1)) fmt.Println(isMatch(2)) } 参考答案及解析：false true。Go 语言的 switch 语句虽然没有”break”，但如果 case 完成程序会默认 break，可以在 case 语句后面加上关键字 fallthrough，这样就会接着走下一个 case 语句（不用匹配后续条件表达式）。或者，利用 case 可以匹配多个值的特性。 修复代码： func main() { isMatch := func(i int) bool { switch(i) { case 1: fallthrough case 2: return true } return false } fmt.Println(isMatch(1)) // true fmt.Println(isMatch(2)) // true match := func(i int) bool { switch(i) { case 1,2: return true } return false } fmt.Println(match(1)) // true fmt.Println(match(2)) // true } ","date":"2023-06-19","objectID":"/posts/go/day41-50/:11:2","tags":["go","面试"],"title":"Go Exercises(Day41-50)","uri":"/posts/go/day41-50/"},{"categories":["对抗攻击"],"content":"对抗攻击 Benign Image 原始图片 Attacked Image 加入杂讯后的图片 通常我们加的杂讯、噪音都应该非常小、人的肉眼是看不出来的，下图中加入的杂讯就有点过分了。 对抗攻击分为两类： Non-targeted 没有目标的攻击（如上图中，只要识别出来不是猫就行） Targeted 有目标的攻击、定向攻击 （被识别出一个确定的其他类别） 下图展示了使用ResNet-50作为backbone，识别图片，原始图片识别为Tiger Cat，定向攻击后识别为Star Fish。 下图展示了，被攻击后的图片和未被攻击的图片果然是不一样的，只是人眼看不出来，但是却对网络的识别结果产生了影响。 同样的，如果我们给原始图片加入了其他杂讯，还能定向攻击该图片，使网络识别出其为键盘。 和我们直观的理解不一样的一点是，上面的例子中加入的杂讯是肉眼看不出来的，并看不出图片由多大的改变，而相反的如下图所示，在图片中加入了肉眼可见的明显的杂讯，网络反而还能识别出这是一直猫，直到杂讯大到离谱了，识别成其他东西了。 接下来看看到底是怎么进行攻击的。 非定向攻击：我们希望找到一个x，使得L(x)越小越好，L(x)是带负号的，所以就是说y和y尖越大，即距离越远，达到了攻击的目的。 定向攻击：我们还需要考虑让y和y target越近越好。 除此之外，如下图框出的，我们还需要让x和x0越接近越好，即d(x0,x)≤ε，x和x0之间的距离在一定阈值之内，这个阈值指的就是不被人类所能察觉到的一个范围。 接下来是两种计算d(x0,x)的方式，即计算两张图片之间距离的方法。 对于上面的箭头是对每个pixel进行了一点点的改变，而下面的箭头是只有对绿色部分进行了很多的改变，在计算两种距离后我们发现，两种改变后的图片与原始图片计算距离，L2-norm是一样的，而L-infinity相差的就明显了，可见L-infinity更符合我们人类的认知，因为我们可以明显的发现下面的图片改动的要比上面的大。如果我们做的是其他领域的，比如研究两个声音相近的程度，就需要考虑其他的因素了。 接下来我们就找这样一个x，最小化损失函数，接下来介绍方法。 我们先不考虑d(x0,x)≤ε这样的条件，其实可以发现，这和我们之前学的训练一个分类网络的model是一样的，也是利用梯度下降的方法，只不过这里面我们更新的不是网络的参数了，而是更新输入图片。 那如果我们再考虑上d(x0,x)≤ε的限制呢？在梯度下降的时候做一个判断，如果超出这个范围了，那么就给他拉回来，选择一个最近的位置。 对抗攻击的方法有很多，大体都是基于此公式，有的是选择不同的优化方法，有的是采用不同的约束条件，但是使用的都是梯度下降。 介绍几种攻击方法 FGSM（Fast Gradient Sign Method） https://arxiv.org/abs/1412.6572 只迭代一次，对于g也做了特别的设计，取一个sign，这样g就只能是+-1，同时学习率就取ε，这样就能保证x0和x的距离就在ε之内，即在正方形的4个点上。 I-FGSM https://arxiv.org/abs/1607.02533 当然也有迭代的版本，那么就和之前一样了，跑出去的话需要拉回来。 以上的内容都是白盒攻击，接下来具体的介绍一下白盒攻击与黑盒攻击。 白盒攻击：知道模型的参数。 黑盒攻击：不知道模型的参数。 我们之前讲的攻击，需要计算梯度，所以这一定是需要知道模型的参数的，所以属于白盒攻击，那么黑盒攻击是怎么做到的呢？ 如果我们知道某一个网络训练所使用的数据集，我们拿这个数据集再训练一个Proxy网络，那么也行有可能，在Proxy网络上训练处的攻击后的图片也能对未知参数的模型产生攻击效果。 那如果我们连数据集都不知道怎么办呢？ 我们在未知模型上传进去输入，得到输出，拿这样成对的数据当做数据集去训练Proxy网络。 下图展示了黑箱攻击的一个成功率，对角线上被攻击的模型和Proxy模型是一样的就是属于白盒攻击了。（低的正确率就代表攻击的成功率高）黑箱攻击中非定向的攻击相较于定向攻击更容易成功一些。 那怎么增加黑盒攻击的成功率呢，见下图。下图中非对角线的部分是白盒攻击，对角线部分是黑盒攻击，即我们要攻击ResNet-152，但是我们并没有使用ResNet-152……我们发现如果我们找到了一个attacked image可以成功骗过多个模型的时候，骗过一个黑箱network也比较容易成功。 那么为什么攻击会这么容易成功呢？ 以一个小丑鱼为例（第一个图中的圆点表示小丑鱼），图中深蓝色的区域表示能识别成为小丑鱼的范围，超出了这个范围就识别不成功，可以发现对于每个网络都有相同的趋势，在x方向上移动会攻击成功，在y方向上移动会攻击失败。Adversarial Examples Are Not Bugs，They Are Features。（https://arxiv.org/abs/1905.02175）攻击成功的原因来自于data，而不是来自于模型。 介绍其他几种攻击 One pixel attack https://arxiv.org/abs/1710.08864 通过改变一个pixel就可以达到攻击的效果。 Universal Acersarial Attack https://arxiv.org/abs/1610.08401 之前的扰动是每一张图片添加的扰动是不一样的，客制化的，而Universal Acersarial Attack是说对好多图片添加的是同样的一种扰动。 除了图片、也有语音和nlp方向的攻击。 车牌、现实世界、多角度。 BackDoor Attack 后门攻击 https://arxiv.org/abs/1804.00792 在训练的阶段就展开攻击，在训练集中加入了特殊的图片。（之前的攻击是测试的时候攻击。） ","date":"2023-06-18","objectID":"/posts/dl/aa/lesson1/:1:0","tags":["深度学习","对抗攻击"],"title":"对抗攻击学习笔记（李宏毅）","uri":"/posts/dl/aa/lesson1/"},{"categories":["对抗攻击"],"content":"对抗防御 ","date":"2023-06-18","objectID":"/posts/dl/aa/lesson1/:2:0","tags":["深度学习","对抗攻击"],"title":"对抗攻击学习笔记（李宏毅）","uri":"/posts/dl/aa/lesson1/"},{"categories":["对抗攻击"],"content":"被动防御 1.在模型前面加一个Filter，这个Filter比如一个smoothing模糊化就可以做到。 但是这个smoothing也不能太过头，比如下图中第二行的例子，会把本来识别正确的图片的识别准确率拉低。 2.图像压缩（先压缩再解压避开攻击） https://arxiv.org/abs/1704.01155 https://arxiv.org/abs/1802.06816 3.基于Generator的方法 https://arxiv.org/abs/1805.06605 把输入的图片用生成器重新产生一下。 4.随机的防御 https://arxiv.org/abs/1711.01991 加入不同的防御的方式，我们自己都不知道一张图片传进网络后会怎么进行防御。 ","date":"2023-06-18","objectID":"/posts/dl/aa/lesson1/:2:1","tags":["深度学习","对抗攻击"],"title":"对抗攻击学习笔记（李宏毅）","uri":"/posts/dl/aa/lesson1/"},{"categories":["对抗攻击"],"content":"主动防御 训练模型的时候，就训练一个鲁邦的模型，不易被攻击的模型。 方法是训练的输入x1……xn都进行攻击，然后把被攻击后的图片也重新的正确打上label，这样就有了新的数据集X’，在丢进模型中进行训练。这种方法也属于数据增强。但是这种方法也有很多缺点，比如浪费计算资源（Adversarial Training for Free 解决了这个问题 https://arxiv.org/abs/1904.12843），或者无法适应新算法的攻击。 ","date":"2023-06-18","objectID":"/posts/dl/aa/lesson1/:2:2","tags":["深度学习","对抗攻击"],"title":"对抗攻击学习笔记（李宏毅）","uri":"/posts/dl/aa/lesson1/"},{"categories":["项目"],"content":"2023.07.01 互联网架构演进之路：单体架构–\u003e垂直架构–\u003eSOA架构–\u003e微服务架构 SOA这种是一个代码跑的，只是分一下层。 微服务是一个功能就是一个进程进行拆分。 微服务架构优势 快：更注重敏捷开发、持续交付 准：服务粒度小、服务质量精准可控 狠：使用与互联网时代，产品迭代周期更短 微服务架构带来的挑战： 分布式系统的复杂性 服务依赖管理 数据的一致性保障 测试更加艰难 对DevOps等基础设施的高要求 ","date":"2023-06-11","objectID":"/posts/projects/pro04/:1:0","tags":["项目","微服务","云原生"],"title":"微服务","uri":"/posts/projects/pro04/"},{"categories":["项目"],"content":"2023.07.02 RPC ","date":"2023-06-11","objectID":"/posts/projects/pro04/:2:0","tags":["项目","微服务","云原生"],"title":"微服务","uri":"/posts/projects/pro04/"},{"categories":["项目"],"content":"2023.07.03 ​ ","date":"2023-06-11","objectID":"/posts/projects/pro04/:3:0","tags":["项目","微服务","云原生"],"title":"微服务","uri":"/posts/projects/pro04/"},{"categories":["项目"],"content":"fiber react ","date":"2023-06-11","objectID":"/posts/projects/pro02/:0:0","tags":["项目","fiber","go web"],"title":"储算分离系统","uri":"/posts/projects/pro02/"},{"categories":["项目"],"content":"Unity3D，c#，想法比较好，落地应用，论文，软著，国家优秀结题。 论文：家畜解剖学三维互动APP的开发研究 软著：软著 app：3D家畜解剖 演示视频：3D家畜解剖 项目证书：国家优秀 项目源码：unfinded ","date":"2023-06-11","objectID":"/posts/projects/pro01/:0:0","tags":["项目"],"title":"U3D家畜解剖app","uri":"/posts/projects/pro01/"},{"categories":["gin"],"content":"分布式ID生成器 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:1:0","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"分布式ID的特点 全局唯一性：不能出现有重复的ID标识，这是基本要求。 递增性：确保生成ID对于用户或业务是递增的。 高可用性：确保任何时候都能生成正确的ID。 高性能性：在高并发的环境下依然表现良好。 不仅仅适用于用户ID，实际互联网中有很多场景需要能够生成类似MySQL自增ID这样不断增大，同时又不会重复的id。以支持业务中的高并发场景。 比较典型的场景有：电商促销时短时间内会有大量的订单涌入到系统，比如每秒10w+；明星出轨时微博短时间内会产生大量的相关微博转发和评论消息。在这些业务场景下将数据插入数据库之前，我们需要给这些订单和消息先分配一个唯一-ID， 然后再保存到数据库中。对这个id的要求是希望其中能带有一 些时间信息，这样即使我们后端的系统对消息进行了分库分表，也能够以时间顺序对这些消息进行排序。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:1:1","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"雪花算法（snowflake） 雪花算法，它是Twitter开源的由64位整数组成分布式ID，性能较高，并且在单机上递增。 第一位占用1bit，其值始终是0，没有实际作用。 时间戳占用41bit，单位为毫秒，总共可以容纳约69年的时间。当然，我们的时间毫秒计数不会真的从1970年开始记，那样我们的系统跑到2039/9/7 23:47:35 就不能用了，所以这里的时间戳只是相对于某个时间的增量，比如我们的系统上线是2020-07-01，那么我们完全可以把这个timestamp当作是从2020-07-01 00:00:00. 000的偏移量。 工作机器id占用10bit，其中高位5bit是数据中心ID，低位5bit是工作节点ID,最多可以容纳1024个节点。 序列号占用12bit，用来记录同毫秒内产生的不同id。每个节点每毫秒0开始不断累加，最多可以累加到4095，同一毫秒一共可以产生4096个ID。 SnowFlake算法在同一毫秒内最多可以生成1024*4096=4194304个全局唯一ID。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:1:2","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"SnowFlake的Go实现 1.https://github.com/bwmarrin/snowflake 这是一个相当轻量化的snowflake的Go实现。 package main import ( \"fmt\" \"github.com/bwmarrin/snowflake\" \"time\" ) var node *snowflake.Node func Init(startTime string, machineID int64) (err error) { var st time.Time st, err = time.Parse(\"2006-01-02\", startTime) if err != nil { return } snowflake.Epoch = st.UnixNano() / 1000000 node, err = snowflake.NewNode(machineID) return } func GenID() int64 { return node.Generate().Int64() } func main() { if err := Init(\"2020-07-01\", 1); err != nil { fmt.Printf(\"init failed, err:%v\\n\", err) return } id := GenID() fmt.Println(id) } 2.https://github.com/sony/sonyflake sonyflake是Sony公司的一个开源项目，基本思路和snowflake差不多，不过位分配上稍有不同： 这里的时间只用了了39个bit，但时间的单位变成了10ms，所以理论上比41位表示的时间还要久(174年)。Sequence ID 和之前的定义一致， Machine ID 其实就是节点id。 sonyflake 库有以下配置参数： type Settings struct { StartTime time.Time MachineID func() (uint16, error) CheckMachineID func(uint16) bool } 其中： StartTime 选项和我们之前的 Epoch 差不不多，如果不设置的话，默认是从 2014-09-0100:00:00 +0000 UTC 开始。 MachineID 可以由用户自定义的函数，如果用户不定义的话，会默认将本机IP的低16位作为 machine id 。 CheckMachineID 是由用户提供的检查 MachineID 是否冲突的函数 package main import ( \"fmt\" \"github.com/sony/sonyflake\" \"time\" ) var ( sonyFlake *sonyflake.Sonyflake sonyMachineID uint16 ) func getMachineID() (uint16, error) { return sonyMachineID, nil } // 需传⼊入当前的机器ID func Init(startTime string, machineId uint16) (err error) { sonyMachineID = machineId var st time.Time st, err = time.Parse(\"2006-01-02\", startTime) if err != nil { return err } settings := sonyflake.Settings{ StartTime: st, MachineID: getMachineID, } sonyFlake = sonyflake.NewSonyflake(settings) return } // GenID ⽣生成id func GenID() (id uint64, err error) { if sonyFlake == nil { err = fmt.Errorf(\"snoy flake not inited\") return } id, err = sonyFlake.NextID() return } func main() { if err := Init(\"2020-07-01\", 1); err != nil { fmt.Printf(\"Init failed, err:%v\\n\", err) return } id, _ := GenID() fmt.Println(id) } ","date":"2023-06-10","objectID":"/posts/gin/gin12/:1:3","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"validator库参数校验若干实用技巧 在web开发中一个不可避免的环节就是对请求参数进行校验，通常我们会在代码中定义与请求参数相对应的模型（结构体），借助模型绑定快捷地解析请求中的参数，例如 gin 框架中的Bind和ShouldBind系列方法。本文就以 gin 框架的请求参数校验为例，介绍一些validator库的实用技巧。 gin框架使用github.com/go-playground/validator进行参数校验，目前已经支持github.com/go-playground/validator/v10了，我们需要在定义结构体时使用 binding tag标识相关校验规则，可以查看validator文档查看支持的所有 tag。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:2:0","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"基本示例 首先来看gin框架内置使用validator做参数校验的基本示例。 package main import ( \"net/http\" \"github.com/gin-gonic/gin\" ) type SignUpParam struct { Age uint8 `json:\"age\" binding:\"gte=1,lte=130\"` Name string `json:\"name\" binding:\"required\"` Email string `json:\"email\" binding:\"required,email\"` Password string `json:\"password\" binding:\"required\"` RePassword string `json:\"re_password\" binding:\"required,eqfield=Password\"` } func main() { r := gin.Default() r.POST(\"/signup\", func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(\u0026u); err != nil { c.JSON(http.StatusOK, gin.H{ \"msg\": err.Error(), }) return } // 保存入库等业务逻辑代码... c.JSON(http.StatusOK, \"success\") }) _ = r.Run(\":8999\") } 我们使用curl发送一个POST请求测试下： curl -H \"Content-type: application/json\" -X POST -d '{\"name\":\"q1mi\",\"age\":18,\"email\":\"123.com\"}' http://127.0.0.1:8999/signup 输出结果： {\"msg\":\"Key: 'SignUpParam.Email' Error:Field validation for 'Email' failed on the 'email' tag\\nKey: 'SignUpParam.Password' Error:Field validation for 'Password' failed on the 'required' tag\\nKey: 'SignUpParam.RePassword' Error:Field validation for 'RePassword' failed on the 'required' tag\"} 从最终的输出结果可以看到 validator 的检验生效了，但是错误提示的字段不是特别友好，我们可能需要将它翻译成中文。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:2:1","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"翻译校验错误提示信息 validator库本身是支持国际化的，借助相应的语言包可以实现校验错误提示信息的自动翻译。下面的示例代码演示了如何将错误提示信息翻译成中文，翻译成其他语言的方法类似。 package main import ( \"fmt\" \"net/http\" \"github.com/gin-gonic/gin\" \"github.com/gin-gonic/gin/binding\" \"github.com/go-playground/locales/en\" \"github.com/go-playground/locales/zh\" ut \"github.com/go-playground/universal-translator\" \"github.com/go-playground/validator/v10\" enTranslations \"github.com/go-playground/validator/v10/translations/en\" zhTranslations \"github.com/go-playground/validator/v10/translations/zh\" ) // 定义一个全局翻译器T var trans ut.Translator // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // locale 通常取决于 http 请求头的 'Accept-Language' var ok bool // 也可以使用 uni.FindTranslator(...) 传入多个locale进行查找 trans, ok = uni.GetTranslator(locale) if !ok { return fmt.Errorf(\"uni.GetTranslator(%s) failed\", locale) } // 注册翻译器 switch locale { case \"en\": err = enTranslations.RegisterDefaultTranslations(v, trans) case \"zh\": err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) } return } return } type SignUpParam struct { Age uint8 `json:\"age\" binding:\"gte=1,lte=130\"` Name string `json:\"name\" binding:\"required\"` Email string `json:\"email\" binding:\"required,email\"` Password string `json:\"password\" binding:\"required\"` RePassword string `json:\"re_password\" binding:\"required,eqfield=Password\"` } func main() { if err := InitTrans(\"zh\"); err != nil { fmt.Printf(\"init trans failed, err:%v\\n\", err) return } r := gin.Default() r.POST(\"/signup\", func(c *gin.Context) { var u SignUpParam if err := c.ShouldBind(\u0026u); err != nil { // 获取validator.ValidationErrors类型的errors errs, ok := err.(validator.ValidationErrors) if !ok { // 非validator.ValidationErrors类型错误直接返回 c.JSON(http.StatusOK, gin.H{ \"msg\": err.Error(), }) return } // validator.ValidationErrors类型错误则进行翻译 c.JSON(http.StatusOK, gin.H{ \"msg\":errs.Translate(trans), }) return } // 保存入库等具体业务逻辑代码... c.JSON(http.StatusOK, \"success\") }) _ = r.Run(\":8999\") } 同样的请求再来一次： curl -H \"Content-type: application/json\" -X POST -d '{\"name\":\"q1mi\",\"age\":18,\"email\":\"123.com\"}' http://127.0.0.1:8999/signup 这一次的输出结果如下： {\"msg\":{\"SignUpParam.Email\":\"Email必须是一个有效的邮箱\",\"SignUpParam.Password\":\"Password为必填字段\",\"SignUpParam.RePassword\":\"RePassword为必填字段\"}} ","date":"2023-06-10","objectID":"/posts/gin/gin12/:2:2","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"自定义错误提示信息的字段名 上面的错误提示看起来是可以了，但是还是差点意思，首先是错误提示中的字段并不是请求中使用的字段，例如：RePassword是我们后端定义的结构体中的字段名，而请求中使用的是re_password字段。如何是错误提示中的字段使用自定义的名称，例如jsontag指定的值呢？ 只需要在初始化翻译器的时候像下面一样添加一个获取json tag的自定义方法即可。 // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { // 注册一个获取json tag的自定义方法 v.RegisterTagNameFunc(func(fld reflect.StructField) string { name := strings.SplitN(fld.Tag.Get(\"json\"), \",\", 2)[0] if name == \"-\" { return \"\" } return name }) zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // ... liwenzhou.com ... } 再尝试发请求，看一下效果： {\"msg\":{\"SignUpParam.email\":\"email必须是一个有效的邮箱\",\"SignUpParam.password\":\"password为必填字段\",\"SignUpParam.re_password\":\"re_password为必填字段\"}} 可以看到现在错误提示信息中使用的就是我们结构体中jsontag设置的名称了。 但是还是有点瑕疵，那就是最终的错误提示信息中心还是有我们后端定义的结构体名称——SignUpParam，这个名称其实是不需要随错误提示返回给前端的，前端并不需要这个值。我们需要想办法把它去掉。 这里参考https://github.com/go-playground/validator/issues/633#issuecomment-654382345提供的方法，定义一个去掉结构体名称前缀的自定义方法： func removeTopStruct(fields map[string]string) map[string]string { res := map[string]string{} for field, err := range fields { res[field[strings.Index(field, \".\")+1:]] = err } return res } 我们在代码中使用上述函数将翻译后的errors做一下处理即可： if err := c.ShouldBind(\u0026u); err != nil { // 获取validator.ValidationErrors类型的errors errs, ok := err.(validator.ValidationErrors) if !ok { // 非validator.ValidationErrors类型错误直接返回 c.JSON(http.StatusOK, gin.H{ \"msg\": err.Error(), }) return } // validator.ValidationErrors类型错误则进行翻译 // 并使用removeTopStruct函数去除字段名中的结构体名称标识 c.JSON(http.StatusOK, gin.H{ \"msg\": removeTopStruct(errs.Translate(trans)), }) return } 看一下最终的效果： {\"msg\":{\"email\":\"email必须是一个有效的邮箱\",\"password\":\"password为必填字段\",\"re_password\":\"re_password为必填字段\"}} 这一次看起来就比较符合我们预期的标准了。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:2:3","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"自定义结构体校验方法 上面的校验还是有点小问题，就是当涉及到一些复杂的校验规则，比如re_password字段需要与password字段的值相等这样的校验规则，我们的自定义错误提示字段名称方法就不能很好解决错误提示信息中的其他字段名称了。 curl -H \"Content-type: application/json\" -X POST -d '{\"name\":\"q1mi\",\"age\":18,\"email\":\"123.com\",\"password\":\"123\",\"re_password\":\"321\"}' http://127.0.0.1:8999/signup 最后输出的错误提示信息如下： {\"msg\":{\"email\":\"email必须是一个有效的邮箱\",\"re_password\":\"re_password必须等于Password\"}} 可以看到re_password字段的提示信息中还是出现了Password这个结构体字段名称。这有点小小的遗憾，毕竟自定义字段名称的方法不能影响被当成param传入的值。 此时如果想要追求更好的提示效果，将上面的Password字段也改为和json tag一致的名称，就需要我们自定义结构体校验的方法。 例如，我们为SignUpParam自定义一个校验方法如下： // SignUpParamStructLevelValidation 自定义SignUpParam结构体校验函数 func SignUpParamStructLevelValidation(sl validator.StructLevel) { su := sl.Current().Interface().(SignUpParam) if su.Password != su.RePassword { // 输出错误提示信息，最后一个参数就是传递的param sl.ReportError(su.RePassword, \"re_password\", \"RePassword\", \"eqfield\", \"password\") } } 然后在初始化校验器的函数中注册该自定义校验方法即可： func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { // ... liwenzhou.com ... // 为SignUpParam注册自定义校验方法 v.RegisterStructValidation(SignUpParamStructLevelValidation, SignUpParam{}) zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // ... liwenzhou.com ... } 最终再请求一次，看一下效果： {\"msg\":{\"email\":\"email必须是一个有效的邮箱\",\"re_password\":\"re_password必须等于password\"}} 这一次re_password字段的错误提示信息就符合我们预期了。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:2:4","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"自定义字段校验方法 除了上面介绍到的自定义结构体校验方法，validator还支持为某个字段自定义校验方法，并使用RegisterValidation()注册到校验器实例中。 接下来我们来为SignUpParam添加一个需要使用自定义校验方法checkDate做参数校验的字段Date。 type SignUpParam struct { Age uint8 `json:\"age\" binding:\"gte=1,lte=130\"` Name string `json:\"name\" binding:\"required\"` Email string `json:\"email\" binding:\"required,email\"` Password string `json:\"password\" binding:\"required\"` RePassword string `json:\"re_password\" binding:\"required,eqfield=Password\"` // 需要使用自定义校验方法checkDate做参数校验的字段Date Date string `json:\"date\" binding:\"required,datetime=2006-01-02,checkDate\"` } 其中datetime=2006-01-02是内置的用于校验日期类参数是否满足指定格式要求的tag。 如果传入的date参数不满足2006-01-02这种格式就会提示如下错误： {\"msg\":{\"date\":\"date的格式必须是2006-01-02\"}} 针对date字段除了内置的datetime=2006-01-02提供的格式要求外，假设我们还要求该字段的时间必须是一个未来的时间（晚于当前时间），像这样针对某个字段的特殊校验需求就需要我们使用自定义字段校验方法了。 首先我们要在需要执行自定义校验的字段后面添加自定义tag，这里使用的是checkDate，注意使用英文分号分隔开。 // customFunc 自定义字段级别校验方法 func customFunc(fl validator.FieldLevel) bool { date, err := time.Parse(\"2006-01-02\", fl.Field().String()) if err != nil { return false } if date.Before(time.Now()) { return false } return true } 定义好了字段及其自定义校验方法后，就需要将它们联系起来并注册到我们的校验器实例中。 // 在校验器注册自定义的校验方法 if err := v.RegisterValidation(\"checkDate\", customFunc); err != nil { return err } 这样，我们就可以对请求参数中date字段执行自定义的checkDate进行校验了。 我们发送如下请求测试一下： curl -H \"Content-type: application/json\" -X POST -d '{\"name\":\"q1mi\",\"age\":18,\"email\":\"123@qq.com\",\"password\":\"123\", \"re_password\": \"123\", \"date\":\"2020-01-02\"}' http://127.0.0.1:8999/signup 此时得到的响应结果是： {\"msg\":{\"date\":\"Key: 'SignUpParam.date' Error:Field validation for 'date' failed on the 'checkDate' tag\"}} 这…自定义字段级别的校验方法的错误提示信息很“简单粗暴”，和我们上面的中文提示风格有出入，必须想办法搞定它呀！ ","date":"2023-06-10","objectID":"/posts/gin/gin12/:2:5","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"自定义翻译方法 我们现在需要为自定义字段校验方法提供一个自定义的翻译方法，从而实现该字段错误提示信息的自定义显示。 // registerTranslator 为自定义字段添加翻译功能 func registerTranslator(tag string, msg string) validator.RegisterTranslationsFunc { return func(trans ut.Translator) error { if err := trans.Add(tag, msg, false); err != nil { return err } return nil } } // translate 自定义字段的翻译方法 func translate(trans ut.Translator, fe validator.FieldError) string { msg, err := trans.T(fe.Tag(), fe.Field()) if err != nil { panic(fe.(error).Error()) } return msg } 定义好了相关翻译方法之后，我们在InitTrans函数中通过调用RegisterTranslation()方法来注册我们自定义的翻译方法。 // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { // ...liwenzhou.com... // 注册翻译器 switch locale { case \"en\": err = enTranslations.RegisterDefaultTranslations(v, trans) case \"zh\": err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) } if err != nil { return err } // 注意！因为这里会使用到trans实例 // 所以这一步注册要放到trans初始化的后面 if err := v.RegisterTranslation( \"checkDate\", trans, registerTranslator(\"checkDate\", \"{0}必须要晚于当前日期\"), translate, ); err != nil { return err } return } return } 这样再次尝试发送请求，就能得到想要的错误提示信息了。 {\"msg\":{\"date\":\"date必须要晚于当前日期\"}} ","date":"2023-06-10","objectID":"/posts/gin/gin12/:2:6","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"用户认证与JWT HTTP是一个无状态的协议，一次请求结束后，下次再发送请求，服务器就不知道这个请求是谁发来的了(同一个IP不代表同一个用户)，在Web应用中，用户的认证和鉴权是非常重要的一环，实践中有多种可用方案，并且各有千秋。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:3:0","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"Cookie - Session 认证模式 在Web应用发展的初期，大部分采用基于Cookie - Session的会话管理方式，逻辑如下。 客户端使用用户名、密码进行认证 服务端验证用户名、密码，正确后生成并存储Session，将SessionID通过Cookie返回给客户端 客户端访问需要认证的接口时在Cookie中携带SessionID 服务端通过SessionID查找Session并进行鉴权，返回给客户端需要的数据 基于Session的方式存在多种问题 服务端需要存储Session，并且由于Session需要经常快速查找，通常存储在内存或内存数据库中，同时在线用户较多时需要占用大量的服务器资源。 当需要扩展时，创建Session的服务器可能不是验证Session的服务器，所以还需要将所有Session单独存储并共享。 由于客户端使用Cookie存储SessionID，在跨域场景下需要进行兼容性处理，同时这种方式也难以防范CSRF攻击。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:3:1","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"Token 认证模式 鉴于基于Session的会话管理方式存在上述多个缺点，基于Token的无状态会话管理方式诞生了，所谓无状态，就是服务端可以不再存储信息，甚至是不再存储Session，逻辑如下。 客户端使用用户名、密码进行认证 服务端验证用户名、密码正确后生成Token返回给客户端 客户端保存Token，访问需要认证的接口时在URL参数或HTTP Header中加入Token 服务端通过解码Token进行鉴权，返回给客户端需要的数据 基于Token的会话管理方式有效解决了基于Session的会话管理方式带来的问题。 服务端不需要存储和用户鉴权有关的信息，鉴权信息会被加密到Token中，服务端只需要读取Token中包含的鉴权信息即可 避免了共享Session导致的不易扩展问题 不需要依赖Cookie， 有效避免Cookie带来的CSRF攻击问题 使用CORS可以快速解决跨域问题 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:3:2","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"JWT介绍 JWT是JSON Web Token的缩写，是为了在网络应用环境间传递声明而执行的一种基于JSON的开放标准((RFC 7519)。JWT本身没有定义任何技术实现，它只是定义了一种基于Token的会话管理的规则，涵盖Token需要包含的标准内容和Token的生成过程，特别适用于分布式站点的单点登录(SSO) 场景。 一个JWT Token就像这样： eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoyODAxODcyNzQ4ODMyMzU4NSwiZXhwIjoxNTk0NTQwMjkxLCJpc3MiOiJibHVlYmVsbCJ9.lk_ZrAtYGCeZhK3iupHxP1kgjBJzQTVTtX0iZYFx9wU 它是由.分隔的三部分组成，这三部分依次是： 头部（Header） 负载（Payload） 签名（Signature） 头部和负载是以JSON形式存在，这就是JWT中的JSON，三部分的内容都分别单独经过了Base64编码，以.拼接成一个JWT Token。 Header jwt中的Header中存储了所使用的加密算法和Token类型。 { \"alg\": \"HS256\", \"typ\": \"JWT\" } Payload Payload表示负载，也是一个JSON对象，JWT规定了7个官方字段供选用， iss (issuer)：签发⼈人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：⽣生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 除了官方字段，开发者也可以自己指定字段和内容，例如下面的内容。 { \"sub\": \"1234567890\", \"name\": \"John Doe\", \"admin\": true } 注意，JWT默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。这个JSON对象也要使用Base64URL算法转成字符串。 Signature Signature部分是对前两部分的签名，防止数据篡改。 首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用Header里面指定的签名算法（默认是HMAC SHA256），按照下面的公式产生签名。 HMACSHA256(base64UrlEncode(header) + \".\" + base64UrlEncode(payload),secret) JWT优缺点 JWT拥有基于Token的会话管理方式所拥有的一切优势，不依赖Cookie，使得其可以防止CSRF攻击，也能在禁用Cookie的浏览器环境中正常运行。 而JWT的最大优势是服务端不再需要存储Session，使得服务端认证鉴权业务可以方便扩展，避免存储Session所需要引入的Redis等组件，降低了系统架构复杂度。但这也是JWT最大的劣势，由于有效期存储在Token中，JWT Token一旦签发，就会在有效期内一直可用，无法在服务端废止，当用户进行登出操作，只能依赖客户端删除掉本地存储的JWT Token，如果需要禁用用户，单纯使用JWT就无法做到了。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:3:3","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"基于JWT实现认证实践 使用jwt-go这个库来实现我们生成JWT和解析JWT的功能。 定义需求 我们需要定制自己的需求来决定JWT中保存哪些数据，比如我们规定在JWT中要存储username信息，那么我们就定义一个MyClaims结构体如下： // MyClaims 自定义声明结构体并内嵌jwt.StandardClaims // jwt包自带的jwt.StandardClaims只包含了官方字段 // 我们这里需要额外记录一个username字段，所以要自定义结构体 // 如果想要保存更多信息，都可以添加到这个结构体中 type MyClaims struct { Username string `json:\"username\"` jwt.StandardClaims } 然后我们定义JWT的过期时间，这里以2小时为例： const TokenExpireDuration = time.Hour * 2 接下来还需要定义Secret： var MySecret = []byte(\"剑来\") 生成JWT // GenToken 生成JWT func GenToken(username string) (string, error) { // 创建一个我们自己的声明 c := MyClaims{ username, // 自定义字段 jwt.StandardClaims{ ExpiresAt: time.Now().Add(TokenExpireDuration).Unix(), // 过期时间 Issuer: \"my-project\", // 签发人 }, } // 使用指定的签名方法创建签名对象 token := jwt.NewWithClaims(jwt.SigningMethodHS256, c) // 使用指定的secret签名并获得完整的编码后的字符串token return token.SignedString(MySecret) } 解析JWT // ParseToken 解析JWT func ParseToken(tokenString string) (*MyClaims, error) { // 解析token token, err := jwt.ParseWithClaims(tokenString, \u0026MyClaims{}, func(token *jwt.Token) (i interface{}, err error) { return MySecret, nil }) if err != nil { return nil, err } if claims, ok := token.Claims.(*MyClaims); ok \u0026\u0026 token.Valid { // 校验token return claims, nil } return nil, errors.New(\"invalid token\") } 使用refreshtoken刷新accesstoken 前面讲的Token，都是Access Token，也就是访问资源接口时所需要的Token，还有另外一种Token,，Refresh Token，通常情况下，Refresh Token的有效期会比较长，而Access Token的有效期比较短，当Access Token由于过期而失效时，使用Refresh Token就可以获取到新的Access Token，如果Refresh Token也失效了，用户就只能重新登录了。 在JWT的实践中，引入Refresh Token,将会话管理流程改进如下。 客户端使用用户名密码进行认证 服务端生成有效时间较短的Access Token (例如10分钟)， 和有效时间较长的RefreshToken (例如7天) 客户端访问需要认证的接口时，携带Access Token 如果Access Token没有过期，服务端鉴权后返回给客户端需要的数据 如果携带Access Token访问需要认证的接口时鉴权失败(例如返回401错误)，则客户端使用Refresh Token向刷新接口申请新的Access Token 如果Refresh Token没有过期，服务端向客户端下发新的Access Token 客户端使用新的Access Token访问需要认证的接口 后端需要对外提供一个刷新Token的接口，前端需要实验一个当Access Token过期时自动请求刷新Token接口获取新Access Token的拦截器。 生成access token 和 refresh token // GenToken ⽣生成access token 和 refresh token func GenToken(userID int64) (aToken, rToken string, err error) { // 创建⼀一个我们⾃自⼰己的声明 c := MyClaims{ userID, // ⾃自定义字段 jwt.StandardClaims{ ExpiresAt: time.Now().Add(TokenExpireDuration).Unix(), // 过期时间 Issuer: \"bluebell\", // 签发⼈人 }, } // 加密并获得完整的编码后的字符串串token aToken, err = jwt.NewWithClaims(jwt.SigningMethodHS256, c).SignedString(mySecret) // refresh token 不不需要存任何⾃自定义数据 rToken, err = jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.StandardClaims{ ExpiresAt: time.Now().Add(time.Second * 30).Unix(), // 过期时间 Issuer: \"bluebell\", // 签发⼈人 }).SignedString(mySecret) // 使⽤用指定的secret签名并获得完整的编码后的字符串串token return } 解析access token // ParseToken 解析JWT func ParseToken(tokenString string) (claims *MyClaims, err error) { // 解析token var token *jwt.Token claims = new(MyClaims) token, err = jwt.ParseWithClaims(tokenString, claims, keyFunc) if err != nil { return } if !token.Valid { // 校验token err = errors.New(\"invalid token\") } return } refresh token // RefreshToken 刷新AccessToken func RefreshToken(aToken, rToken string) (newAToken, newRToken string, err error) { // refresh token⽆无效直接返回 if _, err = jwt.Parse(rToken, keyFunc); err != nil { return } // 从旧access token中解析出claims数据 var claims MyClaims _, err = jwt.ParseWithClaims(aToken, \u0026claims, keyFunc) v, _ := err.(*jwt.ValidationError) // 当access token是过期错误 并且 refresh token没有过期时就创建⼀一个新的access token if v.Errors == jwt.ValidationErrorExpired { return GenToken(claims.UserID) } return } ","date":"2023-06-10","objectID":"/posts/gin/gin12/:3:4","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"makefile 借助Makefile我们在编译过程中不再需要每次手动输入编译的命令和编译的参数，可以极大简化项目编译过程。 make介绍 make是一个构建自动化工具，会在当前目录下寻找Makefile或makefile文件。如果存在相应的文件，它就会依据其中定义好的规则完成构建任务。 makefile介绍 我们可以把Makefile简单理解为它定义了一个项目文件的编译规则。借助Makefile我们在编译过程中不再需要每次手动输入编译的命令和编译的参数，可以极大简化项目编译过程。同时使用Makefile也可以在项目中确定具体的编译规则和流程，很多开源项目中都会定义Makefile文件。关于Makefile的详细内容推荐阅读Makefile教程。 规则描述 Makefile由多条规则组成，每条规则主要由两个部分组成，分别是依赖的关系和执行的命令。 其结构如下所示： [target] ... : [prerequisites] ... \u003ctab\u003e[command] ... ... 其中： targets：规则的目标 prerequisites：可选的要生成 targets 需要的文件或者是目标。 command：make 需要执行的命令（任意的 shell 命令）。可以有多条命令，每一条命令占一行。 举个例子： build: CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o xx 示例 .PHONY: all build run gotool clean help BINARY=\"bluebell\" all: gotool build build: CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o ${BINARY} run: @go run ./ gotool: go fmt ./ go vet ./ clean: @if [ -f ${BINARY} ] ; then rm ${BINARY} ; fi help: @echo \"make - 格式化 Go 代码, 并编译生成二进制文件\" @echo \"make build - 编译 Go 代码, 生成二进制文件\" @echo \"make run - 直接运行 Go 代码\" @echo \"make clean - 移除二进制文件和 vim swap files\" @echo \"make gotool - 运行 Go 工具 'fmt' and 'vet'\" 其中： BINARY=\"bluebell\"是定义变量。 .PHONY用来定义伪目标。不创建目标文件，而是去执行这个目标下面的命令。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:4:0","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"air热加载 Air能够实时监听项目的代码文件，在代码发生变更之后自动重新编译并执行，大大提高gin框架项目的开发效率。（常见的Flask或Django框架都是支持实时加载的） ","date":"2023-06-10","objectID":"/posts/gin/gin12/:5:0","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"安装 go get -u github.com/cosmtrek/air ","date":"2023-06-10","objectID":"/posts/gin/gin12/:5:1","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"air_example.conf示例 # [Air](https://github.com/cosmtrek/air) TOML 格式的配置文件 # 工作目录 # 使用 . 或绝对路径，请注意 `tmp_dir` 目录必须在 `root` 目录下 root = \".\" tmp_dir = \"tmp\" [build] # 只需要写你平常编译使用的shell命令。你也可以使用 `make` # Windows平台示例: cmd = \"go build -o tmp\\main.exe .\" cmd = \"go build -o ./tmp/main .\" # 由`cmd`命令得到的二进制文件名 # Windows平台示例：bin = \"tmp\\main.exe\" bin = \"tmp/main\" # 自定义执行程序的命令，可以添加额外的编译标识例如添加 GIN_MODE=release # Windows平台示例：full_bin = \"tmp\\main.exe\" full_bin = \"APP_ENV=dev APP_USER=air ./tmp/main\" # 监听以下文件扩展名的文件. include_ext = [\"go\", \"tpl\", \"tmpl\", \"html\"] # 忽略这些文件扩展名或目录 exclude_dir = [\"assets\", \"tmp\", \"vendor\", \"frontend/node_modules\"] # 监听以下指定目录的文件 include_dir = [] # 排除以下文件 exclude_file = [] # 如果文件更改过于频繁，则没有必要在每次更改时都触发构建。可以设置触发构建的延迟时间 delay = 1000 # ms # 发生构建错误时，停止运行旧的二进制文件。 stop_on_error = true # air的日志文件名，该日志文件放置在你的`tmp_dir`中 log = \"air_errors.log\" [log] # 显示日志时间 time = true [color] # 自定义每个部分显示的颜色。如果找不到颜色，使用原始的应用程序日志。 main = \"magenta\" watcher = \"cyan\" build = \"yellow\" runner = \"green\" [misc] # 退出时删除tmp目录 clean_on_exit = true ","date":"2023-06-10","objectID":"/posts/gin/gin12/:5:2","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"问题 我使用命令没有安装成功，是在github上下载的exe，https://github.com/cosmtrek/air/releases，重命名为air.exe放在goroot的bin目录下。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:5:3","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"swagger Swagger本质上是一种用于描述使用JSON表示的RESTful API的接口描述语言。Swagger与一组开源软件工具一起使用，以设计、构建、记录和使用RESTful Web服务。Swagger包括自动文档，代码生成和测试用例生成。 在前后端分离的项目开发过程中，如果后端同学能够提供一份清晰明了的接口文档，那么就能极大地提高大家的沟通效率和开发效率。可是编写接口文档历来都是令人头痛的，而且后续接口文档的维护也十分耗费精力。 最好是有一种方案能够既满足我们输出文档的需要又能随代码的变更自动更新，而Swagger正是那种能帮我们解决接口文档问题的工具。 这里以gin框架为例，使用gin-swagger库以使用Swagger 2.0自动生成RESTful API文档。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:6:0","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"gin-swagger实战 想要使用gin-swagger为你的代码自动生成接口文档，一般需要下面三个步骤： 按照swagger要求给接口代码添加声明式注释，具体参照声明式注释格式。 使用swag工具扫描代码自动生成API接口文档数据 使用gin-swagger渲染在线接口文档页面 第一步：添加注释 在程序入口main函数上以注释的方式写下项目相关介绍信息。 package main // @title 这里写标题 // @version 1.0 // @description 这里写描述信息 // @termsOfService http://swagger.io/terms/ // @contact.name 这里写联系人信息 // @contact.url http://www.swagger.io/support // @contact.email support@swagger.io // @license.name Apache 2.0 // @license.url http://www.apache.org/licenses/LICENSE-2.0.html // @host 这里写接口服务的host // @BasePath 这里写base path func main() { r := gin.New() // liwenzhou.com ... r.Run() } 在你代码中处理请求的接口函数（通常位于controller层）按如下方式写上注释： // GetPostListHandler2 升级版帖子列表接口 // @Summary 升级版帖子列表接口 // @Description 可按社区按时间或分数排序查询帖子列表接口 // @Tags 帖子相关接口 // @Accept application/json // @Produce application/json // @Param Authorization header string false \"Bearer 用户令牌\" // @Param object query models.ParamPostList false \"查询参数\" // @Security ApiKeyAuth // @Success 200 {object} _ResponsePostList // @Router /posts2 [get] func GetPostListHandler2(c *gin.Context) { // GET请求参数(query string)：/api/v1/posts2?page=1\u0026size=10\u0026order=time // 初始化结构体时指定初始参数 p := \u0026models.ParamPostList{ Page: 1, Size: 10, Order: models.OrderTime, } if err := c.ShouldBindQuery(p); err != nil { zap.L().Error(\"GetPostListHandler2 with invalid params\", zap.Error(err)) ResponseError(c, CodeInvalidParam) return } data, err := logic.GetPostListNew(p) // 获取数据 if err != nil { zap.L().Error(\"logic.GetPostList() failed\", zap.Error(err)) ResponseError(c, CodeServerBusy) return } ResponseSuccess(c, data) // 返回响应 } 上面注释中参数类型使用了object，models.ParamPostList具体定义如下： // bluebell/models/params.go // ParamPostList 获取帖子列表query string参数 type ParamPostList struct { CommunityID int64 `json:\"community_id\" form:\"community_id\"` // 可以为空 Page int64 `json:\"page\" form:\"page\" example:\"1\"` // 页码 Size int64 `json:\"size\" form:\"size\" example:\"10\"` // 每页数据量 Order string `json:\"order\" form:\"order\" example:\"score\"` // 排序依据 } 响应数据类型也使用的object，我个人习惯在controller层专门定义一个docs_models.go文件来存储文档中使用的响应数据model。 // bluebell/controller/docs_models.go // _ResponsePostList 帖子列表接口响应数据 type _ResponsePostList struct { Code ResCode `json:\"code\"` // 业务响应状态码 Message string `json:\"message\"` // 提示信息 Data []*models.ApiPostDetail `json:\"data\"` // 数据 } 第二步：生成接口文档数据 编写完注释后，使用以下命令安装swag工具： go get -u github.com/swaggo/swag/cmd/swag 在项目根目录执行以下命令，使用swag工具生成接口文档数据。 swag init 执行完上述命令后，如果你写的注释格式没问题，此时你的项目根目录下会多出一个docs文件夹。 ./docs ├── docs.go ├── swagger.json └── swagger.yaml 第三步：引入gin-swagger渲染文档数据 然后在项目代码中注册路由的地方按如下方式引入gin-swagger相关内容： import ( // liwenzhou.com ... _ \"bluebell/docs\" // 千万不要忘了导入把你上一步生成的docs gs \"github.com/swaggo/gin-swagger\" \"github.com/swaggo/gin-swagger/swaggerFiles\" \"github.com/gin-gonic/gin\" ) 注册swagger api相关路由 r.GET(\"/swagger/*any\", gs.WrapHandler(swaggerFiles.Handler)) 把你的项目程序运行起来，打开浏览器访问http://localhost:8080/swagger/index.html就能看到Swagger 2.0 Api文档了。 gin-swagger同时还提供了DisablingWrapHandler函数，方便我们通过设置某些环境变量来禁用Swagger。例如： r.GET(\"/swagger/*any\", gs.DisablingWrapHandler(swaggerFiles.Handler, \"NAME_OF_ENV_VARIABLE\")) 此时如果将环境变量NAME_OF_ENV_VARIABLE设置为任意值，则/swagger/*any将返回404响应，就像未指定路由时一样。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:6:1","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"go_test https://www.liwenzhou.com/posts/Go/unit-test/ ","date":"2023-06-10","objectID":"/posts/gin/gin12/:7:0","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"常用的HTTP服务压测工具介绍 https://www.liwenzhou.com/posts/Go/benchmark-tools/ 在项目正式上线之前，我们通常需要通过压测来评估当前系统能够支撑的请求量、排查可能存在的隐藏bug，同时了解了程序的实际处理能力能够帮我们更好的匹配项目的实际需求，节约资源成本。 在项目正式上线之前，我们通常需要通过压测来评估当前系统能够支撑的请求量、排查可能存在的隐藏bug，同时了解了程序的实际处理能力能够帮我们更好的匹配项目的实际需求，节约资源成本。 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:8:0","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"压测相关术语 响应时间(RT) ：指系统对请求作出响应的时间. 吞吐量(Throughput) ：指系统在单位时间内处理请求的数量 QPS每秒查询率(Query Per Second) ：“每秒查询率”，是一台服务器每秒能够响应的查询次数，是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。 TPS(TransactionPerSecond)：每秒钟系统能够处理的交易或事务的数量 并发连接数：某个时刻服务器所接受的请求总数 ","date":"2023-06-10","objectID":"/posts/gin/gin12/:8:1","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"压力测试工具 ab ab全称Apache Bench，是Apache自带的性能测试工具。使用这个工具，只须指定同时连接数、请求数以及URL，即可测试网站或网站程序的性能。 通过ab发送请求模拟多个访问者同时对某一URL地址进行访问,可以得到每秒传送字节数、每秒处理请求数、每请求处理时间等统计数据。 命令格式： ab [options] [http://]hostname[:port]/path 常用参数如下： -n requests 总请求数 -c concurrency 一次产生的请求数，可以理解为并发数 -t timelimit 测试所进行的最大秒数, 可以当做请求的超时时间 -p postfile 包含了需要POST的数据的文件 -T content-type POST数据所使用的Content-type头信息 更多参数请查看官方文档。 例如测试某个GET请求接口： ab -n 10000 -c 100 -t 10 \"http://127.0.0.1:8080/api/v1/posts?size=10\" 测试POST请求接口： ab -n 10000 -c 100 -t 10 -p post.json -T \"application/json\" \"http://127.0.0.1:8080/api/v1/post\" wrk wrk是一款开源的HTTP性能测试工具，它和上面提到的ab同属于HTTP性能测试工具，它比ab功能更加强大，可以通过编写lua脚本来支持更加复杂的测试场景。 Mac下安装： brew install wrk 常用命令参数： -c --conections：保持的连接数 -d --duration：压测持续时间(s) -t --threads：使用的线程总数 -s --script：加载lua脚本 -H --header：在请求头部添加一些参数 --latency 打印详细的延迟统计信息 --timeout 请求的最大超时时间(s) 使用示例： wrk -t8 -c100 -d30s --latency http://127.0.0.1:8080/api/v1/posts?size=10 输出结果： Running 30s test @ http://127.0.0.1:8080/api/v1/posts?size=10 8 threads and 100 connections Thread Stats Avg Stdev Max +/- Stdev Latency 14.55ms 2.02ms 31.59ms 76.70% Req/Sec 828.16 85.69 0.97k 60.46% Latency Distribution 50% 14.44ms 75% 15.76ms 90% 16.63ms 99% 21.07ms 198091 requests in 30.05s, 29.66MB read Requests/sec: 6592.29 Transfer/sec: 0.99MB go-wrk go-wrk是Go语言版本的wrk，Windows同学可以使用它来测试，使用如下命令来安装go-wrk： go get github.com/adeven/go-wrk 使用方法同wrk类似，基本格式如下： go-wrk [flags] url 常用的参数： -H=\"User-Agent: go-wrk 0.1 bechmark\\nContent-Type: text/html;\": 由'\\n'分隔的请求头 -c=100: 使用的最大连接数 -k=true: 是否禁用keep-alives -i=false: if TLS security checks are disabled -m=\"GET\": HTTP请求方法 -n=1000: 请求总数 -t=1: 使用的线程数 -b=\"\" HTTP请求体 -s=\"\" 如果指定，它将计算响应中包含搜索到的字符串s的频率 执行测试： go-wrk -t=8 -c=100 -n=10000 \"http://127.0.0.1:8080/api/v1/posts?size=10\" 输出结果： ==========================BENCHMARK========================== URL: http://127.0.0.1:8080/api/v1/posts?size=10 Used Connections: 100 Used Threads: 8 Total number of calls: 10000 ===========================TIMINGS=========================== Total time passed: 2.74s Avg time per request: 27.11ms Requests per second: 3644.53 Median time per request: 26.88ms 99th percentile time: 39.16ms Slowest time for request: 45.00ms =============================DATA============================= Total response body sizes: 340000 Avg response body per request: 34.00 Byte Transfer rate per second: 123914.11 Byte/s (0.12 MByte/s) ==========================RESPONSES========================== 20X Responses: 10000 (100.00%) 30X Responses: 0 (0.00%) 40X Responses: 0 (0.00%) 50X Responses: 0 (0.00%) Errors: 0 (0.00%) ","date":"2023-06-10","objectID":"/posts/gin/gin12/:8:2","tags":["gin","go web"],"title":"go web开发中遇到的小技术与知识点","uri":"/posts/gin/gin12/"},{"categories":["gin"],"content":"我们编写的Web项目部署之后，经常会因为需要进行配置变更或功能迭代而重启服务，单纯的kill -9 pid的方式会强制关闭进程，这样就会导致服务端当前正在处理的请求失败，那有没有更优雅的方式来实现关机或重启呢？ ","date":"2023-06-09","objectID":"/posts/gin/gin10/:0:0","tags":["gin"],"title":"Gin-优雅关机与重启","uri":"/posts/gin/gin10/"},{"categories":["gin"],"content":"什么是优雅关机 优雅关机就是服务端关机命令发出后不是立即关机，而是等待当前还在处理的请求全部处理完毕后再退出程序，是一种对客户端友好的关机方式。而执行Ctrl+C关闭服务端时，会强制结束进程导致正在访问的请求出现问题。 ","date":"2023-06-09","objectID":"/posts/gin/gin10/:1:0","tags":["gin"],"title":"Gin-优雅关机与重启","uri":"/posts/gin/gin10/"},{"categories":["gin"],"content":"如何实现优雅关机 Go 1.8版本之后， http.Server 内置的 Shutdown() 方法就支持优雅地关机，具体示例如下： // +build go1.8 package main import ( \"context\" \"log\" \"net/http\" \"os\" \"os/signal\" \"syscall\" \"time\" \"github.com/gin-gonic/gin\" ) func main() { router := gin.Default() router.GET(\"/\", func(c *gin.Context) { time.Sleep(5 * time.Second) c.String(http.StatusOK, \"Welcome Gin Server\") }) srv := \u0026http.Server{ Addr: \":8080\", Handler: router, } go func() { // 开启一个goroutine启动服务 if err := srv.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed { log.Fatalf(\"listen: %s\\n\", err) } }() // 等待中断信号来优雅地关闭服务器，为关闭服务器操作设置一个5秒的超时 quit := make(chan os.Signal, 1) // 创建一个接收信号的通道 // kill 默认会发送 syscall.SIGTERM 信号 // kill -2 发送 syscall.SIGINT 信号，我们常用的Ctrl+C就是触发系统SIGINT信号 // kill -9 发送 syscall.SIGKILL 信号，但是不能被捕获，所以不需要添加它 // signal.Notify把收到的 syscall.SIGINT或syscall.SIGTERM 信号转发给quit signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM) // 此处不会阻塞 \u003c-quit // 阻塞在此，当接收到上述两种信号时才会往下执行 log.Println(\"Shutdown Server ...\") // 创建一个5秒超时的context ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() // 5秒内优雅关闭服务（将未处理完的请求处理完再关闭服务），超过5秒就超时退出 if err := srv.Shutdown(ctx); err != nil { log.Fatal(\"Server Shutdown: \", err) } log.Println(\"Server exiting\") } 如何验证优雅关机的效果呢？ 上面的代码运行后会在本地的8080端口开启一个web服务，它只注册了一条路由/，后端服务会先sleep 5秒钟然后才返回响应信息。 我们按下Ctrl+C时会发送syscall.SIGINT来通知程序优雅关机，具体做法如下： 打开终端，编译并执行上面的代码 打开一个浏览器，访问127.0.0.1:8080/，此时浏览器白屏等待服务端返回响应。 在终端迅速执行Ctrl+C命令给程序发送syscall.SIGINT信号 此时程序并不立即退出而是等我们第2步的响应返回之后再退出，从而实现优雅关机。 ","date":"2023-06-09","objectID":"/posts/gin/gin10/:2:0","tags":["gin"],"title":"Gin-优雅关机与重启","uri":"/posts/gin/gin10/"},{"categories":["gin"],"content":"优雅重启 优雅关机实现了，那么该如何实现优雅重启呢？ 我们可以使用 fvbock/endless 来替换默认的 ListenAndServe启动服务来实现， 示例代码如下： package main import ( \"log\" \"net/http\" \"time\" \"github.com/fvbock/endless\" \"github.com/gin-gonic/gin\" ) func main() { router := gin.Default() router.GET(\"/\", func(c *gin.Context) { time.Sleep(5 * time.Second) c.String(http.StatusOK, \"hello gin!\") }) // 默认endless服务器会监听下列信号： // syscall.SIGHUP，syscall.SIGUSR1，syscall.SIGUSR2，syscall.SIGINT，syscall.SIGTERM和syscall.SIGTSTP // 接收到 SIGHUP 信号将触发`fork/restart` 实现优雅重启（kill -1 pid会发送SIGHUP信号） // 接收到 syscall.SIGINT或syscall.SIGTERM 信号将触发优雅关机 // 接收到 SIGUSR2 信号将触发HammerTime // SIGUSR1 和 SIGTSTP 被用来触发一些用户自定义的hook函数 if err := endless.ListenAndServe(\":8080\", router); err!=nil{ log.Fatalf(\"listen: %s\\n\", err) } log.Println(\"Server exiting\") } 如何验证优雅重启的效果呢？ 我们通过执行kill -1 pid命令发送syscall.SIGINT来通知程序优雅重启，具体做法如下： 打开终端，go build -o graceful_restart编译并执行./graceful_restart,终端输出当前pid(假设为43682) 将代码中处理请求函数返回的hello gin!修改为hello q1mi!，再次编译go build -o graceful_restart 打开一个浏览器，访问127.0.0.1:8080/，此时浏览器白屏等待服务端返回响应。 在终端迅速执行kill -1 43682命令给程序发送syscall.SIGHUP信号 等第3步浏览器收到响应信息hello gin!后再次访问127.0.0.1:8080/会收到hello q1mi!的响应。 在不影响当前未处理完请求的同时完成了程序代码的替换，实现了优雅重启。 但是需要注意的是，此时程序的PID变化了，因为endless 是通过fork子进程处理新请求，待原进程处理完当前请求后再退出的方式实现优雅重启的。所以当你的项目是使用类似supervisor的软件管理进程时就不适用这种方式了。 ","date":"2023-06-09","objectID":"/posts/gin/gin10/:3:0","tags":["gin"],"title":"Gin-优雅关机与重启","uri":"/posts/gin/gin10/"},{"categories":["gin"],"content":"总结 无论是优雅关机还是优雅重启归根结底都是通过监听特定系统信号，然后执行一定的逻辑处理保障当前系统正在处理的请求被正常处理后再关闭当前进程。使用优雅关机还是使用优雅重启以及怎么实现，这就需要根据项目实际情况来决定了。 ","date":"2023-06-09","objectID":"/posts/gin/gin10/:4:0","tags":["gin"],"title":"Gin-优雅关机与重启","uri":"/posts/gin/gin10/"},{"categories":["gin"],"content":"https://github.com/spf13/viper/blob/master/README.md Viper是适用于Go应用程序的完整配置解决方案。它被设计用于在应用程序中工作，并且可以处理所有类型的配置需求和格式。 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:0:0","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"安装 go get github.com/spf13/viper ","date":"2023-06-09","objectID":"/posts/gin/gin09/:1:0","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"什么是Viper Viper是适用于Go应用程序（包括Twelve-Factor App）的完整配置解决方案。它被设计用于在应用程序中工作，并且可以处理所有类型的配置需求和格式。它支持以下特性： 设置默认值 从JSON、TOML、YAML、HCL、envfile和Java properties格式的配置文件读取配置信息 实时监控和重新读取配置文件（可选） 从环境变量中读取 从远程配置系统（etcd或Consul）读取并监控配置变化 从命令行参数读取配置 从buffer读取配置 显式配置值 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:2:0","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"为什么选择Viper 在构建现代应用程序时，你无需担心配置文件格式；你想要专注于构建出色的软件。Viper的出现就是为了在这方面帮助你的。 Viper能够为你执行下列操作： 查找、加载和反序列化JSON、TOML、YAML、HCL、INI、envfile和Java properties格式的配置文件。 提供一种机制为你的不同配置选项设置默认值。 提供一种机制来通过命令行参数覆盖指定选项的值。 提供别名系统，以便在不破坏现有代码的情况下轻松重命名参数。 当用户提供了与默认值相同的命令行或配置文件时，可以很容易地分辨出它们之间的区别。 Viper会按照下面的优先级。每个项目的优先级都高于它下面的项目: 显示调用Set设置值 命令行参数（flag） 环境变量 配置文件 key/value存储 默认值 重要： 目前Viper配置的键（Key）是大小写不敏感的。目前正在讨论是否将这一选项设为可选。 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:3:0","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"把值存入Viper ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:0","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"建立默认值 一个好的配置系统应该支持默认值。键不需要默认值，但如果没有通过配置文件、环境变量、远程配置或命令行标志（flag）设置键，则默认值非常有用。 例如： viper.SetDefault(\"ContentDir\", \"content\") viper.SetDefault(\"LayoutDir\", \"layouts\") viper.SetDefault(\"Taxonomies\", map[string]string{\"tag\": \"tags\", \"category\": \"categories\"}) ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:1","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"读取配置文件 Viper需要最少知道在哪里查找配置文件的配置。Viper支持JSON、TOML、YAML、HCL、envfile和Java properties格式的配置文件。Viper可以搜索多个路径，但目前单个Viper实例只支持单个配置文件。Viper不默认任何配置搜索路径，将默认决策留给应用程序。 下面是一个如何使用Viper搜索和读取配置文件的示例。不需要任何特定的路径，但是至少应该提供一个配置文件预期出现的路径。 viper.SetConfigFile(\"./config.yaml\") // 指定配置文件路径 viper.SetConfigName(\"config\") // 配置文件名称(无扩展名) viper.SetConfigType(\"yaml\") // 如果配置文件的名称中没有扩展名，则需要配置此项 viper.AddConfigPath(\"/etc/appname/\") // 查找配置文件所在的路径 viper.AddConfigPath(\"$HOME/.appname\") // 多次调用以添加多个搜索路径 viper.AddConfigPath(\".\") // 还可以在工作目录中查找配置 err := viper.ReadInConfig() // 查找并读取配置文件 if err != nil { // 处理读取配置文件的错误 panic(fmt.Errorf(\"Fatal error config file: %s \\n\", err)) } 在加载配置文件出错时，你可以像下面这样处理找不到配置文件的特定情况： if err := viper.ReadInConfig(); err != nil { if _, ok := err.(viper.ConfigFileNotFoundError); ok { // 配置文件未找到错误；如果需要可以忽略 } else { // 配置文件被找到，但产生了另外的错误 } } // 配置文件找到并成功解析 注意[自1.6起]： 你也可以有不带扩展名的文件，并以编程方式指定其格式。对于位于用户$HOME目录中的配置文件没有任何扩展名，如.bashrc。 两个问题、未验证 当你使用如下方式读取配置时，viper会从./conf目录下查找任何以config为文件名的配置文件，如果同时存在./conf/config.json和./conf/config.yaml两个配置文件的话，viper会从哪个配置文件加载配置呢？ viper.SetConfigName(\"config\") viper.AddConfigPath(\"./conf\") 在上面两个语句下搭配使用viper.SetConfigType(\"yaml\")指定配置文件类型可以实现预期的效果吗？ ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:2","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"写入配置文件 从配置文件中读取配置文件是有用的，但是有时你想要存储在运行时所做的所有修改。为此，可以使用下面一组命令，每个命令都有自己的用途: WriteConfig - 将当前的viper配置写入预定义的路径并覆盖（如果存在的话）。如果没有预定义的路径，则报错。 SafeWriteConfig - 将当前的viper配置写入预定义的路径。如果没有预定义的路径，则报错。如果存在，将不会覆盖当前的配置文件。 WriteConfigAs - 将当前的viper配置写入给定的文件路径。将覆盖给定的文件(如果它存在的话)。 SafeWriteConfigAs - 将当前的viper配置写入给定的文件路径。不会覆盖给定的文件(如果它存在的话)。 根据经验，标记为safe的所有方法都不会覆盖任何文件，而是直接创建（如果不存在），而默认行为是创建或截断。 一个小示例： viper.WriteConfig() // 将当前配置写入“viper.AddConfigPath()”和“viper.SetConfigName”设置的预定义路径 viper.SafeWriteConfig() viper.WriteConfigAs(\"/path/to/my/.config\") viper.SafeWriteConfigAs(\"/path/to/my/.config\") // 因为该配置文件写入过，所以会报错 viper.SafeWriteConfigAs(\"/path/to/my/.other_config\") ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:3","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"监控并重新读取配置文件 Viper支持在运行时实时读取配置文件的功能。 需要重新启动服务器以使配置生效的日子已经一去不复返了，viper驱动的应用程序可以在运行时读取配置文件的更新，而不会错过任何消息。 只需告诉viper实例watchConfig。可选地，你可以为Viper提供一个回调函数，以便在每次发生更改时运行。 确保在调用WatchConfig()之前添加了所有的配置路径。 viper.WatchConfig() viper.OnConfigChange(func(e fsnotify.Event) { // 配置文件发生变更之后会调用的回调函数 fmt.Println(\"Config file changed:\", e.Name) }) ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:4","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"从io.Reader读取配置 Viper预先定义了许多配置源，如文件、环境变量、标志和远程K/V存储，但你不受其约束。你还可以实现自己所需的配置源并将其提供给viper。 viper.SetConfigType(\"yaml\") // 或者 viper.SetConfigType(\"YAML\") // 任何需要将此配置添加到程序中的方法。 var yamlExample = []byte(` Hacker: true name: steve hobbies: - skateboarding - snowboarding - go clothing: jacket: leather trousers: denim age: 35 eyes : brown beard: true `) viper.ReadConfig(bytes.NewBuffer(yamlExample)) viper.Get(\"name\") // 这里会得到 \"steve\" ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:5","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"覆盖设置 这些可能来自命令行标志，也可能来自你自己的应用程序逻辑。 viper.Set(\"Verbose\", true) viper.Set(\"LogFile\", LogFile) ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:6","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"注册和使用别名 别名允许多个键引用单个值 viper.RegisterAlias(\"loud\", \"Verbose\") // 注册别名（此处loud和Verbose建立了别名） viper.Set(\"verbose\", true) // 结果与下一行相同 viper.Set(\"loud\", true) // 结果与前一行相同 viper.GetBool(\"loud\") // true viper.GetBool(\"verbose\") // true ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:7","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"使用环境变量 Viper完全支持环境变量。这使Twelve-Factor App开箱即用。有五种方法可以帮助与ENV协作: AutomaticEnv() BindEnv(string...) : error SetEnvPrefix(string) SetEnvKeyReplacer(string...) *strings.Replacer AllowEmptyEnv(bool) 使用ENV变量时，务必要意识到Viper将ENV变量视为区分大小写。 Viper提供了一种机制来确保ENV变量是惟一的。通过使用SetEnvPrefix，你可以告诉Viper在读取环境变量时使用前缀。BindEnv和AutomaticEnv都将使用这个前缀。 BindEnv使用一个或两个参数。第一个参数是键名称，第二个是环境变量的名称。环境变量的名称区分大小写。如果没有提供ENV变量名，那么Viper将自动假设ENV变量与以下格式匹配：前缀+ “_” +键名全部大写。当你显式提供ENV变量名（第二个参数）时，它 不会 自动添加前缀。例如，如果第二个参数是“id”，Viper将查找环境变量“ID”。 在使用ENV变量时，需要注意的一件重要事情是，每次访问该值时都将读取它。Viper在调用BindEnv时不固定该值。 AutomaticEnv是一个强大的助手，尤其是与SetEnvPrefix结合使用时。调用时，Viper会在发出viper.Get请求时随时检查环境变量。它将应用以下规则。它将检查环境变量的名称是否与键匹配（如果设置了EnvPrefix）。 SetEnvKeyReplacer允许你使用strings.Replacer对象在一定程度上重写 Env 键。如果你希望在Get()调用中使用-或者其他什么符号，但是环境变量里使用_分隔符，那么这个功能是非常有用的。可以在viper_test.go中找到它的使用示例。 或者，你可以使用带有NewWithOptions工厂函数的EnvKeyReplacer。与SetEnvKeyReplacer不同，它接受StringReplacer接口，允许你编写自定义字符串替换逻辑。 默认情况下，空环境变量被认为是未设置的，并将返回到下一个配置源。若要将空环境变量视为已设置，请使用AllowEmptyEnv方法。 Env 示例： SetEnvPrefix(\"spf\") // 将自动转为大写 BindEnv(\"id\") os.Setenv(\"SPF_ID\", \"13\") // 通常是在应用程序之外完成的 id := Get(\"id\") // 13 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:8","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"使用Flags Viper 具有绑定到标志的能力。具体来说，Viper支持Cobra库中使用的Pflag。 与BindEnv类似，该值不是在调用绑定方法时设置的，而是在访问该方法时设置的。这意味着你可以根据需要尽早进行绑定，即使在init()函数中也是如此。 对于单个标志，BindPFlag()方法提供此功能。 例如： serverCmd.Flags().Int(\"port\", 1138, \"Port to run Application server on\") viper.BindPFlag(\"port\", serverCmd.Flags().Lookup(\"port\")) 你还可以绑定一组现有的pflags （pflag.FlagSet）： 举个例子： pflag.Int(\"flagname\", 1234, \"help message for flagname\") pflag.Parse() viper.BindPFlags(pflag.CommandLine) i := viper.GetInt(\"flagname\") // 从viper而不是从pflag检索值 在 Viper 中使用 pflag 并不阻碍其他包中使用标准库中的 flag 包。pflag 包可以通过导入这些 flags 来处理flag包定义的flags。这是通过调用pflag包提供的便利函数AddGoFlagSet()来实现的。 例如： package main import ( \"flag\" \"github.com/spf13/pflag\" ) func main() { // 使用标准库 \"flag\" 包 flag.Int(\"flagname\", 1234, \"help message for flagname\") pflag.CommandLine.AddGoFlagSet(flag.CommandLine) pflag.Parse() viper.BindPFlags(pflag.CommandLine) i := viper.GetInt(\"flagname\") // 从 viper 检索值 ... } flag接口 如果你不使用Pflag，Viper 提供了两个Go接口来绑定其他 flag 系统。 FlagValue表示单个flag。这是一个关于如何实现这个接口的非常简单的例子： type myFlag struct {} func (f myFlag) HasChanged() bool { return false } func (f myFlag) Name() string { return \"my-flag-name\" } func (f myFlag) ValueString() string { return \"my-flag-value\" } func (f myFlag) ValueType() string { return \"string\" } 一旦你的 flag 实现了这个接口，你可以很方便地告诉Viper绑定它： viper.BindFlagValue(\"my-flag-name\", myFlag{}) FlagValueSet代表一组 flags 。这是一个关于如何实现这个接口的非常简单的例子: type myFlagSet struct { flags []myFlag } func (f myFlagSet) VisitAll(fn func(FlagValue)) { for _, flag := range flags { fn(flag) } } 一旦你的flag set实现了这个接口，你就可以很方便地告诉Viper绑定它： fSet := myFlagSet{ flags: []myFlag{myFlag{}, myFlag{}}, } viper.BindFlagValues(\"my-flags\", fSet) ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:9","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"远程Key/Value存储支持 在Viper中启用远程支持，需要在代码中匿名导入viper/remote这个包。 import _ \"github.com/spf13/viper/remote\" Viper将读取从Key/Value存储（例如etcd或Consul）中的路径检索到的配置字符串（如JSON、TOML、YAML、HCL、envfile和Java properties格式）。这些值的优先级高于默认值，但是会被从磁盘、flag或环境变量检索到的配置值覆盖。（译注：也就是说Viper加载配置值的优先级为：磁盘上的配置文件\u003e命令行标志位\u003e环境变量\u003e远程Key/Value存储\u003e默认值。） Viper使用crypt从K/V存储中检索配置，这意味着如果你有正确的gpg密匙，你可以将配置值加密存储并自动解密。加密是可选的。 你可以将远程配置与本地配置结合使用，也可以独立使用。 crypt有一个命令行助手，你可以使用它将配置放入K/V存储中。crypt默认使用在http://127.0.0.1:4001的etcd。 $ go get github.com/bketelsen/crypt/bin/crypt $ crypt set -plaintext /config/hugo.json /Users/hugo/settings/config.json 确认值已经设置： $ crypt get -plaintext /config/hugo.json 有关如何设置加密值或如何使用Consul的示例，请参见crypt文档。 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:10","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"远程Key/Value存储实例–未加密 etcd viper.AddRemoteProvider(\"etcd\", \"http://127.0.0.1:4001\",\"/config/hugo.json\") viper.SetConfigType(\"json\") // 因为在字节流中没有文件扩展名，所以这里需要设置下类型。支持的扩展名有 \"json\", \"toml\", \"yaml\", \"yml\", \"properties\", \"props\", \"prop\", \"env\", \"dotenv\" err := viper.ReadRemoteConfig() Consul 你需要 Consul Key/Value存储中设置一个Key保存包含所需配置的JSON值。例如，创建一个keyMY_CONSUL_KEY将下面的值存入Consul key/value 存储： { \"port\": 8080, \"hostname\": \"liwenzhou.com\" } viper.AddRemoteProvider(\"consul\", \"localhost:8500\", \"MY_CONSUL_KEY\") viper.SetConfigType(\"json\") // 需要显示设置成json err := viper.ReadRemoteConfig() fmt.Println(viper.Get(\"port\")) // 8080 fmt.Println(viper.Get(\"hostname\")) // liwenzhou.com Firestore viper.AddRemoteProvider(\"firestore\", \"google-cloud-project-id\", \"collection/document\") viper.SetConfigType(\"json\") // 配置的格式: \"json\", \"toml\", \"yaml\", \"yml\" err := viper.ReadRemoteConfig() 当然，你也可以使用SecureRemoteProvider。 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:11","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"远程Key/Value存储实例–加密 viper.AddSecureRemoteProvider(\"etcd\",\"http://127.0.0.1:4001\",\"/config/hugo.json\",\"/etc/secrets/mykeyring.gpg\") viper.SetConfigType(\"json\") // 因为在字节流中没有文件扩展名，所以这里需要设置下类型。支持的扩展名有 \"json\", \"toml\", \"yaml\", \"yml\", \"properties\", \"props\", \"prop\", \"env\", \"dotenv\" err := viper.ReadRemoteConfig() ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:12","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"监控etcd中的更改–未加密 // 或者你可以创建一个新的viper实例 var runtime_viper = viper.New() runtime_viper.AddRemoteProvider(\"etcd\", \"http://127.0.0.1:4001\", \"/config/hugo.yml\") runtime_viper.SetConfigType(\"yaml\") // 因为在字节流中没有文件扩展名，所以这里需要设置下类型。支持的扩展名有 \"json\", \"toml\", \"yaml\", \"yml\", \"properties\", \"props\", \"prop\", \"env\", \"dotenv\" // 第一次从远程读取配置 err := runtime_viper.ReadRemoteConfig() // 反序列化 runtime_viper.Unmarshal(\u0026runtime_conf) // 开启一个单独的goroutine一直监控远端的变更 go func(){ for { time.Sleep(time.Second * 5) // 每次请求后延迟一下 // 目前只测试了etcd支持 err := runtime_viper.WatchRemoteConfig() if err != nil { log.Errorf(\"unable to read remote config: %v\", err) continue } // 将新配置反序列化到我们运行时的配置结构体中。你还可以借助channel实现一个通知系统更改的信号 runtime_viper.Unmarshal(\u0026runtime_conf) } }() ","date":"2023-06-09","objectID":"/posts/gin/gin09/:4:13","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"从Viper获取值 在Viper中，有几种方法可以根据值的类型获取值。存在以下功能和方法: Get(key string) : interface{} GetBool(key string) : bool GetFloat64(key string) : float64 GetInt(key string) : int GetIntSlice(key string) : []int GetString(key string) : string GetStringMap(key string) : map[string]interface{} GetStringMapString(key string) : map[string]string GetStringSlice(key string) : []string GetTime(key string) : time.Time GetDuration(key string) : time.Duration IsSet(key string) : bool AllSettings() : map[string]interface{} 需要认识到的一件重要事情是，每一个Get方法在找不到值的时候都会返回零值。为了检查给定的键是否存在，提供了IsSet()方法。 例如： viper.GetString(\"logfile\") // 不区分大小写的设置和获取 if viper.GetBool(\"verbose\") { fmt.Println(\"verbose enabled\") } ","date":"2023-06-09","objectID":"/posts/gin/gin09/:5:0","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"访问嵌套的键 访问器方法也接受深度嵌套键的格式化路径。例如，如果加载下面的JSON文件： { \"host\": { \"address\": \"localhost\", \"port\": 5799 }, \"datastore\": { \"metric\": { \"host\": \"127.0.0.1\", \"port\": 3099 }, \"warehouse\": { \"host\": \"198.0.0.1\", \"port\": 2112 } } } Viper可以通过传入.分隔的路径来访问嵌套字段： GetString(\"datastore.metric.host\") // (返回 \"127.0.0.1\") 这遵守上面建立的优先规则；搜索路径将遍历其余配置注册表，直到找到为止。(译注：因为Viper支持从多种配置来源，例如磁盘上的配置文件\u003e命令行标志位\u003e环境变量\u003e远程Key/Value存储\u003e默认值，我们在查找一个配置的时候如果在当前配置源中没找到，就会继续从后续的配置源查找，直到找到为止。) 例如，在给定此配置文件的情况下，datastore.metric.host和datastore.metric.port均已定义（并且可以被覆盖）。如果另外在默认值中定义了datastore.metric.protocol，Viper也会找到它。 然而，如果datastore.metric被直接赋值覆盖（被flag，环境变量，set()方法等等…），那么datastore.metric的所有子键都将变为未定义状态，它们被高优先级配置级别“遮蔽”（shadowed）了。 最后，如果存在与分隔的键路径匹配的键，则返回其值。例如： { \"datastore.metric.host\": \"0.0.0.0\", \"host\": { \"address\": \"localhost\", \"port\": 5799 }, \"datastore\": { \"metric\": { \"host\": \"127.0.0.1\", \"port\": 3099 }, \"warehouse\": { \"host\": \"198.0.0.1\", \"port\": 2112 } } } GetString(\"datastore.metric.host\") // 返回 \"0.0.0.0\" ","date":"2023-06-09","objectID":"/posts/gin/gin09/:5:1","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"提取子树 从Viper中提取子树。 例如，viper实例现在代表了以下配置： app: cache1: max-items: 100 item-size: 64 cache2: max-items: 200 item-size: 80 执行后： subv := viper.Sub(\"app.cache1\") subv现在就代表： max-items: 100 item-size: 64 假设我们现在有这么一个函数： func NewCache(cfg *Viper) *Cache {...} 它基于subv格式的配置信息创建缓存。现在，可以轻松地分别创建这两个缓存，如下所示： cfg1 := viper.Sub(\"app.cache1\") cache1 := NewCache(cfg1) cfg2 := viper.Sub(\"app.cache2\") cache2 := NewCache(cfg2) ","date":"2023-06-09","objectID":"/posts/gin/gin09/:5:2","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"反序列化 你还可以选择将所有或特定的值解析到结构体、map等。 有两种方法可以做到这一点： Unmarshal(rawVal interface{}) : error UnmarshalKey(key string, rawVal interface{}) : error 举个例子： type config struct { Port int Name string PathMap string `mapstructure:\"path_map\"` } var C config err := viper.Unmarshal(\u0026C) if err != nil { t.Fatalf(\"unable to decode into struct, %v\", err) } 如果你想要解析那些键本身就包含.(默认的键分隔符）的配置，你需要修改分隔符： v := viper.NewWithOptions(viper.KeyDelimiter(\"::\")) v.SetDefault(\"chart::values\", map[string]interface{}{ \"ingress\": map[string]interface{}{ \"annotations\": map[string]interface{}{ \"traefik.frontend.rule.type\": \"PathPrefix\", \"traefik.ingress.kubernetes.io/ssl-redirect\": \"true\", }, }, }) type config struct { Chart struct{ Values map[string]interface{} } } var C config v.Unmarshal(\u0026C) Viper还支持解析到嵌入的结构体： /* Example config: module: enabled: true token: 89h3f98hbwf987h3f98wenf89ehf */ type config struct { Module struct { Enabled bool moduleConfig `mapstructure:\",squash\"` } } // moduleConfig could be in a module specific package type moduleConfig struct { Token string } var C config err := viper.Unmarshal(\u0026C) if err != nil { t.Fatalf(\"unable to decode into struct, %v\", err) } Viper在后台使用github.com/mitchellh/mapstructure来解析值，其默认情况下使用mapstructuretag。 注意 当我们需要将viper读取的配置反序列到我们定义的结构体变量中时，一定要使用mapstructuretag哦！ ","date":"2023-06-09","objectID":"/posts/gin/gin09/:5:3","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"序列化成字符串 你可能需要将viper中保存的所有设置序列化到一个字符串中，而不是将它们写入到一个文件中。你可以将自己喜欢的格式的序列化器与AllSettings()返回的配置一起使用。 import ( yaml \"gopkg.in/yaml.v2\" // ... ) func yamlStringSettings() string { c := viper.AllSettings() bs, err := yaml.Marshal(c) if err != nil { log.Fatalf(\"unable to marshal config to YAML: %v\", err) } return string(bs) } ","date":"2023-06-09","objectID":"/posts/gin/gin09/:5:4","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"使用单个还是多个Viper实例 Viper是开箱即用的。你不需要配置或初始化即可开始使用Viper。由于大多数应用程序都希望使用单个中央存储库管理它们的配置信息，所以viper包提供了这个功能。它类似于单例模式。 在上面的所有示例中，它们都以其单例风格的方法演示了如何使用viper。 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:6:0","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"使用多个viper实例 你还可以在应用程序中创建许多不同的viper实例。每个都有自己独特的一组配置和值。每个人都可以从不同的配置文件，key value存储区等读取数据。每个都可以从不同的配置文件、键值存储等中读取。viper包支持的所有功能都被镜像为viper实例的方法。 例如： x := viper.New() y := viper.New() x.SetDefault(\"ContentDir\", \"content\") y.SetDefault(\"ContentDir\", \"foobar\") //... 当使用多个viper实例时，由用户来管理不同的viper实例。 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:6:1","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"使用Viper示例 假设我们的项目现在有一个./conf/config.yaml配置文件，内容如下： port: 8123 version: \"v1.2.3\" 接下来通过示例代码演示两种在项目中使用viper管理项目配置信息的方式。 ","date":"2023-06-09","objectID":"/posts/gin/gin09/:7:0","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"直接使用viper管理配置 这里用一个demo演示如何在gin框架搭建的web项目中使用viper，使用viper加载配置文件中的信息，并在代码中直接使用viper.GetXXX()方法获取对应的配置值。 package main import ( \"fmt\" \"net/http\" \"github.com/gin-gonic/gin\" \"github.com/spf13/viper\" ) func main() { viper.SetConfigFile(\"./conf/config.yaml\") // 指定配置文件路径 err := viper.ReadInConfig() // 读取配置信息 if err != nil { // 读取配置信息失败 panic(fmt.Errorf(\"Fatal error config file: %s \\n\", err)) } // 监控配置文件变化 viper.WatchConfig() r := gin.Default() // 访问/version的返回值会随配置文件的变化而变化 r.GET(\"/version\", func(c *gin.Context) { c.String(http.StatusOK, viper.GetString(\"version\")) }) if err := r.Run( fmt.Sprintf(\":%d\", viper.GetInt(\"port\"))); err != nil { panic(err) } } ","date":"2023-06-09","objectID":"/posts/gin/gin09/:7:1","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"使用结构体变量保存配置信息 除了上面的用法外，我们还可以在项目中定义与配置文件对应的结构体，viper加载完配置信息后使用结构体变量保存配置信息。 package main import ( \"fmt\" \"net/http\" \"github.com/fsnotify/fsnotify\" \"github.com/gin-gonic/gin\" \"github.com/spf13/viper\" ) type Config struct { Port int `mapstructure:\"port\"` Version string `mapstructure:\"version\"` } var Conf = new(Config) func main() { viper.SetConfigFile(\"./conf/config.yaml\") // 指定配置文件路径 err := viper.ReadInConfig() // 读取配置信息 if err != nil { // 读取配置信息失败 panic(fmt.Errorf(\"Fatal error config file: %s \\n\", err)) } // 将读取的配置信息保存至全局变量Conf if err := viper.Unmarshal(Conf); err != nil { panic(fmt.Errorf(\"unmarshal conf failed, err:%s \\n\", err)) } // 监控配置文件变化 viper.WatchConfig() // 注意！！！配置文件发生变化后要同步到全局变量Conf viper.OnConfigChange(func(in fsnotify.Event) { fmt.Println(\"夭寿啦~配置文件被人修改啦...\") if err := viper.Unmarshal(Conf); err != nil { panic(fmt.Errorf(\"unmarshal conf failed, err:%s \\n\", err)) } }) r := gin.Default() // 访问/version的返回值会随配置文件的变化而变化 r.GET(\"/version\", func(c *gin.Context) { c.String(http.StatusOK, Conf.Version) }) if err := r.Run(fmt.Sprintf(\":%d\", Conf.Port)); err != nil { panic(err) } } ","date":"2023-06-09","objectID":"/posts/gin/gin09/:7:2","tags":["gin"],"title":"Go配置管理——Viper","uri":"/posts/gin/gin09/"},{"categories":["gin"],"content":"gin默认的中间件 首先我们来看一个最简单的gin项目： func main() { r := gin.Default() r.GET(\"/hello\", func(c *gin.Context) { c.String(\"hello liwenzhou.com!\") }) r.Run( } 接下来我们看一下gin.Default()的源码： func Default() *Engine { debugPrintWARNINGDefault() engine := New() engine.Use(Logger(), Recovery()) return engine } 也就是我们在使用gin.Default()的同时是用到了gin框架内的两个默认中间件Logger()和Recovery()。 其中Logger()是把gin框架本身的日志输出到标准输出（我们本地开发调试时在终端输出的那些日志就是它的功劳），而Recovery()是在程序出现panic的时候恢复现场并写入500响应的。 ","date":"2023-06-09","objectID":"/posts/gin/gin08/:1:0","tags":["gin"],"title":"Gin中使用Zap","uri":"/posts/gin/gin08/"},{"categories":["gin"],"content":"基于zap的中间件 我们可以模仿Logger()和Recovery()的实现，使用我们的日志库来接收gin框架默认输出的日志。 这里以zap为例，我们实现两个中间件如下：（其实这里就是查看源码，把原来log的地方用zap的logger写） // GinLogger 接收gin框架默认的日志 func GinLogger(logger *zap.Logger) gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() path := c.Request.URL.Path query := c.Request.URL.RawQuery c.Next() cost := time.Since(start) logger.Info(path, zap.Int(\"status\", c.Writer.Status()), zap.String(\"method\", c.Request.Method), zap.String(\"path\", path), zap.String(\"query\", query), zap.String(\"ip\", c.ClientIP()), zap.String(\"user-agent\", c.Request.UserAgent()), zap.String(\"errors\", c.Errors.ByType(gin.ErrorTypePrivate).String()), zap.Duration(\"cost\", cost), ) } } // GinRecovery recover掉项目可能出现的panic func GinRecovery(logger *zap.Logger, stack bool) gin.HandlerFunc { return func(c *gin.Context) { defer func() { if err := recover(); err != nil { // Check for a broken connection, as it is not really a // condition that warrants a panic stack trace. var brokenPipe bool if ne, ok := err.(*net.OpError); ok { if se, ok := ne.Err.(*os.SyscallError); ok { if strings.Contains(strings.ToLower(se.Error()), \"broken pipe\") || strings.Contains(strings.ToLower(se.Error()), \"connection reset by peer\") { brokenPipe = true } } } httpRequest, _ := httputil.DumpRequest(c.Request, false) if brokenPipe { logger.Error(c.Request.URL.Path, zap.Any(\"error\", err), zap.String(\"request\", string(httpRequest)), ) // If the connection is dead, we can't write a status to it. c.Error(err.(error)) // nolint: errcheck c.Abort() return } if stack { logger.Error(\"[Recovery from panic]\", zap.Any(\"error\", err), zap.String(\"request\", string(httpRequest)), zap.String(\"stack\", string(debug.Stack())), ) } else { logger.Error(\"[Recovery from panic]\", zap.Any(\"error\", err), zap.String(\"request\", string(httpRequest)), ) } c.AbortWithStatus(http.StatusInternalServerError) } }() c.Next() } } 如果不想自己实现，可以使用github上有别人封装好的https://github.com/gin-contrib/zap。 这样我们就可以在gin框架中使用我们上面定义好的两个中间件来代替gin框架默认的Logger()和Recovery()了。 r := gin.New() r.Use(GinLogger(), GinRecovery()) ","date":"2023-06-09","objectID":"/posts/gin/gin08/:2:0","tags":["gin"],"title":"Gin中使用Zap","uri":"/posts/gin/gin08/"},{"categories":["gin"],"content":"在gin项目中使用zap 最后我们再加入我们项目中常用的日志切割，完整版的logger.go代码如下： package logger import ( \"gin_zap_demo/config\" \"net\" \"net/http\" \"net/http/httputil\" \"os\" \"runtime/debug\" \"strings\" \"time\" \"github.com/gin-gonic/gin\" \"github.com/natefinch/lumberjack\" \"go.uber.org/zap\" \"go.uber.org/zap/zapcore\" ) var lg *zap.Logger // InitLogger 初始化Logger func InitLogger(cfg *config.LogConfig) (err error) { writeSyncer := getLogWriter(cfg.Filename, cfg.MaxSize, cfg.MaxBackups, cfg.MaxAge) encoder := getEncoder() var l = new(zapcore.Level) err = l.UnmarshalText([]byte(cfg.Level)) if err != nil { return } core := zapcore.NewCore(encoder, writeSyncer, l) lg = zap.New(core, zap.AddCaller()) zap.ReplaceGlobals(lg) // 替换zap包中全局的logger实例，后续在其他包中只需使用zap.L()调用即可 return } func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.TimeKey = \"time\" encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder encoderConfig.EncodeDuration = zapcore.SecondsDurationEncoder encoderConfig.EncodeCaller = zapcore.ShortCallerEncoder return zapcore.NewJSONEncoder(encoderConfig) } func getLogWriter(filename string, maxSize, maxBackup, maxAge int) zapcore.WriteSyncer { lumberJackLogger := \u0026lumberjack.Logger{ Filename: filename, MaxSize: maxSize, MaxBackups: maxBackup, MaxAge: maxAge, } return zapcore.AddSync(lumberJackLogger) } // GinLogger 接收gin框架默认的日志 func GinLogger() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() path := c.Request.URL.Path query := c.Request.URL.RawQuery c.Next() cost := time.Since(start) lg.Info(path, zap.Int(\"status\", c.Writer.Status()), zap.String(\"method\", c.Request.Method), zap.String(\"path\", path), zap.String(\"query\", query), zap.String(\"ip\", c.ClientIP()), zap.String(\"user-agent\", c.Request.UserAgent()), zap.String(\"errors\", c.Errors.ByType(gin.ErrorTypePrivate).String()), zap.Duration(\"cost\", cost), ) } } // GinRecovery recover掉项目可能出现的panic，并使用zap记录相关日志 func GinRecovery(stack bool) gin.HandlerFunc { return func(c *gin.Context) { defer func() { if err := recover(); err != nil { // Check for a broken connection, as it is not really a // condition that warrants a panic stack trace. var brokenPipe bool if ne, ok := err.(*net.OpError); ok { if se, ok := ne.Err.(*os.SyscallError); ok { if strings.Contains(strings.ToLower(se.Error()), \"broken pipe\") || strings.Contains(strings.ToLower(se.Error()), \"connection reset by peer\") { brokenPipe = true } } } httpRequest, _ := httputil.DumpRequest(c.Request, false) if brokenPipe { lg.Error(c.Request.URL.Path, zap.Any(\"error\", err), zap.String(\"request\", string(httpRequest)), ) // If the connection is dead, we can't write a status to it. c.Error(err.(error)) // nolint: errcheck c.Abort() return } if stack { lg.Error(\"[Recovery from panic]\", zap.Any(\"error\", err), zap.String(\"request\", string(httpRequest)), zap.String(\"stack\", string(debug.Stack())), ) } else { lg.Error(\"[Recovery from panic]\", zap.Any(\"error\", err), zap.String(\"request\", string(httpRequest)), ) } c.AbortWithStatus(http.StatusInternalServerError) } }() c.Next() } } 然后定义日志相关配置： type LogConfig struct { Level string `json:\"level\"` Filename string `json:\"filename\"` MaxSize int `json:\"maxsize\"` MaxAge int `json:\"max_age\"` MaxBackups int `json:\"max_backups\"` } 在项目中先从配置文件加载配置信息，再调用logger.InitLogger(config.Conf.LogConfig)即可完成logger实例的初识化。其中，通过r.Use(logger.GinLogger(), logger.GinRecovery(true))注册我们的中间件来使用zap接收gin框架自身的日志，在项目中需要的地方通过使用zap.L().Xxx()方法来记录自定义日志信息。 package main import ( \"fmt\" \"gin_zap_demo/config\" \"gin_zap_demo/logger\" \"net/http\" \"os\" \"go.uber.org/zap\" \"github.com/gin-gonic/gin\" ) func main() { // load config from config.json if len(os.Args) \u003c 1 { return } if err := config.Init(os.Args[1]); err != nil { panic(err) } // init logger if err := logger.InitLogger(config.Conf.LogConfig); err != nil { fmt.Printf(\"init logger failed, err:%v\\n\", err) return } gin.SetMode(config.Conf.Mode) r := gin.Default() // 注册zap相关中间件 r.Use(logger.GinLogger(), logger.Gi","date":"2023-06-09","objectID":"/posts/gin/gin08/:3:0","tags":["gin"],"title":"Gin中使用Zap","uri":"/posts/gin/gin08/"},{"categories":["gin"],"content":"介绍 在许多Go语言项目中，我们需要一个好的日志记录器能够提供下面这些功能： 能够将事件记录到文件中，而不是应用程序控制台。 日志切割-能够根据文件大小、时间或间隔等来切割日志文件。 支持不同的日志级别。例如INFO，DEBUG，ERROR等。 能够打印基本信息，如调用文件/函数名和行号，日志时间等。 ","date":"2023-06-08","objectID":"/posts/gin/gin07/:1:0","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"默认的Go Logger 在介绍Uber-go的zap包之前，让我们先看看Go语言提供的基本日志功能。Go语言提供的默认日志包是https://golang.org/pkg/log/。 ","date":"2023-06-08","objectID":"/posts/gin/gin07/:2:0","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"实现Go Logger 实现一个Go语言中的日志记录器非常简单——创建一个新的日志文件，然后设置它为日志的输出位置。 设置Logger 我们可以像下面的代码一样设置日志记录器 func SetupLogger() { logFileLocation, _ := os.OpenFile(\"/Users/nzR/test.log\", os.O_CREATE|os.O_APPEND|os.O_RDWR, 0744) log.SetOutput(logFileLocation) } 使用Logger 让我们来写一些虚拟的代码来使用这个日志记录器。 在当前的示例中，我们将建立一个到URL的HTTP连接，并将状态代码/错误记录到日志文件中。 func simpleHttpGet(url string) { resp, err := http.Get(url) if err != nil { log.Printf(\"Error fetching url %s : %s\", url, err.Error()) } else { log.Printf(\"Status Code for %s : %s\", url, resp.Status) resp.Body.Close() } } Logger的运行 现在让我们执行上面的代码并查看日志记录器的运行情况。 func main() { SetupLogger() simpleHttpGet(\"www.google.com\") simpleHttpGet(\"http://www.google.com\") } 当我们执行上面的代码，我们能看到一个test.log文件被创建，下面的内容会被添加到这个日志文件中。 2019/05/24 01:14:13 Error fetching url www.google.com : Get www.google.com: unsupported protocol scheme \"\" 2019/05/24 01:14:14 Status Code for http://www.google.com : 200 OK ","date":"2023-06-08","objectID":"/posts/gin/gin07/:2:1","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"Go Logger的优势和劣势 优势 它最大的优点是使用非常简单。我们可以设置任何io.Writer作为日志记录输出并向其发送要写入的日志。 劣势 仅限基本的日志级别 只有一个Print选项。不支持INFO/DEBUG等多个级别。 对于错误日志，它有Fatal和Panic Fatal日志通过调用os.Exit(1)来结束程序 Panic日志在写入日志消息之后抛出一个panic 但是它缺少一个ERROR日志级别，这个级别可以在不抛出panic或退出程序的情况下记录错误 缺乏日志格式化的能力——例如记录调用者的函数名和行号，格式化日期和时间格式。等等。 不提供日志切割的能力。 ","date":"2023-06-08","objectID":"/posts/gin/gin07/:2:2","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"Uber-go Zap Zap是非常快的、结构化的，分日志级别的Go日志库。 ","date":"2023-06-08","objectID":"/posts/gin/gin07/:3:0","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"为什么选择Uber-go zap 它同时提供了结构化日志记录和printf风格的日志记录 它非常的快 根据Uber-go Zap的文档，它的性能比类似的结构化日志包更好——也比标准库更快。 以下是Zap发布的基准测试信息 记录一条消息和10个字段: Package Time Time % to zap Objects Allocated ⚡️ zap 862 ns/op +0% 5 allocs/op ⚡️ zap (sugared) 1250 ns/op +45% 11 allocs/op zerolog 4021 ns/op +366% 76 allocs/op go-kit 4542 ns/op +427% 105 allocs/op apex/log 26785 ns/op +3007% 115 allocs/op logrus 29501 ns/op +3322% 125 allocs/op log15 29906 ns/op +3369% 122 allocs/op 记录一个静态字符串，没有任何上下文或printf风格的模板： Package Time Time % to zap Objects Allocated ⚡️ zap 118 ns/op +0% 0 allocs/op ⚡️ zap (sugared) 191 ns/op +62% 2 allocs/op zerolog 93 ns/op -21% 0 allocs/op go-kit 280 ns/op +137% 11 allocs/op standard library 499 ns/op +323% 2 allocs/op apex/log 1990 ns/op +1586% 10 allocs/op logrus 3129 ns/op +2552% 24 allocs/op log15 3887 ns/op +3194% 23 allocs/op ","date":"2023-06-08","objectID":"/posts/gin/gin07/:3:1","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"安装 运行下面的命令安装zap go get -u go.uber.org/zap ","date":"2023-06-08","objectID":"/posts/gin/gin07/:3:2","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"配置Zap Logger Zap提供了两种类型的日志记录器—Sugared Logger和Logger。 在性能很好但不是很关键的上下文中，使用SugaredLogger。它比其他结构化日志记录包快4-10倍，并且支持结构化和printf风格的日志记录。 在每一微秒和每一次内存分配都很重要的上下文中，使用Logger。它甚至比SugaredLogger更快，内存分配次数也更少，但它只支持强类型的结构化日志记录。 Logger 通过调用zap.NewProduction()/zap.NewDevelopment()或者zap.Example()创建一个Logger。 上面的每一个函数都将创建一个logger。唯一的区别在于它将记录的信息不同。例如production logger默认记录调用函数信息、日期和时间等。 通过Logger调用Info/Error等。 默认情况下日志都会打印到应用程序的console界面。 var logger *zap.Logger func main() { InitLogger() defer logger.Sync() simpleHttpGet(\"www.google.com\") simpleHttpGet(\"http://www.google.com\") } func InitLogger() { logger, _ = zap.NewProduction() } func simpleHttpGet(url string) { resp, err := http.Get(url) if err != nil { logger.Error( \"Error fetching url..\", zap.String(\"url\", url), zap.Error(err)) } else { logger.Info(\"Success..\", zap.String(\"statusCode\", resp.Status), zap.String(\"url\", url)) resp.Body.Close() } } 在上面的代码中，我们首先创建了一个Logger，然后使用Info/ Error等Logger方法记录消息。 日志记录器方法的语法是这样的： func (log *Logger) MethodXXX(msg string, fields ...Field) 其中MethodXXX是一个可变参数函数，可以是Info / Error/ Debug / Panic等。每个方法都接受一个消息字符串和任意数量的zapcore.Field场参数。 每个zapcore.Field其实就是一组键值对参数。 我们执行上面的代码会得到如下输出结果： {\"level\":\"error\",\"ts\":1572159218.912792,\"caller\":\"zap_demo/temp.go:25\",\"msg\":\"Error fetching url..\",\"url\":\"www.sogo.com\",\"error\":\"Get www.sogo.com: unsupported protocol scheme \\\"\\\"\",\"stacktrace\":\"main.simpleHttpGet\\n\\t/Users/q1mi/zap_demo/temp.go:25\\nmain.main\\n\\t/Users/q1mi/zap_demo/temp.go:14\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\"} {\"level\":\"info\",\"ts\":1572159219.1227388,\"caller\":\"zap_demo/temp.go:30\",\"msg\":\"Success..\",\"statusCode\":\"200 OK\",\"url\":\"http://www.sogo.com\"} Sugared Logger 现在让我们使用Sugared Logger来实现相同的功能。 大部分的实现基本都相同。 惟一的区别是，我们通过调用主logger的. Sugar()方法来获取一个SugaredLogger。 然后使用SugaredLogger以printf格式记录语句 下面是修改过后使用SugaredLogger代替Logger的代码： var sugarLogger *zap.SugaredLogger func main() { InitLogger() defer sugarLogger.Sync() simpleHttpGet(\"www.google.com\") simpleHttpGet(\"http://www.google.com\") } func InitLogger() { logger, _ := zap.NewProduction() sugarLogger = logger.Sugar() } func simpleHttpGet(url string) { sugarLogger.Debugf(\"Trying to hit GET request for %s\", url) resp, err := http.Get(url) if err != nil { sugarLogger.Errorf(\"Error fetching URL %s : Error = %s\", url, err) } else { sugarLogger.Infof(\"Success! statusCode = %s for URL %s\", resp.Status, url) resp.Body.Close() } } 当你执行上面的代码会得到如下输出： {\"level\":\"error\",\"ts\":1572159149.923002,\"caller\":\"logic/temp2.go:27\",\"msg\":\"Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \\\"\\\"\",\"stacktrace\":\"main.simpleHttpGet\\n\\t/Users/q1mi/zap_demo/logic/temp2.go:27\\nmain.main\\n\\t/Users/q1mi/zap_demo/logic/temp2.go:14\\nruntime.main\\n\\t/usr/local/go/src/runtime/proc.go:203\"} {\"level\":\"info\",\"ts\":1572159150.192585,\"caller\":\"logic/temp2.go:29\",\"msg\":\"Success! statusCode = 200 OK for URL http://www.sogo.com\"} 你应该注意到的了，到目前为止这两个logger都打印输出JSON结构格式。 在本博客的后面部分，我们将更详细地讨论SugaredLogger，并了解如何进一步配置它。 ","date":"2023-06-08","objectID":"/posts/gin/gin07/:3:3","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"定制logger 将日志写入文件而不是终端 我们要做的第一个更改是把日志写入文件，而不是打印到应用程序控制台。 我们将使用zap.New(…)方法来手动传递所有配置，而不是使用像zap.NewProduction()这样的预置方法来创建logger。 func New(core zapcore.Core, options ...Option) *Logger zapcore.Core需要三个配置——Encoder，WriteSyncer，LogLevel。 1.Encoder:编码器(如何写入日志)。我们将使用开箱即用的NewJSONEncoder()，并使用预先设置的ProductionEncoderConfig()。 zapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()) 2.WriterSyncer ：指定日志将写到哪里去。我们使用zapcore.AddSync()函数并且将打开的文件句柄传进去。 file, _ := os.Create(\"./test.log\") writeSyncer := zapcore.AddSync(file) 3.Log Level：哪种级别的日志将被写入。 我们将修改上述部分中的Logger代码，并重写InitLogger()方法。其余方法—main() /SimpleHttpGet()保持不变。 func InitLogger() { writeSyncer := getLogWriter() encoder := getEncoder() core := zapcore.NewCore(encoder, writeSyncer, zapcore.DebugLevel) logger := zap.New(core) sugarLogger = logger.Sugar() } func getEncoder() zapcore.Encoder { return zapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()) } func getLogWriter() zapcore.WriteSyncer { file, _ := os.Create(\"./test.log\")// 可以在后面设置追加等 return zapcore.AddSync(file) } 当使用这些修改过的logger配置调用上述部分的main()函数时，以下输出将打印在文件——test.log中。 {\"level\":\"debug\",\"ts\":1572160754.994731,\"msg\":\"Trying to hit GET request for www.sogo.com\"} {\"level\":\"error\",\"ts\":1572160754.994982,\"msg\":\"Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \\\"\\\"\"} {\"level\":\"debug\",\"ts\":1572160754.994996,\"msg\":\"Trying to hit GET request for http://www.sogo.com\"} {\"level\":\"info\",\"ts\":1572160757.3755069,\"msg\":\"Success! statusCode = 200 OK for URL http://www.sogo.com\"} 将JSON Encoder更改为普通的Log Encoder 现在，我们希望将编码器从JSON Encoder更改为普通Encoder。为此，我们需要将NewJSONEncoder()更改为NewConsoleEncoder()。 return zapcore.NewConsoleEncoder(zap.NewProductionEncoderConfig()) 当使用这些修改过的logger配置调用上述部分的main()函数时，以下输出将打印在文件——test.log中。 1.572161051846623e+09 debug Trying to hit GET request for www.sogo.com 1.572161051846828e+09 error Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \"\" 1.5721610518468401e+09 debug Trying to hit GET request for http://www.sogo.com 1.572161052068744e+09 info Success! statusCode = 200 OK for URL http://www.sogo.com 更改时间编码并添加调用者详细信息 鉴于我们对配置所做的更改，有下面两个问题： 时间是以非人类可读的方式展示，例如1.572161051846623e+09 调用方函数的详细信息没有显示在日志中 我们要做的第一件事是覆盖默认的ProductionConfig()，并进行以下更改: 修改时间编码器 在日志文件中使用大写字母记录日志级别 func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder return zapcore.NewConsoleEncoder(encoderConfig) } 接下来，我们将修改zap logger代码，添加将调用函数信息记录到日志中的功能。为此，我们将在zap.New(..)函数中添加一个Option。 logger := zap.New(core, zap.AddCaller()) 当使用这些修改过的logger配置调用上述部分的main()函数时，以下输出将打印在文件——test.log中。 2019-10-27T15:33:29.855+0800 DEBUG logic/temp2.go:47 Trying to hit GET request for www.sogo.com 2019-10-27T15:33:29.855+0800 ERROR logic/temp2.go:50 Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \"\" 2019-10-27T15:33:29.856+0800 DEBUG logic/temp2.go:47 Trying to hit GET request for http://www.sogo.com 2019-10-27T15:33:30.125+0800 INFO logic/temp2.go:52 Success! statusCode = 200 OK for URL http://www.sogo.com AddCallerSkip 当我们不是直接使用初始化好的logger实例记录日志，而是将其包装成一个函数等，此时日录日志的函数调用链会增加，想要获得准确的调用信息就需要通过AddCallerSkip函数来跳过。 logger := zap.New(core, zap.AddCaller(), zap.AddCallerSkip(1)) 将日志输出到多个位置 我们可以将日志同时输出到文件和终端。 func getLogWriter() zapcore.WriteSyncer { file, _ := os.Create(\"./test.log\") // 利用io.MultiWriter支持文件和终端两个输出目标 ws := io.MultiWriter(file, os.Stdout) return zapcore.AddSync(ws) } 将err日志单独输出到文件 有时候我们除了将全量日志输出到xx.log文件中之外，还希望将ERROR级别的日志单独输出到一个名为xx.err.log的日志文件中。我们可以通过以下方式实现。 func InitLogger() { encoder := getEncoder() // test.log记录全量日志 logF, _ := os.Create(\"./test.log\") c1 := zapcore.NewCore(encoder, zapcore.AddSync(logF), zapcore.DebugLevel) // test.err.log记录ERROR级别的日志 errF, _ := os.Create(\"./test.err.log\") c2 := zapcore.NewCore(encoder, zapcore.AddSync(errF), zap.ErrorLevel) // 使用NewTee将c1和c2合并到core core := zapcore.NewTee(c1, c2) logger = zap.Ne","date":"2023-06-08","objectID":"/posts/gin/gin07/:3:4","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"使用Lumberjack进行日志的切割和归档 Zap本身不支持切割归档日志文件 官方的说法是为了添加日志切割归档功能，我们将使用第三方库Lumberjack来实现。 目前只支持按文件大小切割，原因是按时间切割效率低且不能保证日志数据不被破坏。详情戳https://github.com/natefinch/lumberjack/issues/54。 想按日期切割可以使用github.com/lestrrat-go/file-rotatelogs这个库，虽然目前不维护了，但也够用了。 // 使用file-rotatelogs按天切割日志 import rotatelogs \"github.com/lestrrat-go/file-rotatelogs\" l, _ := rotatelogs.New( filename+\".%Y%m%d%H%M\", rotatelogs.WithMaxAge(30*24*time.Hour), // 最长保存30天 rotatelogs.WithRotationTime(time.Hour*24), // 24小时切割一次 ) zapcore.AddSync(l) ","date":"2023-06-08","objectID":"/posts/gin/gin07/:4:0","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"安装 go get gopkg.in/natefinch/lumberjack.v2 ","date":"2023-06-08","objectID":"/posts/gin/gin07/:4:1","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"zap logger中加入Lumberjack 要在zap中加入Lumberjack支持，我们需要修改WriteSyncer代码。我们将按照下面的代码修改getLogWriter()函数： func getLogWriter() zapcore.WriteSyncer { lumberJackLogger := \u0026lumberjack.Logger{ Filename: \"./test.log\", MaxSize: 10, MaxBackups: 5, MaxAge: 30, Compress: false, } return zapcore.AddSync(lumberJackLogger) } Lumberjack Logger采用以下属性作为输入: Filename: 日志文件的位置 MaxSize：在进行切割之前，日志文件的最大大小（以MB为单位） MaxBackups：保留旧文件的最大个数 MaxAges：保留旧文件的最大天数 Compress：是否压缩/归档旧文件 ","date":"2023-06-08","objectID":"/posts/gin/gin07/:4:2","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["gin"],"content":"测试所有功能 最终，使用Zap/Lumberjack logger的完整示例代码如下： package main import ( \"net/http\" \"gopkg.in/natefinch/lumberjack.v2\" \"go.uber.org/zap\" \"go.uber.org/zap/zapcore\" ) var sugarLogger *zap.SugaredLogger func main() { InitLogger() defer sugarLogger.Sync() simpleHttpGet(\"www.sogo.com\") simpleHttpGet(\"http://www.sogo.com\") } func InitLogger() { writeSyncer := getLogWriter() encoder := getEncoder() core := zapcore.NewCore(encoder, writeSyncer, zapcore.DebugLevel) logger := zap.New(core, zap.AddCaller()) sugarLogger = logger.Sugar() } func getEncoder() zapcore.Encoder { encoderConfig := zap.NewProductionEncoderConfig() encoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder encoderConfig.EncodeLevel = zapcore.CapitalLevelEncoder return zapcore.NewConsoleEncoder(encoderConfig) } func getLogWriter() zapcore.WriteSyncer { lumberJackLogger := \u0026lumberjack.Logger{ Filename: \"./test.log\", MaxSize: 1, MaxBackups: 5, MaxAge: 30, Compress: false, } return zapcore.AddSync(lumberJackLogger) } func simpleHttpGet(url string) { sugarLogger.Debugf(\"Trying to hit GET request for %s\", url) resp, err := http.Get(url) if err != nil { sugarLogger.Errorf(\"Error fetching URL %s : Error = %s\", url, err) } else { sugarLogger.Infof(\"Success! statusCode = %s for URL %s\", resp.Status, url) resp.Body.Close() } } 执行上述代码，下面的内容会输出到文件——test.log中。 2019-10-27T15:50:32.944+0800 DEBUG logic/temp2.go:48 Trying to hit GET request for www.sogo.com 2019-10-27T15:50:32.944+0800 ERROR logic/temp2.go:51 Error fetching URL www.sogo.com : Error = Get www.sogo.com: unsupported protocol scheme \"\" 2019-10-27T15:50:32.944+0800 DEBUG logic/temp2.go:48 Trying to hit GET request for http://www.sogo.com 2019-10-27T15:50:33.165+0800 INFO logic/temp2.go:53 Success! statusCode = 200 OK for URL http://www.sogo.com 同时，可以在main函数中循环记录日志，测试日志文件是否会自动切割和归档（日志文件每1MB会切割并且在当前目录下最多保存5个备份）。 至此，我们总结了如何将Zap日志程序集成到Go应用程序项目中。 ","date":"2023-06-08","objectID":"/posts/gin/gin07/:4:3","tags":["gin"],"title":"Go中使用Zap","uri":"/posts/gin/gin07/"},{"categories":["Go每日一练"],"content":"Day21 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:1:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面的两个切片声明中有什么区别？哪个更可取？ A. var a []int B. a := []int{} 参考答案及解析：A 声明的是 nil 切片；B 声明的是长度和容量都为 0 的空切片。第一种切片声明不会分配内存，优先选择。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:1:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.A、B、C、D哪些选项有语法错误？ type S struct { } func f(x interface{}) { } func g(x *interface{}) { } func main() { s := S{} p := \u0026s f(s) //A g(s) //B f(p) //C g(p) //D } 参考答案及解析：BD。函数参数为 interface{} 时可以接收任何类型的参数，包括用户自定义类型等，即使是接收指针类型也用 interface{}，而不是使用 *interface{}。 永远不要使用一个指针指向一个接口类型，因为它已经是一个指针。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:1:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"3.下面A、B两处应该填入什么代码，才能确保顺利打印出结果？ type S struct { m string } func f() *S { return __ //A } func main() { p := __ //B fmt.Println(p.m) //print \"foo\" } 参考答案及解析： A. \u0026S{\"foo\"} B. *f() 或者 f() f() 函数返回参数是指针类型，所以可以用 \u0026 取结构体的指针；B 处，如果填 *f()，则 p 是 S 类型？？？？？？？？；如果填 f()，则 p 是 *S 类型，不过都可以使用 p.m 取得结构体的成员。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:1:3","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day22 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:2:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面的代码有几处语法问题，各是什么？ package main import ( \"fmt\" ) func main() { var x string = nil if x == nil { x = \"default\" } fmt.Println(x) } 参考答案及解析：两个地方有语法问题。golang 的字符串类型是不能赋值 nil 的，也不能跟 nil 比较。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:2:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.return之后的defer语句会执行吗，下面这段代码输出什么？ var a bool = true func main() { defer func(){ fmt.Println(\"1\") }() if a == true { fmt.Println(\"2\") return } defer func(){ fmt.Println(\"3\") }() } 参考答案及解析：2 1。defer 关键字后面的函数或者方法想要执行必须先注册，return 之后的 defer 是不能注册的， 也就不能执行后面的函数或方法。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:2:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day23 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:3:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？为什么？ func main() { s1 := []int{1, 2, 3} s2 := s1[1:] s2[1] = 4 fmt.Println(s1) s2 = append(s2, 5, 6, 7) fmt.Println(s1) } [1 2 4] [1 2 4] 我们知道，golang 中切片底层的数据结构是数组。当使用 s1[1:] 获得切片 s2，和 s1 共享同一个底层数组，这会导致 s2[1] = 4 语句影响 s1。 而 append 操作会导致底层数组扩容，生成新的数组，因此追加数据后的 s2 不会影响 s1。 但是为什么对 s2 赋值后影响的却是 s1 的第三个元素呢？这是因为切片 s2 是从数组的第二个元素开始，s2 索引为 1 的元素对应的是 s1 索引为 2 的元素。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:3:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.下面选项正确的是？ func main() { if a := 1; false { } else if b := 2; false { } else { println(a, b) } } A. 1 2 B. compilation error 参考答案及解析：A。知识点：代码块和变量作用域。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:3:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"延伸 一、代码块 在 Go 语言中，代码块（也叫句法块）一般就是一个由花括号括起来的区域，里面可以包含表达式和语句。Go 语言本身以及我们编写的代码共同形成了一个非常大的代码块，也叫全域代码块。这主要体现在，只要是公开的全局变量，都可以被任何代码所使用。 相对小一些的代码块是代码包，一个代码包可以包含许多子代码包，所以这样的代码块也可以很大。 接下来，每个源码文件也都是一个代码块，每个函数也是一个代码块，每个if语句、for语句、switch语句和select语句都是一个代码块。甚至，switch或select语句中的case子句也都是独立的代码块。走个极端，我就在main函数中写一对紧挨着的花括号也算一个代码块：叫“空代码块”。 Go 语言的代码块是一层套一层的，就像大圆套小圆。 二、作用域 声明语句的作用域是指源代码中可以有效使用这个名字的范围。也就是说，我们声明的函数也好，变量也好，都是有它的“适用范围”的，弄清楚这个范围很重要！一个程序实体的作用域总是会被限制在某个代码块中，而这个作用域最大的用处，就是对程序实体的访问权限的控制。 这里需要重点区分下另外一个概念：生命周期！这两个完全是不同的概念，不要混为一谈。 作用域：对应的是一个源代码的文本区域，它是一个编译时的属性。 生命周期：是指程序运行时变量存在的有效时间段，在此时间区域内它可以被程序的其他部分引用，是一个运行时的概念。 句法块内部声明的名字是无法被外部块访问的。这个块决定了内部声明的名字的作用域范围。声明语句对应的词法域决定了作用域范围的大小。 当编译器遇到一个名字引用时，它会对其定义进行查找，查找过程从最内层的词法域向全局的作用域（从内到外）进行。 通过下面的示例代码，感受下作用域： package main import \"fmt\" var block = \"package\" func main() { block := \"function\" { block := \"inner\" fmt.Printf(\"The block is %s.\\n\", block) } fmt.Printf(\"The block is %s.\\n\", block) } 这段代码中有四个代码块，它们是：全域代码块、main包代表的代码块、main函数代表的代码块，以及在main函数中的一个用花括号包起来的代码块。最后执行之后的结果如下： The block is inner. The block is function. 首先，代码引用变量的时候总会最优先查找当前代码块中的那个变量 其次，如果当前代码块中没有声明以此为名的变量，那么程序会沿着代码块的嵌套关系，从直接包含当前代码块的那个代码块开始，一层一层地查找。 一般情况下，程序会一直查到当前代码包代表的代码块。如果仍然找不到，那么 Go 语言的编译器就会报错了。 所以，虽然通过var block = “package\"声明的变量作用域是整个main代码包，但是在main函数中，它却被那两个同名的变量“屏蔽”了。相似的，虽然main函数首先声明的block的作用域，是整个main函数，但是在最内层的那个代码块中，它却是不可能被引用到的。反过来讲，最内层代码块中的block也不可能被该块之外的代码引用到。 三、捕获迭代变量的“坑” 这里特别强调一个Go词法作用域的陷阱。请务必仔细的阅读，弄清楚发生问题的原因。相信你一定在这里踩过雷！ 首先看下下面的程序示例：你被要求首先创建一些目录，再将目录删除。在下面的例子中我们用函数值来完成删除操作。下面的示例代码需要引入os包。为了使代码简单，我们忽略了所有的异常处理。 var rmdirs []func() for _, d := range tempDirs() { dir := d // NOTE: necessary! os.MkdirAll(dir, 0755) // creates parent directories too rmdirs = append(rmdirs, func() { os.RemoveAll(dir) }) } // ...do some work… for _, rmdir := range rmdirs { rmdir() // clean up } 你可能会感到困惑，为什么要在循环体中用循环变量d赋值一个新的局部变量，而不是像下面的代码一样直接使用循环变量dir。需要注意，下面的代码是错误的。 var rmdirs []func() for _, dir := range tempDirs() { os.MkdirAll(dir, 0755) rmdirs = append(rmdirs, func() { os.RemoveAll(dir) // NOTE: incorrect! }) } 问题的原因在于循环变量的作用域。在上面的程序中，for循环语句引入了新的词法块，循环变量dir在这个词法块中被声明。在该循环中生成的所有函数值都共享相同的循环变量。需要注意，函数值中记录的是循环变量的内存地址，而不是循环变量某一时刻的值。以dir为例，后续的迭代会不断更新dir的值，当删除操作执行时，for循环已完成，dir中存储的值等于最后一次迭代的值。这意味着，每次对os.RemoveAll的调用删除的都是相同的目录（这说是还不是下面部分的代码）。 所以，看出来创建一个与循环变量同名的局部变量的重要性和合理性了吧！ 不止在range中，在下面的例子中，依然存在这个问题。 var rmdirs []func() dirs := tempDirs() for i := 0; i \u003c len(dirs); i++ { os.MkdirAll(dirs[i], 0755) // OK rmdirs = append(rmdirs, func() { os.RemoveAll(dirs[i]) // NOTE: incorrect! }) } ","date":"2023-06-08","objectID":"/posts/go/day21-30/:3:3","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day24 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:4:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？ func main() { m := map[int]string{0:\"zero\",1:\"one\"} for k,v := range m { fmt.Println(k,v) } } 参考答案及解析： 0 zero 1 one // 或者 1 one 0 zero map 的输出是无序的。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:4:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ func main() { a := 1 b := 2 defer calc(\"1\", a, calc(\"10\", a, b)) a = 0 defer calc(\"2\", a, calc(\"20\", a, b)) b = 1 } func calc(index string, a, b int) int { ret := a + b fmt.Println(index, a, b, ret) return ret } 参考答案及解析： 10 1 2 3 20 0 2 2 2 0 2 2 1 1 3 4 程序执行到 main() 函数三行代码的时候，会先执行 calc() 函数的 b 参数，即：calc(“10”,a,b)，输出：10 1 2 3，得到值 3，因为 defer 定义的函数是延迟函数，故 calc(“1”,1,3) 会被延迟执行； 程序执行到第五行的时候，同样先执行 calc(“20”,a,b) 输出：20 0 2 2 得到值 2，同样将 calc(“2”,0,2) 延迟执行； 程序执行到末尾的时候，按照栈先进后出的方式依次执行：calc(“2”,0,2)，calc(“1”,1,3)，则就依次输出：2 0 2 2，1 1 3 4。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:4:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day25 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:5:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？为什么？ func (i int) PrintInt () { fmt.Println(i) } func main() { var i int = 1 i.PrintInt() } A. 1 B. compilation error 参考答案及解析：B。基于类型创建的方法必须定义在同一个包内，上面的代码基于 int 类型创建了 PrintInt() 方法，由于 int 类型和方法 PrintInt() 定义在不同的包内，所以编译出错。 解决的办法可以定义一种新的类型： type Myint int func (i Myint) PrintInt () { fmt.Println(i) } func main() { var i Myint = 1 i.PrintInt() } ","date":"2023-06-08","objectID":"/posts/go/day21-30/:5:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？为什么？ type People interface { Speak(string) string } type Student struct{} func (stu *Student) Speak(think string) (talk string) { if think == \"speak\" { talk = \"speak\" } else { talk = \"hi\" } return } func main() { var peo People = Student{} think := \"speak\" fmt.Println(peo.Speak(think)) } A. speak B. compilation error 参考答案及解析：B。编译错误 Student does not implement People (Speak method has pointer receiver)，值类型 Student 没有实现接口的 Speak() 方法，而是指针类型 *Student 实现该方法。应当改为 var peo People = \u0026Student{}或者stu := new(Student) var peo People = stu ","date":"2023-06-08","objectID":"/posts/go/day21-30/:5:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day26 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:6:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？ const ( a = iota b = iota ) const ( name = \"name\" c = iota d = iota ) func main() { fmt.Println(a) fmt.Println(b) fmt.Println(c) fmt.Println(d) } 参考答案及解析：0 1 1 2。知识点：iota 的用法。 iota 是 golang 语言的常量计数器，只能在常量的表达式中使用。 iota 在 const 关键字出现时将被重置为0，const中每新增一行常量声明将使 iota 计数一次。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:6:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"延伸： iota是golang语言的常量计数器,只能在常量的表达式中使用。 iota在const关键字出现时将被重置为0(const内部的第一行之前)，const中每新增一行常量声明将使iota计数一次(iota可理解为const语句块中的行索引)。 使用iota能简化定义，在定义枚举时很有用。 举例如下： 1、iota只能在常量的表达式中使用。 fmt.Println(iota) 编译错误： undefined: iota 2、每次 const 出现时，都会让 iota 初始化为0. const a = iota // a=0 const ( b = iota //b=0 c //c=1 ) 3、自定义类型 自增长常量经常包含一个自定义枚举类型，允许你依靠编译器完成自增设置。 type Stereotype int const ( TypicalNoob Stereotype = iota // 0 TypicalHipster // 1 TypicalUnixWizard // 2 TypicalStartupFounder // 3 ) 4、可跳过的值 设想你在处理消费者的音频输出。音频可能无论什么都没有任何输出，或者它可能是单声道，立体声，或是环绕立体声的。 这可能有些潜在的逻辑定义没有任何输出为 0，单声道为 1，立体声为 2，值是由通道的数量提供。 所以你给 Dolby 5.1 环绕立体声什么值。 一方面，它有6个通道输出，但是另一方面，仅仅 5 个通道是全带宽通道（因此 5.1 称号 - 其中 .1 表示的是低频效果通道）。 不管怎样，我们不想简单的增加到 3。 我们可以使用下划线跳过不想要的值。 type AudioOutput int const ( OutMute AudioOutput = iota // 0 OutMono // 1 OutStereo // 2 _ _ OutSurround // 5 ) 5、位掩码表达式 type Allergen int const ( IgEggs Allergen = 1 \u003c\u003c iota // 1 \u003c\u003c 0 which is 00000001 IgChocolate // 1 \u003c\u003c 1 which is 00000010 IgNuts // 1 \u003c\u003c 2 which is 00000100 IgStrawberries // 1 \u003c\u003c 3 which is 00001000 IgShellfish // 1 \u003c\u003c 4 which is 00010000 ) 这个工作是因为当你在一个 const 组中仅仅有一个标示符在一行的时候，它将使用增长的 iota 取得前面的表达式并且再运用它，。在 Go 语言的 spec 中， 这就是所谓的隐性重复最后一个非空的表达式列表。 如果你对鸡蛋，巧克力和海鲜过敏，把这些 bits 翻转到 “on” 的位置（从左到右映射 bits）。然后你将得到一个 bit 值 00010011，它对应十进制的 19。 fmt.Println(IgEggs | IgChocolate | IgShellfish) // output: // 19 6、定义数量级 type ByteSize float64 const ( _ = iota // ignore first value by assigning to blank identifier KB ByteSize = 1 \u003c\u003c (10 * iota) // 1 \u003c\u003c (10*1) MB // 1 \u003c\u003c (10*2) GB // 1 \u003c\u003c (10*3) TB // 1 \u003c\u003c (10*4) PB // 1 \u003c\u003c (10*5) EB // 1 \u003c\u003c (10*6) ZB // 1 \u003c\u003c (10*7) YB // 1 \u003c\u003c (10*8) ) 7、定义在一行的情况 const ( Apple, Banana = iota + 1, iota + 2 Cherimoya, Durian Elderberry, Fig ) iota 在下一行增长，而不是立即取得它的引用。 // Apple: 1 // Banana: 2 // Cherimoya: 2 // Durian: 3 // Elderberry: 3 // Fig: 4 8、中间插队 const ( i = iota j = 3.14 k = iota l ) 那么打印出来的结果是 i=0,j=3.14,k=2,l=3 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:6:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？为什么？ type People interface { Show() } type Student struct{} func (stu *Student) Show() { } func main() { var s *Student if s == nil { fmt.Println(\"s is nil\") } else { fmt.Println(\"s is not nil\") } var p People = s if p == nil { fmt.Println(\"p is nil\") } else { fmt.Println(\"p is not nil\") } } 参考答案及解析：s is nil 和 p is not nil。这道题会不会有点诧异，我们分配给变量 p 的值明明是 nil，然而 p 却不是 nil。记住一点，当且仅当动态值和动态类型都为 nil 时，接口类型值才为 nil。上面的代码，给变量 p 赋值之后，p 的动态值是 nil，但是动态类型却是 *Student，是一个 nil 指针，所以相等条件不成。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:6:3","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day27 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:7:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？ type Direction int const ( North Direction = iota East South West ) func (d Direction) String() string { return [...]string{\"North\", \"East\", \"South\", \"West\"}[d] } func main() { fmt.Println(South) } 参考答案及解析：South。知识点：iota 的用法、类型的 String() 方法。 根据 iota 的用法推断出 South 的值是 2；另外，如果类型定义了 String() 方法，当使用 fmt.Printf()、fmt.Print() 和 fmt.Println() 会自动使用 String() 方法，实现字符串的打印。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:7:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么 type Math struct { x, y int } var m = map[string]Math{ \"foo\": Math{2, 3}, } func main() { m[\"foo\"].x = 4 fmt.Println(m[\"foo\"].x) } A. 4 B. compilation error 参考答案及解析：B，编译报错 cannot assign to struct field m[“foo”].x in map。错误原因：对于类似 X = Y的赋值操作，必须知道 X 的地址，才能够将 Y 的值赋给 X，但 go 中的 map 的 value 本身是不可寻址的。 有两个解决办法： 1.使用临时变量 type Math struct { x, y int } var m = map[string]Math{ \"foo\": Math{2, 3}, } func main() { tmp := m[\"foo\"] tmp.x = 4 m[\"foo\"] = tmp fmt.Println(m[\"foo\"].x) } 2.修改数据结构 type Math struct { x, y int } var m = map[string]*Math{ \"foo\": \u0026Math{2, 3}, } func main() { m[\"foo\"].x = 4 fmt.Println(m[\"foo\"].x) fmt.Printf(\"%#v\", m[\"foo\"]) // %#v 格式化输出详细信息 } ","date":"2023-06-08","objectID":"/posts/go/day21-30/:7:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day28 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:8:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面的代码有什么问题？ func main() { fmt.Println([...]int{1} == [2]int{1}) fmt.Println([]int{1} == []int{1}) } 参考答案及解析：有两处错误 go 中不同类型是不能比较的，而数组长度是数组类型的一部分，所以 […]int{1} 和 [2]int{1} 是两种不同的类型，不能比较； 切片是不能比较的；（不可比较的还有map、function） ","date":"2023-06-08","objectID":"/posts/go/day21-30/:8:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ var p *int func foo() (*int, error) { var i int = 5 return \u0026i, nil } func bar() { //use p fmt.Println(*p) } func main() { p, err := foo() if err != nil { fmt.Println(err) return } bar() fmt.Println(*p) } A. 5 5 B. runtime error 参考答案及解析：B。知识点：变量作用域。问题出在操作符:=，对于使用:=定义的变量，如果新变量与同名已定义的变量不在同一个作用域中，那么 Go 会新定义这个变量。对于本例来说，main() 函数里的 p 是新定义的变量，会遮住全局变量 p，导致执行到bar()时程序，全局变量 p 依然还是 nil，程序随即 Crash。 正确的做法是将 main() 函数修改为： func main() { var err error p, err = foo() if err != nil { fmt.Println(err) return } bar() fmt.Println(*p) } 这道题目引自 Tony Bai 老师的一篇文章，原文讲的很详细，推荐。 https://tonybai.com/2015/01/13/a-hole-about-variable-scope-in-golang/ ","date":"2023-06-08","objectID":"/posts/go/day21-30/:8:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day29 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:9:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面这段代码能否正常结束？ func main() { v := []int{1, 2, 3} for i := range v { v = append(v, i) } } 参考答案及解析：不会出现死循环，能正常结束。 循环次数在循环开始前就已经确定，循环内改变切片的长度，不影响循环次数。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:9:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？为什么？ func main() { var m = [...]int{1, 2, 3} for i, v := range m { go func() { fmt.Println(i, v) }() } time.Sleep(time.Second * 3) } 参考答案及解析： 2 3 2 3 2 3 for range 使用短变量声明(:=)的形式迭代变量，需要注意的是，变量 i、v 在每次循环体中都会被重用，而不是重新声明。 各个 goroutine 中输出的 i、v 值都是 for range 循环结束后的 i、v 最终值，而不是各个goroutine启动时的i, v值。可以理解为闭包引用，使用的是上下文环境的值。 两种可行的 fix 方法: 1.使用函数传递 for i, v := range m { go func(i,v int) { fmt.Println(i, v) }(i,v) } 2.使用临时变量保留当前值 for i, v := range m { i := i // 这里的 := 会重新声明变量，而不是重用 v := v go func() { fmt.Println(i, v) }() } 引自：https://tonybai.com/2015/09/17/7-things-you-may-not-pay-attation-to-in-go/ ","date":"2023-06-08","objectID":"/posts/go/day21-30/:9:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"Day30 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:10:0","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？（again） func f(n int) (r int) { defer func() { r += n recover() }() var f func() defer f() f = func() { r += 2 } return n + 1 } func main() { fmt.Println(f(3)) } 参考答案及解析：7。根据 5 年 Gopher 都不知道的 defer 细节，你别再掉进坑里！ 提到的“三步拆解法”，第一步执行r = n +1，接着执行第二个 defer，由于此时 f() 未定义，引发异常，随即执行第一个 defer，异常被 recover()，程序正常执行，最后 return。 此题引自知识星球《Go项目实战》 麻了麻了麻了，今天想不动了 回头再仔细想。 ","date":"2023-06-08","objectID":"/posts/go/day21-30/:10:1","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ func main() { var a = [5]int{1, 2, 3, 4, 5} var r [5]int for i, v := range a { if i == 0 { a[1] = 12 a[2] = 13 } r[i] = v } fmt.Println(\"r = \", r) fmt.Println(\"a = \", a) } r = [1 2 3 4 5] a = [1 12 13 4 5] range 表达式是副本参与循环，就是说例子中参与循环的是 a 的副本，而不是真正的 a。就这个例子来说，假设 b 是 a 的副本，则 range 循环代码是这样的 for i, v := range b { if i == 0 { a[1] = 12 a[2] = 13 } r[i] = v } 因此无论 a 被如何修改，其副本 b 依旧保持原值，并且参与循环的是 b，因此 v 从 b 中取出的仍旧是 a 的原值，而非修改后的值。 如果想要 r 和 a 一样输出，修复办法： func main() { var a = [5]int{1, 2, 3, 4, 5} var r [5]int for i, v := range \u0026a { if i == 0 { a[1] = 12 a[2] = 13 } r[i] = v } fmt.Println(\"r = \", r) fmt.Println(\"a = \", a) } 输出： r = [1 12 13 4 5] a = [1 12 13 4 5] 修复代码中，使用 *[5]int 作为 range 表达式，其副本依旧是一个指向原数组 a 的指针，因此后续所有循环中均是 \u0026a 指向的原数组亲自参与的，因此 v 能从 \u0026a 指向的原数组中取出 a 修改后的值。 引自：https://tonybai.com/2015/09/17/7-things-you-may-not-pay-attation-to-in-go/ ","date":"2023-06-08","objectID":"/posts/go/day21-30/:10:2","tags":["go","面试"],"title":"Go Exercises(Day21-30)","uri":"/posts/go/day21-30/"},{"categories":["gin"],"content":"go操作redis ","date":"2023-06-02","objectID":"/posts/gin/gin06/:0:0","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"Redis介绍 Redis是一个开源的内存数据库，Redis提供了多种不同类型的数据结构，很多业务场景下的问题都可以很自然地映射到这些数据结构上。除此之外，通过复制、持久化和客户端分片等特性，我们可以很方便地将Redis扩展成一个能够包含数百GB数据、每秒处理上百万次请求的系统。 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:1:0","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"Redis支持的数据结构 Redis支持诸如字符串（string）、哈希（hashe）、列表（list）、集合（set）、带范围查询的排序集合（sorted set）、bitmap、hyperloglog、带半径查询的地理空间索引（geospatial index）和流（stream）等数据结构。 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:1:1","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"Redis应用场景 缓存系统，减轻主数据库（MySQL）的压力。 计数场景，比如微博、抖音中的关注数和粉丝数。 热门排行榜，需要排序的场景特别适合使用ZSET。 利用 LIST 可以实现队列的功能。 利用 HyperLogLog 统计UV、PV等数据。 使用 geospatial index 进行地理位置相关查询。 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:1:2","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"准备Redis环境 读者可以选择在本机安装 redis 或使用云数据库，这里直接使用Docker启动一个 redis 环境，方便学习使用。 使用下面的命令启动一个名为 redis507 的 5.0.7 版本的 redis server环境。 docker run --name redis507 -p 6379:6379 -d redis:5.0.7 **注意：**此处的版本、容器名和端口号可以根据自己需要设置。 启动一个 redis-cli 连接上面的 redis server。 docker run -it --network host --rm redis:5.0.7 redis-cli ","date":"2023-06-02","objectID":"/posts/gin/gin06/:1:3","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"go-redis库 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:2:0","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"安装 Go 社区中目前有很多成熟的 redis client 库，比如https://github.com/gomodule/redigo 和https://github.com/go-redis/redis，读者可以自行选择适合自己的库。以下使用 go-redis 这个库来操作 Redis 数据库。 使用以下命令下安装 go-redis 库。 go get github.com/go-redis/redis/v8 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:2:1","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"连接 普通连接模式 go-redis 库中使用 redis.NewClient 函数连接 Redis 服务器。 rdb := redis.NewClient(\u0026redis.Options{ Addr: \"localhost:6379\", Password: \"\", // 密码 DB: 0, // 数据库 PoolSize: 20, // 连接池大小 }) 除此之外，还可以使用 redis.ParseURL 函数从表示数据源的字符串中解析得到 Redis 服务器的配置信息。 opt, err := redis.ParseURL(\"redis://\u003cuser\u003e:\u003cpass\u003e@localhost:6379/\u003cdb\u003e\") if err != nil { panic(err) } rdb := redis.NewClient(opt) TLS连接模式 如果使用的是 TLS 连接方式，则需要使用 tls.Config 配置。 rdb := redis.NewClient(\u0026redis.Options{ TLSConfig: \u0026tls.Config{ MinVersion: tls.VersionTLS12, // Certificates: []tls.Certificate{cert}, // ServerName: \"your.domain.com\", }, }) Redis Sentinel模式(哨兵模式) 使用下面的命令连接到由 Redis Sentinel 管理的 Redis 服务器。 rdb := redis.NewFailoverClient(\u0026redis.FailoverOptions{ MasterName: \"master-name\", SentinelAddrs: []string{\":9126\", \":9127\", \":9128\"}, }) Redis Cluster模式（集群模式） 使用下面的命令连接到 Redis Cluster，go-redis 支持按延迟或随机路由命令。 rdb := redis.NewClusterClient(\u0026redis.ClusterOptions{ Addrs: []string{\":7000\", \":7001\", \":7002\", \":7003\", \":7004\", \":7005\"}, // 若要根据延迟或随机路由命令，请启用以下命令之一 // RouteByLatency: true, // RouteRandomly: true, }) ","date":"2023-06-02","objectID":"/posts/gin/gin06/:2:2","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"基本使用 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:3:0","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"set/get示例 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:3:1","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"执行命令 下面的示例代码演示了 go-redis 库的基本使用。 // doCommand go-redis基本使用示例 func doCommand() { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() // 执行命令获取结果 val, err := rdb.Get(ctx, \"key\").Result() fmt.Println(val, err) // 先获取到命令对象 cmder := rdb.Get(ctx, \"key\") fmt.Println(cmder.Val()) // 获取值 fmt.Println(cmder.Err()) // 获取错误 // 直接执行命令获取错误 err = rdb.Set(ctx, \"key\", 10, time.Hour).Err() // 直接执行命令获取值 value := rdb.Get(ctx, \"key\").Val() fmt.Println(value) } ","date":"2023-06-02","objectID":"/posts/gin/gin06/:3:2","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"执行任意命令 go-redis 还提供了一个执行任意命令或自定义命令的 Do 方法，特别是一些 go-redis 库暂时不支持的命令都可以使用该方法执行。具体使用方法如下。 // doDemo rdb.Do 方法使用示例 func doDemo() { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() // 直接执行命令获取错误 err := rdb.Do(ctx, \"set\", \"key\", 10, \"EX\", 3600).Err() fmt.Println(err) // 执行命令获取结果 val, err := rdb.Do(ctx, \"get\", \"key\").Result() fmt.Println(val, err) } ","date":"2023-06-02","objectID":"/posts/gin/gin06/:3:3","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"redis.Nil go-redis 库提供了一个 redis.Nil 错误来表示 Key 不存在的错误。因此在使用 go-redis 时需要注意对返回错误的判断。在某些场景下我们应该区别处理 redis.Nil 和其他不为 nil 的错误。 // getValueFromRedis redis.Nil判断 func getValueFromRedis(key, defaultValue string) (string, error) { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() val, err := rdb.Get(ctx, key).Result() if err != nil { // 如果返回的错误是key不存在 if errors.Is(err, redis.Nil) { return defaultValue, nil } // 出其他错了 return \"\", err } return val, nil } ","date":"2023-06-02","objectID":"/posts/gin/gin06/:3:4","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"其他示例 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:4:0","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"zset示例（有序集合，常用来做排行榜等） 下面的示例代码演示了如何使用 go-redis 库操作 zset。 // zsetDemo 操作zset示例 func zsetDemo() { // key zsetKey := \"language_rank\" // value languages := []*redis.Z{ {Score: 90.0, Member: \"Golang\"}, {Score: 98.0, Member: \"Java\"}, {Score: 95.0, Member: \"Python\"}, {Score: 97.0, Member: \"JavaScript\"}, {Score: 99.0, Member: \"C/C++\"}, } ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() // ZADD err := rdb.ZAdd(ctx, zsetKey, languages...).Err() if err != nil { fmt.Printf(\"zadd failed, err:%v\\n\", err) return } fmt.Println(\"zadd success\") // 把Golang的分数加10 newScore, err := rdb.ZIncrBy(ctx, zsetKey, 10.0, \"Golang\").Result() if err != nil { fmt.Printf(\"zincrby failed, err:%v\\n\", err) return } fmt.Printf(\"Golang's score is %f now.\\n\", newScore) // 取分数最高的3个 ret := rdb.ZRevRangeWithScores(ctx, zsetKey, 0, 2).Val() for _, z := range ret { fmt.Println(z.Member, z.Score) } // 取95~100分的 op := \u0026redis.ZRangeBy{ Min: \"95\", Max: \"100\", } ret, err = rdb.ZRangeByScoreWithScores(ctx, zsetKey, op).Result() if err != nil { fmt.Printf(\"zrangebyscore failed, err:%v\\n\", err) return } for _, z := range ret { fmt.Println(z.Member, z.Score) } } 执行上面的函数将得到如下输出结果。 zadd success Golang's score is 100.000000 now. Golang 100 C/C++ 99 Java 98 Python 95 JavaScript 97 Java 98 C/C++ 99 Golang 100 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:4:1","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"扫描或遍历所有key 你可以使用KEYS prefix:* 命令按前缀获取所有 key。 vals, err := rdb.Keys(ctx, \"prefix*\").Result() 但是如果需要扫描数百万的 key ，那速度就会比较慢。这种场景下你可以使用Scan 命令来遍历所有符合要求的 key。 // scanKeysDemo1 按前缀查找所有key示例 func scanKeysDemo1() { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() var cursor uint64 for { var keys []string var err error // 按前缀扫描key keys, cursor, err = rdb.Scan(ctx, cursor, \"prefix:*\", 0).Result() if err != nil { panic(err) } for _, key := range keys { fmt.Println(\"key\", key) } if cursor == 0 { // no more keys break } } } Go-redis 允许将上面的代码简化为如下示例。 // scanKeysDemo2 按前缀扫描key示例 func scanKeysDemo2() { ctx, cancel := context.WithTimeout(context.Background(), 500*time.Millisecond) defer cancel() // 按前缀扫描key iter := rdb.Scan(ctx, 0, \"prefix:*\", 0).Iterator() for iter.Next(ctx) { fmt.Println(\"keys\", iter.Val()) } if err := iter.Err(); err != nil { panic(err) } } 例如，我们可以写出一个将所有匹配指定模式的 key 删除的示例。 // delKeysByMatch 按match格式扫描所有key并删除 func delKeysByMatch(match string, timeout time.Duration) { ctx, cancel := context.WithTimeout(context.Background(), timeout) defer cancel() iter := rdb.Scan(ctx, 0, match, 0).Iterator() for iter.Next(ctx) { err := rdb.Del(ctx, iter.Val()).Err() if err != nil { panic(err) } } if err := iter.Err(); err != nil { panic(err) } } 此外，对于 Redis 中的 set、hash、zset 数据类型，go-redis 也支持类似的遍历方法。 iter := rdb.SScan(ctx, \"set-key\", 0, \"prefix:*\", 0).Iterator() iter := rdb.HScan(ctx, \"hash-key\", 0, \"prefix:*\", 0).Iterator() iter := rdb.ZScan(ctx, \"sorted-hash-key\", 0, \"prefix:*\", 0).Iterator( ","date":"2023-06-02","objectID":"/posts/gin/gin06/:4:2","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"Pipeline pipeline 注意pipeline适用的场景是当我多个命令前后互不影响的时候，才可以放到一起进行操作。 Redis Pipeline 允许通过使用单个 client-server-client 往返执行多个命令来提高性能。区别于一个接一个地执行100个命令，你可以将这些命令放入 pipeline 中，然后使用1次读写操作像执行单个命令一样执行它们。这样做的好处是节省了执行命令的网络往返时间（RTT）。 y在下面的示例代码中演示了使用 pipeline 通过一个 write + read 操作来执行多个命令。 pipe := rdb.Pipeline() incr := pipe.Incr(ctx, \"pipeline_counter\") pipe.Expire(ctx, \"pipeline_counter\", time.Hour) cmds, err := pipe.Exec(ctx) if err != nil { panic(err) } // 在执行pipe.Exec之后才能获取到结果 fmt.Println(incr.Val()) 上面的代码相当于将以下两个命令一次发给 Redis Server 端执行，与不使用 Pipeline 相比能减少一次RTT。 INCR pipeline_counter EXPIRE pipeline_counts 3600 或者，你也可以使用Pipelined 方法，它会在函数退出时调用 Exec。 var incr *redis.IntCmd cmds, err := rdb.Pipelined(ctx, func(pipe redis.Pipeliner) error { incr = pipe.Incr(ctx, \"pipelined_counter\") pipe.Expire(ctx, \"pipelined_counter\", time.Hour) return nil }) if err != nil { panic(err) } // 在pipeline执行后获取到结果 fmt.Println(incr.Val()) 我们可以遍历 pipeline 命令的返回值依次获取每个命令的结果。下方的示例代码中使用pipiline一次执行了100个 Get 命令，在pipeline 执行后遍历取出100个命令的执行结果。 cmds, err := rdb.Pipelined(ctx, func(pipe redis.Pipeliner) error { for i := 0; i \u003c 100; i++ { pipe.Get(ctx, fmt.Sprintf(\"key%d\", i)) } return nil }) if err != nil { panic(err) } for _, cmd := range cmds { fmt.Println(cmd.(*redis.StringCmd).Val()) } 在那些我们需要一次性执行多个命令的场景下，就可以考虑使用 pipeline 来优化。 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:5:0","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"事务 Redis 是单线程执行命令的，因此单个命令始终是原子的，但是来自不同客户端的两个给定命令可以依次执行，例如在它们之间交替执行。但是，Multi/exec能够确保在multi/exec两个语句之间的命令之间没有其他客户端正在执行命令。 在这种场景我们需要使用 TxPipeline 或 TxPipelined 方法将 pipeline 命令使用 MULTI 和EXEC包裹起来。 // TxPipeline demo pipe := rdb.TxPipeline() incr := pipe.Incr(ctx, \"tx_pipeline_counter\") pipe.Expire(ctx, \"tx_pipeline_counter\", time.Hour) _, err := pipe.Exec(ctx) fmt.Println(incr.Val(), err) // TxPipelined demo var incr2 *redis.IntCmd _, err = rdb.TxPipelined(ctx, func(pipe redis.Pipeliner) error { incr2 = pipe.Incr(ctx, \"tx_pipeline_counter\") pipe.Expire(ctx, \"tx_pipeline_counter\", time.Hour) return nil }) fmt.Println(incr2.Val(), err) 上面代码相当于在一个RTT下执行了下面的redis命令： MULTI INCR pipeline_counter EXPIRE pipeline_counts 3600 EXEC ","date":"2023-06-02","objectID":"/posts/gin/gin06/:6:0","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"Watch 我们通常搭配 WATCH命令来执行事务操作。从使用WATCH命令监视某个 key 开始，直到执行EXEC命令的这段时间里，如果有其他用户抢先对被监视的 key 进行了替换、更新、删除等操作，那么当用户尝试执行EXEC的时候，事务将失败并返回一个错误，用户可以根据这个错误选择重试事务或者放弃事务。 Watch方法接收一个函数和一个或多个key作为参数。 Watch(fn func(*Tx) error, keys ...string) error 下面的代码片段演示了 Watch 方法搭配 TxPipelined 的使用示例。 // watchDemo 在key值不变的情况下将其值+1 func watchDemo(ctx context.Context, key string) error { return rdb.Watch(ctx, func(tx *redis.Tx) error { n, err := tx.Get(ctx, key).Int() if err != nil \u0026\u0026 err != redis.Nil { return err } // 假设操作耗时5秒 // 5秒内我们通过其他的客户端修改key，当前事务就会失败 time.Sleep(5 * time.Second) _, err = tx.TxPipelined(ctx, func(pipe redis.Pipeliner) error { pipe.Set(ctx, key, n+1, time.Hour) return nil }) return err }, key) } 将上面的函数执行并打印其返回值，如果我们在程序运行后的5秒内修改了被 watch 的 key 的值，那么该事务操作失败，返回redis: transaction failed错误。 最后我们来看一个 go-redis 官方文档中使用 GET 、SET和WATCH命令实现一个 INCR 命令的完整示例。 const routineCount = 100 increment := func(key string) error { txf := func(tx *redis.Tx) error { // 获得当前值或零值 n, err := tx.Get(key).Int() if err != nil \u0026\u0026 err != redis.Nil { return err } // 实际操作（乐观锁定中的本地操作） n++ // 仅在监视的Key保持不变的情况下运行 _, err = tx.Pipelined(func(pipe redis.Pipeliner) error { // pipe 处理错误情况 pipe.Set(key, n, 0) return nil }) return err } for retries := routineCount; retries \u003e 0; retries-- { err := rdb.Watch(txf, key) if err != redis.TxFailedErr { return err } // 乐观锁丢失 } return errors.New(\"increment reached maximum number of retries\") } var wg sync.WaitGroup wg.Add(routineCount) for i := 0; i \u003c routineCount; i++ { go func() { defer wg.Done() if err := increment(\"counter3\"); err != nil { fmt.Println(\"increment error:\", err) } }() } wg.Wait() n, err := rdb.Get(\"counter3\").Int() fmt.Println(\"ended with\", n, err) 在这个示例中使用了 redis.TxFailedErr 来检查事务是否失败。 ","date":"2023-06-02","objectID":"/posts/gin/gin06/:6:1","tags":["gin"],"title":"Go操作数据库03","uri":"/posts/gin/gin06/"},{"categories":["gin"],"content":"sqlx，一个更强大的连接类sql数据库的工具。 ","date":"2023-05-31","objectID":"/posts/gin/gin05/:0:0","tags":["gin"],"title":"Go操作数据库02","uri":"/posts/gin/gin05/"},{"categories":["gin"],"content":"sqlx介绍 在项目中我们通常可能会使用database/sql连接MySQL数据库。sqlx可以认为是Go语言内置database/sql的超集，它在优秀的内置database/sql基础上提供了一组扩展。这些扩展中除了大家常用来查询的Get(dest interface{}, ...) error和Select(dest interface{}, ...) error外还有很多其他强大的功能。 ","date":"2023-05-31","objectID":"/posts/gin/gin05/:1:0","tags":["gin"],"title":"Go操作数据库02","uri":"/posts/gin/gin05/"},{"categories":["gin"],"content":"安装sqlx go get github.com/jmoiron/sqlx ","date":"2023-05-31","objectID":"/posts/gin/gin05/:2:0","tags":["gin"],"title":"Go操作数据库02","uri":"/posts/gin/gin05/"},{"categories":["gin"],"content":"基本使用 连接数据库 import ( \"fmt\" \"github.com/jmoiron/sqlx\" _ \"githb.com/go-sql-driver/mysql\" ) var db *sqlx.DB func initDB() (err error) { dsn := \"user:password@tcp(127.0.0.1:3306)/sql_test?charset=utf8mb4\u0026parseTime=True\" // 也可以使用MustConnect连接不成功就panic // Connect 这里的一个connect相当于正常用database/sql的连接+ping判断的操作 点进源码看就能发现 db, err = sqlx.Connect(\"mysql\", dsn) if err != nil { fmt.Printf(\"connect DB failed, err:%v\\n\", err) return } db.SetMaxOpenConns(20) db.SetMaxIdleConns(10) return } 查询 查询单行数据示例代码如下： type user struct { // 注意首字母大写 并且写tag ID int `db:\"id\"` Age int `db:\"age\"` Name string `db:\"name\"` } // 查询单条数据示例 func queryRowDemo() { sqlStr := \"select id, name, age from user where id=?\" var u user // 注意传进去的是\u0026u err := db.Get(\u0026u, sqlStr, 1) if err != nil { fmt.Printf(\"get failed, err:%v\\n\", err) return } fmt.Printf(\"id:%d name:%s age:%d\\n\", u.ID, u.Name, u.Age) } 查询多行数据示例代码如下： // 查询多条数据示例 func queryMultiRowDemo() { sqlStr := \"select id, name, age from user where id \u003e ?\" var users []user err := db.Select(\u0026users, sqlStr, 0) if err != nil { fmt.Printf(\"query failed, err:%v\\n\", err) return } fmt.Printf(\"users:%#v\\n\", users) } 插入、更新和删除 sqlx中的exec方法与原生sql中的exec使用基本一致： // 插入数据 func insertRowDemo() { sqlStr := \"insert into user(name, age) values (?,?)\" ret, err := db.Exec(sqlStr, \"沙河小王子\", 19) if err != nil { fmt.Printf(\"insert failed, err:%v\\n\", err) return } theID, err := ret.LastInsertId() // 新插入数据的id if err != nil { fmt.Printf(\"get lastinsert ID failed, err:%v\\n\", err) return } fmt.Printf(\"insert success, the id is %d.\\n\", theID) } // 更新数据 func updateRowDemo() { sqlStr := \"update user set age=? where id = ?\" ret, err := db.Exec(sqlStr, 39, 6) if err != nil { fmt.Printf(\"update failed, err:%v\\n\", err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Printf(\"get RowsAffected failed, err:%v\\n\", err) return } fmt.Printf(\"update success, affected rows:%d\\n\", n) } // 删除数据 func deleteRowDemo() { sqlStr := \"delete from user where id = ?\" ret, err := db.Exec(sqlStr, 6) if err != nil { fmt.Printf(\"delete failed, err:%v\\n\", err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Printf(\"get RowsAffected failed, err:%v\\n\", err) return } fmt.Printf(\"delete success, affected rows:%d\\n\", n) } NamedExec DB.NamedExec方法用来绑定SQL语句与结构体或map中的同名字段。 :+结构体的字段名或map中的key func insertUserDemo()(err error){ sqlStr := \"INSERT INTO user (name,age) VALUES (:name,:age)\" _, err = db.NamedExec(sqlStr, map[string]interface{}{ \"name\": \"七米\", \"age\": 28, }) return } NamedQuery 与DB.NamedExec同理，这里是支持查询。 func namedQuery(){ sqlStr := \"SELECT * FROM user WHERE name=:name\" // 使用map做命名查询 rows, err := db.NamedQuery(sqlStr, map[string]interface{}{\"name\": \"七米\"}) if err != nil { fmt.Printf(\"db.NamedQuery failed, err:%v\\n\", err) return } defer rows.Close() for rows.Next(){ var u user // 这里和之前写的不一样，之前写的是rows.Scan(\u0026u.name,\u0026u.XXX) 注意区别，除此之外还会有 mapScan，sliceScan err := rows.StructScan(\u0026u) if err != nil { fmt.Printf(\"scan failed, err:%v\\n\", err) continue } fmt.Printf(\"user:%#v\\n\", u) } u := user{ Name: \"七米\", } // 使用结构体命名查询，根据结构体字段的 db tag进行映射 rows, err = db.NamedQuery(sqlStr, u) if err != nil { fmt.Printf(\"db.NamedQuery failed, err:%v\\n\", err) return } defer rows.Close() for rows.Next(){ var u user err := rows.StructScan(\u0026u) if err != nil { fmt.Printf(\"scan failed, err:%v\\n\", err) continue } fmt.Printf(\"user:%#v\\n\", u) } } 事务操作 对于事务操作，我们可以使用sqlx中提供的db.Beginx()和tx.Exec()方法。示例代码如下： func transactionDemo2()(err error) { tx, err := db.Beginx() // 开启事务 if err != nil { fmt.Printf(\"begin trans failed, err:%v\\n\", err) return err } // 通过defer实现一个事务的最终判断，如果出错的话在这里进行回滚，否则就提交了。 defer func() { if p := recover(); p != nil { tx.Rollback() panic(p) // re-throw panic after Rollback } else if err != nil { fmt.Println(\"rollback\") tx.Rollback() // err is non-nil; don't change it } else { err = tx.Commit() // err is nil; if Commit returns error update err fmt.Println(\"commit\") } }() sqlStr1 := \"Update user set age=20 where id=?\" rs, err := tx.Exec(sqlStr1, 1) if err!= nil{ return err } n, er","date":"2023-05-31","objectID":"/posts/gin/gin05/:3:0","tags":["gin"],"title":"Go操作数据库02","uri":"/posts/gin/gin05/"},{"categories":["gin"],"content":"sqlx.IN sqlx.In的批量插入实例 表结构 为了方便演示插入数据操作，这里创建一个user表，表结构如下： CREATE TABLE `user` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `name` VARCHAR(20) DEFAULT '', `age` INT(11) DEFAULT '0', PRIMARY KEY(`id`) )ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4; 结构体 定义一个user结构体，字段通过tag与数据库中user表的列一致。 type User struct { Name string `db:\"name\"` Age int `db:\"age\"` } bindvars（绑定变量） 查询占位符?在内部称为bindvars（查询占位符）,它非常重要。你应该始终使用它们向数据库发送值，因为它们可以防止SQL注入攻击。database/sql不尝试对查询文本进行任何验证；它与编码的参数一起按原样发送到服务器。除非驱动程序实现一个特殊的接口，否则在执行之前，查询是在服务器上准备的。因此bindvars是特定于数据库的: MySQL中使用? PostgreSQL使用枚举的$1、$2等bindvar语法 SQLite中?和$1的语法都支持 Oracle中使用:name的语法 bindvars的一个常见误解是，它们用来在sql语句中插入值。它们其实仅用于参数化，不允许更改SQL语句的结构。例如，使用bindvars尝试参数化列或表名将不起作用： // ？不能用来插入表名（做SQL语句中表名的占位符） db.Query(\"SELECT * FROM ?\", \"mytable\") // ？也不能用来插入列名（做SQL语句中列名的占位符） db.Query(\"SELECT ?, ? FROM people\", \"name\", \"location\") 自己使用database/sql进行拼接语句实现批量插入 比较笨，但是很好理解。就是有多少个User就拼接多少个(?, ?)。 // BatchInsertUsers 自行构造批量插入的语句 func BatchInsertUsers(users []*User) error { // 存放 (?, ?) 的slice valueStrings := make([]string, 0, len(users)) // 存放values的slice valueArgs := make([]interface{}, 0, len(users) * 2) // 遍历users准备相关数据 for _, u := range users { // 此处占位符要与插入值的个数对应 valueStrings = append(valueStrings, \"(?, ?)\") valueArgs = append(valueArgs, u.Name) valueArgs = append(valueArgs, u.Age) } // 自行拼接要执行的具体语句 stmt := fmt.Sprintf(\"INSERT INTO user (name, age) VALUES %s\", strings.Join(valueStrings, \",\")) _, err := DB.Exec(stmt, valueArgs...) return err } 使用sqlx.In实现批量插入 前提是需要我们的结构体实现driver.Valuer接口： func (u User) Value() (driver.Value, error) { return []interface{}{u.Name, u.Age}, nil } 使用sqlx.In实现批量插入代码如下： // BatchInsertUsers2 使用sqlx.In帮我们拼接语句和参数, 注意传入的参数是[]interface{} func BatchInsertUsers2(users []interface{}) error { query, args, _ := sqlx.In( \"INSERT INTO user (name, age) (?), (?), (?)\", users..., // 如果arg实现了 driver.Valuer, sqlx.In 会通过调用 Value()来展开它 ) fmt.Println(query) // 查看生成的querystring fmt.Println(args) // 查看生成的args _, err := DB.Exec(query, args...) return err } 使用NamedExec实现批量插入 注意 ：该功能需1.3.1版本以上，并且1.3.1版本目前还有点问题，sql语句最后不能有空格和;，详见issues/690。 使用NamedExec实现批量插入的代码如下： // BatchInsertUsers3 使用NamedExec实现批量插入 func BatchInsertUsers3(users []*User) error { _, err := DB.NamedExec(\"INSERT INTO user (name, age) VALUES (:name, :age)\", users) return err } 把上面三种方法综合起来试一下： func main() { err := initDB() if err != nil { panic(err) } defer DB.Close() u1 := User{Name: \"七米\", Age: 18} u2 := User{Name: \"q1mi\", Age: 28} u3 := User{Name: \"小王子\", Age: 38} // 方法1 users := []*User{\u0026u1, \u0026u2, \u0026u3} err = BatchInsertUsers(users) if err != nil { fmt.Printf(\"BatchInsertUsers failed, err:%v\\n\", err) } // 方法2 users2 := []interface{}{u1, u2, u3} err = BatchInsertUsers2(users2) if err != nil { fmt.Printf(\"BatchInsertUsers2 failed, err:%v\\n\", err) } // 方法3 users3 := []*User{\u0026u1, \u0026u2, \u0026u3} err = BatchInsertUsers3(users3) if err != nil { fmt.Printf(\"BatchInsertUsers3 failed, err:%v\\n\", err) } } sqlx.In的查询实例 关于sqlx.In这里再补充一个用法，在sqlx查询语句中实现In查询和FIND_IN_SET函数。即实现SELECT * FROM user WHERE id in (3, 2, 1);和SELECT * FROM user WHERE id in (3, 2, 1) ORDER BY FIND_IN_SET(id, '3,2,1');。 in查询 查询id在给定id集合中的数据。 // QueryByIDs 根据给定ID查询 func QueryByIDs(ids []int)(users []User, err error){ // 动态填充id query, args, err := sqlx.In(\"SELECT name, age FROM user WHERE id IN (?)\", ids) if err != nil { return } // sqlx.In 返回带 `?` bindvar的查询语句, 我们使用Rebind()重新绑定它 query = DB.Rebind(query) err = DB.Select(\u0026users, query, args...) return } in查询和FIND_IN_SET函数 查询id在给定id集合的数据并维持给定id集合的顺序。 // QueryAndOrderByIDs 按照指定id查询并维护顺序 func QueryAndOrderByIDs(ids []int)(users []User, err error){ // 动态填充id strIDs := make([]string, 0, len(ids)) for _, id := range ids { strIDs = append(strIDs, fmt.Sprintf(\"%d\", id)) } query, args, err := sqlx.In(\"SELECT name, age FROM user WHERE id IN (?) ORDER BY FIND_IN_SET(id, ?)\", ids, strings.Join(strIDs, \",\")) if err != nil { return } // sqlx.In 返回带 `?` bindvar的查询语句, 我们使用Rebind()重新绑定它 query = DB.Rebind(query) err = DB.Select(\u0026users, query, args...) return } 当然，在这个例子里面","date":"2023-05-31","objectID":"/posts/gin/gin05/:4:0","tags":["gin"],"title":"Go操作数据库02","uri":"/posts/gin/gin05/"},{"categories":["k8s"],"content":"资源创建方式 命令行 YAML ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:1:0","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"Namespace 名称空间，用来隔离资源，对资源进行隔离划分。默认只隔离资源，不隔离网络。 通过命令行创建名称空间 kubectl get ns # 查看所有名称空间 kubectl create ns hello # 创建名称空间 kubectl delete ns hello # 删除名称空间 kubectl get pods -A # 查看k8s中部署的全部应用的名字、名称空间等信息 kubectl get pods # 只会查看default名称空间下部署的应用，如果我们创建资源时，不指定名称空间，都会放在default名称空间下 kubectl get pod -n 名称空间 # 查看指定名称空间下部署的应用 通过配置文件法创建名称空间 vi hello.yaml apiVersion: v1 kind: Namespace metadata: name: hello kubectl apply -f hello.yaml 可以通过kubectl delete -f hello.yaml删除名称空间，通过配置文件创建的资源推荐使用这种办法删除。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:2:0","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"Pod 运行中的一组容器（一个pod中可能有不止一个容器，见下下图），Pod是kubernetes中应用的最小单位（虽然pod中是有docker的）。 下图中的1/1指的是一个pod中共有一个容器，有一个容器正在运行，所以也会出现1/2，2/2的情况。 # 使用命令行创建pod mynginx是pod的名字 --image=nginx 指定镜像 kubectl run mynginx --image=nginx # 查看default名称空间的Pod kubectl get pod （-n default） # 描述 会有一项Events 查看进行的事项 kubectl describe pod 你自己的Pod名字 # 删除 kubectl delete pod Pod名字 # 查看Pod的运行日志 kubectl logs Pod名字 # 每个Pod - k8s都会分配一个ip 通过这个命令可以查到这个ip kubectl get pod -owide # 使用Pod的ip+pod里面运行容器的端口 curl 192.168.169.136 # 集群中的任意一个机器以及任意的应用都能通过Pod分配的ip来访问这个Pod # 像docker一样进入交互模式 kubectl exec -it mynginx -- /bin/bash 查看描述，可以发现，这个任务交给了k8s-node2，我们可以在各个node下运行docker ps | grep mynginx进行验证。（实际上，我们可以发现一个事儿，底层的东西就是docker） 用配置文件创建pod vi pod.yaml kubectl apply -f pod.yaml kubectl delete-f pod.yaml apiVersion: v1 kind: Pod metadata: labels: run: mynginx name: mynginx # pod的名字 # namespace: default spec: containers: - image: nginx name: mynginx # 容器的名字 当然也可以通过可视化界面创建。 此时的应用还不能外部访问，因为还没有暴露端口。 apiVersion: v1 kind: Pod metadata: labels: run: myapp name: myapp spec: containers: - image: nginx name: nginx - image: tomcat:8.5.68 # 实现了在一个pod里面装了两个容器 name: tomcat 一个pod里两个容器，通过访问ip的不同端口访问不同的软件，而如果要用nginx访问tomcat，只需要用127.0.0.1即可，因为一个pod内的容器共享网络空间、共享存储。 一个小问题一个pod里面能不能启两个一样的容器，如两个ngnix或两个tomcat 。 发现报错了。使用命令查看一下怎么回事。 结论是不能这样做。因为会出现端口被占用的情况。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:3:0","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"Deployment 控制Pod，使Pod拥有多副本，自愈，扩缩容等能力。 # 清除所有Pod，比较下面两个命令有何不同效果？ kubectl run mynginx --image=nginx kubectl create deployment mytomcat --image=tomcat:8.5.68 如果使用kubectl delete pod mynginx和kubectl delete pod mytomcat删除两个pod。通过watch -n 1 kubectl get pod会发现后者具有自愈能力，删了一个会再新启动一个，新启的名字和之前不同，再次删除还会再次重启。结论是我们通过deployment启的pod不会怕宕机。 那如果我们真的想删除掉这个pod怎么办呢，我们的方法是删除这次部署。kubectl get deploy查看部署，kubectl delete deploy mytomcat删除掉这个部署。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:4:0","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"1.多副本 好比我们有一个订单业务，在一台机器上运行肯定是不够的，我们想让它运行在多台机器。 my-dep是这次部署的名字 ，--image=nginx使用的镜像，--replicas=3部署多少份。 kubectl create deployment my-dep --image=nginx --replicas=3 上图表示本次部署一共启三个应用，0个已准备好，3个正在启动。 在可视化界面创建多副本的pod的部署以及删除部署。 通过配置文件部署多副本的pod。 apiVersion: apps/v1 kind: Deployment metadata: labels: app: my-dep name: my-dep spec: replicas: 3 # 3份副本 selector: matchLabels: app: my-dep template: metadata: labels: app: my-dep spec: containers: - image: nginx name: nginx ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:4:1","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"2.扩缩容 当业务的压力更大，当前的pod数不能满足需求的时候，需要进行扩容，当流量高峰过去之后，还可以进行缩容。 后面还会有k8s的动态扩缩容，自己判断当前的负载能力。 my-dep是部署的名字 --replicas=5扩容成5份 kubectl scale --replicas=5 deployment/my-dep --replicas=2 再缩容成2份 kubectl scale --replicas=2 deployment/my-dep 也可以采用这种方式进行扩缩容，使用下面的命令修改replicas，下面的命令会相当于直接打开vim编辑。 kubectl edit deployment my-dep 在可视化界面里面进行扩缩容 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:4:2","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"3.自愈\u0026故障转移 当一个pod崩溃出故障的时候，k8s会尝试重启修复这个pod，这个是自愈。 而当一个pod的机器宕机了或者断电了，无法再提供服务了，下线了，k8s就会尝试把这个pod中的服务转移到其他pod，这个过程叫做故障转移。 下图模拟的是故障转移的过程，我们手动的将w6shc所在的机器进行关机，在大约5分钟（如果这个阈值太小了，就不合理了，出一点小问题就会杀死，重启）后会看到如下的变化，w6shc先停了，又新启了一个hz2xf的pod，这个pod在另外一个节点上运行。 kubectl get pod -w和watch -n 1 kubectl get pod一样都是用来实时检测状态的，如果有更新，终端就会打印输出。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:4:3","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"4.滚动更新 不停机更新。当部署的3个pod备份v1版本的要更新到v2版本时。会先启一个pod v2版本，等到其启动成功了，在使用他，同时杀死v1的pod。3个pod依次按顺序等上一个完成更新了再更新下一个。如果一次性把老版本全删掉，就会出现因为新版本有问题了，服务全部不好使了。 deployment/my-dep指定一个部署 nginx=nginx:1.16.1前面的nginx是容器名 --record记录这次版本的更新，通过记录我们会发现，新启动的pod就是新启的，因为pod的name会发生变化。 kubectl set image deployment/my-dep nginx=nginx:1.16.1 --record kubectl rollout status deployment/my-dep # 干嘛的？ ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:4:4","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"5.版本回退 版本回退的逻辑和滚动更新相同，都是先启着，启完了再换、停。再回退下一个备份，以此类推。 #历史记录 查看版本历史记录 kubectl rollout history deployment/my-dep #查看某个历史详情 kubectl rollout history deployment/my-dep --revision=2 #回滚(回到上次) kubectl rollout undo deployment/my-dep #回滚(回到指定版本) kubectl rollout undo deployment/my-dep --to-revision=2 更多： 除了Deployment，k8s还有 StatefulSet 、DaemonSet 、Job 等 类型资源。我们都称为 工作负载。 有状态应用使用 StatefulSet 部署，无状态应用使用 Deployment 部署 https://kubernetes.io/zh/docs/concepts/workloads/controllers/ StatefulSet有状态指的是，比如一个Pod死掉了，需要新启一个Pod，能读取到原来Pod中的ip、存储数据等有用的内容。 总结一下，虽然Pod是应用的最终载体，但是我们使用各种工作负载去控制Pod，让Pod有更多强大的功能。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:4:5","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"Service 截止到上面为止，我们的应用还不能通过浏览器进行访问呢，只能在内网机器内进行访问。而Service就是用来将一组Pods公开为网络服务的抽象方法。service是用来做服务发现，负载均衡的。一组服务称为一个service。 nginx的负载均衡是写死几个ip，轮询。而我们这里是动态的，负载均衡的前提是服务发现。 3个pod实现的是一个微服务，组成一个service，统一暴露给前端一个接口。服务发现就是说k8s能发送哪个pod宕机了，然后把工作交给别人去做。负载均衡就不用解释了吧。 #暴露Deploy my-dep 部署名 访问服务的接口是8000相当于去访问pod的80端口 kubectl expose deployment my-dep --port=8000 --target-port=80 #使用标签检索Pod kubectl get pod -l app=my-dep 使用yaml文件暴露端口形成一个service。 apiVersion: v1 kind: Service metadata: labels: app: my-dep name: my-dep spec: selector: # 是指根据哪个去选择，每一个pod都会有个标签 app: my-dep ports: - port: 8000 protocol: TCP targetPort: 80 我们在容器内部访问的时候有两种方式，一种方式是通过ip，另一种方式是使用服务名。如果是在集群内部就只能通过方式一。 kubectl get service 可以简写为kubectl get svc查看service，名字、种类、ip。 以上的service是由kubectl expose deployment my-dep --port=8000 --target-port=80创建的，默认的type是clusterip。 方式二只有在容器的内部才可以通过上述的方法访问到，容器的内部是说比如进去my-tomcat的终端，进行访问。 下图属于在集群中访问，只能通过方式一。 最后再说一下为啥要有service。下面是之前讲过的命令，k8s为每个pod都分配了一个ip，但是实际应用上，我们不可能通过访问这样的ip+端口去获取服务，因为会挂掉，也无法负载均衡，所以我们把一组相同的pod，就是一个部署，给他们统一的暴露出一个ip，以实现服务发现和负载均衡。 # 每个Pod - k8s都会分配一个ip 通过这个命令可以查到这个ip kubectl get pod -owide ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:5:0","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"1.ClusterIP 只能在集群内部访问。 # 等同于没有--type的 kubectl expose deployment my-dep --port=8000 --target-port=80 --type=ClusterIP apiVersion: v1 kind: Service metadata: labels: app: my-dep name: my-dep spec: ports: - port: 8000 protocol: TCP targetPort: 80 selector: app: my-dep type: ClusterIP ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:5:1","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"2.NodePort 在公网上访问。 kubectl expose deployment my-dep --port=8000 --target-port=80 --type=NodePort apiVersion: v1 kind: Service metadata: labels: app: my-dep name: my-dep spec: ports: - port: 8000 protocol: TCP targetPort: 80 selector: app: my-dep type: NodePort 会为每个节点开一个相同的端口，这个NodePort范围在 30000-32767 之间。 这时就可以通过这个端口在公网进行访问了。这个ip是集群机器的ip。并且访问3台机器中的任一台机器（3台机器公网ip不同）的该端口都可以实现服务，并且是一个负载均衡的服务。除此之外也可以像clusterip的方式一样，通过service的ip或name在集群或容器中进行访问。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:5:2","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"Ingress ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:6:0","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"1.安装 Ingress翻译成汉语是入口的意思，是Service的统一网关入口。k8s希望Ingress成为集群流量的唯一入口。实际应用中，我们可能部署好多个服务，每个服务都有多个pod，所有的请求流量都应该先通过ingress，相当于集群统一的网关入口。 wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.47.0/deploy/static/provider/baremetal/deploy.yaml #修改镜像 vi deploy.yaml #将image的值改为如下值： registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/ingress-nginx-controller:v0.46.0 # 检查安装的结果 kubectl get pod,svc -n ingress-nginx # 最后别忘记把svc暴露的端口要放行，见下图 # 31405 和 32401一个是http 一个是https,所有的请求流量都会先走节点的公网ip+这这两个端口 如果下载不到，用以下文件 apiVersion: v1 kind: Namespace metadata: name: ingress-nginx labels: app.kubernetes.io/name: ingress-nginx app.kubernetes.io/instance: ingress-nginx --- # Source: ingress-nginx/templates/controller-serviceaccount.yaml apiVersion: v1 kind: ServiceAccount metadata: labels: helm.sh/chart: ingress-nginx-3.33.0 app.kubernetes.io/name: ingress-nginx app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/version: 0.47.0 app.kubernetes.io/managed-by: Helm app.kubernetes.io/component: controller name: ingress-nginx namespace: ingress-nginx automountServiceAccountToken: true --- # Source: ingress-nginx/templates/controller-configmap.yaml apiVersion: v1 kind: ConfigMap metadata: labels: helm.sh/chart: ingress-nginx-3.33.0 app.kubernetes.io/name: ingress-nginx app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/version: 0.47.0 app.kubernetes.io/managed-by: Helm app.kubernetes.io/component: controller name: ingress-nginx-controller namespace: ingress-nginx data: --- # Source: ingress-nginx/templates/clusterrole.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: helm.sh/chart: ingress-nginx-3.33.0 app.kubernetes.io/name: ingress-nginx app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/version: 0.47.0 app.kubernetes.io/managed-by: Helm name: ingress-nginx rules: - apiGroups: - '' resources: - configmaps - endpoints - nodes - pods - secrets verbs: - list - watch - apiGroups: - '' resources: - nodes verbs: - get - apiGroups: - '' resources: - services verbs: - get - list - watch - apiGroups: - extensions - networking.k8s.io # k8s 1.14+ resources: - ingresses verbs: - get - list - watch - apiGroups: - '' resources: - events verbs: - create - patch - apiGroups: - extensions - networking.k8s.io # k8s 1.14+ resources: - ingresses/status verbs: - update - apiGroups: - networking.k8s.io # k8s 1.14+ resources: - ingressclasses verbs: - get - list - watch --- # Source: ingress-nginx/templates/clusterrolebinding.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: labels: helm.sh/chart: ingress-nginx-3.33.0 app.kubernetes.io/name: ingress-nginx app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/version: 0.47.0 app.kubernetes.io/managed-by: Helm name: ingress-nginx roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: ingress-nginx subjects: - kind: ServiceAccount name: ingress-nginx namespace: ingress-nginx --- # Source: ingress-nginx/templates/controller-role.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: Role metadata: labels: helm.sh/chart: ingress-nginx-3.33.0 app.kubernetes.io/name: ingress-nginx app.kubernetes.io/instance: ingress-nginx app.kubernetes.io/version: 0.47.0 app.kubernetes.io/managed-by: Helm app.kubernetes.io/component: controller name: ingress-nginx namespace: ingress-nginx rules: - apiGroups: - '' resources: - namespaces verbs: - get - apiGroups: - '' resources: - configmaps - pods - secrets - endpoints verbs: - get - list - watch - apiGroups: - '' resources: - services verbs: - get - list - watch - apiGroups: - extensions - networking.k8s.io # k8s 1.14+ resources: - ingresses verbs: - get - list - watch - apiGroups: - extensions - networking.k8s.io # k8s 1.14+ resources: - ingresses/status verbs: - update - apiGroups: - networking.k8s.io # k8s 1.14+ resources: - ingressclasses verbs: - get - list - watch - apiGroups: - '' resources: - configmaps resourceNames: - ingress-controller-leader-nginx verbs: - get - update","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:6:1","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"2.使用 官网地址：https://kubernetes.github.io/ingress-nginx/ 就是nginx做的 https://139.198.163.211:32401/ http://139.198.163.211:31405/ 测试环境 应用如下yaml，准备好测试环境 apiVersion: apps/v1 kind: Deployment metadata: name: hello-server spec: replicas: 2 selector: matchLabels: app: hello-server template: metadata: labels: app: hello-server spec: containers: - name: hello-server image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server ports: - containerPort: 9000 --- apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx-demo name: nginx-demo spec: replicas: 2 selector: matchLabels: app: nginx-demo template: metadata: labels: app: nginx-demo spec: containers: - image: nginx name: nginx --- apiVersion: v1 kind: Service metadata: labels: app: nginx-demo name: nginx-demo spec: selector: app: nginx-demo ports: - port: 8000 protocol: TCP targetPort: 80 --- apiVersion: v1 kind: Service metadata: labels: app: hello-server name: hello-server spec: selector: app: hello-server ports: - port: 8000 protocol: TCP targetPort: 9000 1.域名访问 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-host-bar spec: ingressClassName: nginx rules: - host: \"hello.atguigu.com\" http: paths: - pathType: Prefix path: \"/\" backend: service: name: hello-server port: number: 8000 - host: \"demo.atguigu.com\" http: paths: - pathType: Prefix path: \"/nginx\" # 把请求会转给下面的服务，下面的服务一定要能处理这个路径，不能处理就是404 backend: service: name: nginx-demo ## java，比如使用路径重写，去掉前缀nginx port: number: 8000 问题： path: “/nginx” 与 path: “/” 为什么会有不同的效果？ 2.路径重写 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: annotations: nginx.ingress.kubernetes.io/rewrite-target: /$2 # 路由重写 name: ingress-host-bar spec: ingressClassName: nginx rules: - host: \"hello.atguigu.com\" http: paths: - pathType: Prefix path: \"/\" backend: service: name: hello-server port: number: 8000 - host: \"demo.atguigu.com\" http: paths: - pathType: Prefix # 前缀匹配 path: \"/nginx(/|$)(.*)\" # 把请求会转给下面的服务，下面的服务一定要能处理这个路径，不能处理就是404 backend: service: name: nginx-demo ## java，比如使用路径重写，去掉前缀nginx port: number: 8000 3.流量限制 apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-limit-rate annotations: nginx.ingress.kubernetes.io/limit-rps: \"1\" # 限流 spec: ingressClassName: nginx rules: - host: \"haha.atguigu.com\" http: paths: - pathType: Exact # 精确匹配 path: \"/\" backend: service: name: nginx-demo port: number: 8000 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:6:2","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"存储抽象 业务场景是pod里面的内容目录，在主机上挂一份，就好比docker的挂载，这样我们修改/a的时候/data的内容也随之修改，但如果直接使用这种方式，在我们k8s里会出现一个问题，比如当下图中的黑色pod宕机后，会重启一个pod，同时新开一个挂载，但是这个新启的pod不一定在哪台机器上启动，那么原来节点上挂载着的内容就无法进行一个还原，转移了。 所以在我们k8s中，我们把所有机器的挂载层进行一个统一的管理，放到一个存储层中。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:7:0","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"环境准备 1.所有节点 #所有机器安装 yum install -y nfs-utils 2.主节点 #nfs主节点 echo \"/nfs/data/ *(insecure,rw,sync,no_root_squash)\" \u003e /etc/exports mkdir -p /nfs/data systemctl enable rpcbind --now systemctl enable nfs-server --now #配置生效 exportfs -r 3.从节点 showmount -e 172.31.0.4 #执行以下命令挂载 nfs 服务器上的共享目录到本机路径 /root/nfsmount mkdir -p /nfs/data mount -t nfs 172.31.0.4:/nfs/data /nfs/data # 写入一个测试文件 echo \"hello nfs server\" \u003e /nfs/data/test.txt 原生方式数据挂载 apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx-pv-demo name: nginx-pv-demo spec: replicas: 2 selector: matchLabels: app: nginx-pv-demo template: metadata: labels: app: nginx-pv-demo spec: containers: - image: nginx name: nginx volumeMounts: - name: html # 给这个挂载起个名字 mountPath: /usr/share/nginx/html # 哪个文件需要挂载 volumes: - name: html # html挂载 nfs: # 使用nfs服务 server: 172.31.0.4 # nfs主节点的ip path: /nfs/data/nginx-pv # 挂载到那个目录 图例： 问题1：/nfs/data/nginx-pv这个文件夹需要自己创建一下 问题2：如果把这两个pod删掉了，/nfs/data/nginx-pv这个文件夹不会删，我们希望能自动清理这个内容。 问题3：目前的挂载时，每个pod能用多少空间没有限制。基于这个问题有了下节的内容。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:7:1","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"PV\u0026PVC PV：持久卷（Persistent Volume），将应用需要持久化的数据保存到指定位置 PVC：持久卷申明（Persistent Volume Claim），申明需要使用的持久卷规格 可以给pv指定容量。每个pod用多大的空间需要提交一个pvc申请书，相当于一个pvc和一个pv绑定，当pod删除时，pvc跟着也删除了，空间就会进行回收。 1.创建pv池 静态供应 #nfs主节点 mkdir -p /nfs/data/01 mkdir -p /nfs/data/02 mkdir -p /nfs/data/03 创建PV apiVersion: v1 kind: PersistentVolume metadata: name: pv01-10m spec: capacity: storage: 10M accessModes: - ReadWriteMany storageClassName: nfs nfs: path: /nfs/data/01 server: 172.31.0.4 --- apiVersion: v1 kind: PersistentVolume metadata: name: pv02-1gi spec: capacity: storage: 1Gi accessModes: - ReadWriteMany storageClassName: nfs nfs: path: /nfs/data/02 server: 172.31.0.4 --- apiVersion: v1 kind: PersistentVolume metadata: name: pv03-3gi spec: capacity: storage: 3Gi accessModes: - ReadWriteMany storageClassName: nfs nfs: path: /nfs/data/03 server: 172.31.0.4 2.PVC创建与绑定 创建PVC kind: PersistentVolumeClaim apiVersion: v1 metadata: name: nginx-pvc spec: accessModes: - ReadWriteMany # 能读能写 resources: requests: storage: 200Mi storageClassName: nfs 创建Pod绑定PVC apiVersion: apps/v1 kind: Deployment metadata: labels: app: nginx-deploy-pvc name: nginx-deploy-pvc spec: replicas: 2 selector: matchLabels: app: nginx-deploy-pvc template: metadata: labels: app: nginx-deploy-pvc spec: containers: - image: nginx name: nginx volumeMounts: - name: html mountPath: /usr/share/nginx/html volumes: - name: html persistentVolumeClaim: claimName: nginx-pvc # 申请书 注意这块和之前的挂载方法的区别 还有一种是动态供应，根据你pod想要多大的，然后在pv池子中创建这么大的空间，进行挂载。 ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:7:2","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"ConfigMap pv和pvc是用来挂载文件和目录的，而挂载配置文件我们用ConfigMap。这个配置集保存在k8s中的etcd中。 抽取应用配置，并且可以自动更新 1.redis示例 1、把之前的配置文件创建为配置集 # 创建配置，redis保存到k8s的etcd； kubectl create cm redis-conf --from-file=redis.conf apiVersion: v1 data: #data是所有真正的数据，key：默认是文件名 value：配置文件的内容 redis.conf: | appendonly yes kind: ConfigMap metadata: name: redis-conf namespace: default 2.创建Pod apiVersion: v1 kind: Pod metadata: name: redis spec: containers: - name: redis image: redis command: - redis-server - \"/redis-master/redis.conf\" #指的是redis容器内部的位置 ports: - containerPort: 6379 volumeMounts: - mountPath: /data name: data - mountPath: /redis-master name: config volumes: - name: data emptyDir: {} - name: config configMap: name: redis-conf items: - key: redis.conf path: redis.conf 3.检查默认配置 kubectl exec -it redis -- redis-cli 127.0.0.1:6379\u003e CONFIG GET appendonly 127.0.0.1:6379\u003e CONFIG GET requirepass 4.修改ConfigMap apiVersion: v1 kind: ConfigMap metadata: name: example-redis-config data: redis-config: | maxmemory 2mb maxmemory-policy allkeys-lru 5.检查配置是否更新 kubectl exec -it redis -- redis-cli 127.0.0.1:6379\u003e CONFIG GET maxmemory 127.0.0.1:6379\u003e CONFIG GET maxmemory-policy 检查指定文件内容是否已经更新 修改了CM。Pod里面的配置文件会跟着变 *配置值未更改，因为需要重新启动 Pod 才能从关联的 ConfigMap 中获取更新的值。* *原因：我们的Pod部署的中间件自己本身没有热更新能力* ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:7:3","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["k8s"],"content":"Secret Secret 对象类型用来保存敏感信息，例如密码、OAuth 令牌和 SSH 密钥。 将这些信息放在 secret 中比放在 Pod 的定义或者 容器镜像 中来说更加安全和灵活 kubectl create secret docker-registry leifengyang-docker \\ --docker-username=leifengyang \\ --docker-password=Lfy123456 \\ --docker-email=534096094@qq.com ##命令格式 kubectl create secret docker-registry regcred \\ --docker-server=\u003c你的镜像仓库服务器\u003e \\ --docker-username=\u003c你的用户名\u003e \\ --docker-password=\u003c你的密码\u003e \\ --docker-email=\u003c你的邮箱地址\u003e apiVersion: v1 kind: Pod metadata: name: private-nginx spec: containers: - name: private-nginx image: leifengyang/guignginx:v1.0 imagePullSecrets: - name: leifengyang-docker # 选择 secret ","date":"2023-05-31","objectID":"/posts/k8s/k8s02/:7:4","tags":["k8s"],"title":"K8s入门2","uri":"/posts/k8s/k8s02/"},{"categories":["go"],"content":"表示熟悉 表示掌握 表示了解 ","date":"2023-05-31","objectID":"/posts/go/interview04/:0:0","tags":["go","面试"],"title":"Golang_Interview_垃圾回收","uri":"/posts/go/interview04/"},{"categories":["go"],"content":"golang的垃圾回收1 CSDN Garbage Collection golang GC 算法使用的是无分代（对象没有代际之分）、不整理（回收过程中不对对象进行移动与整理）、并发（与用户代码并发执行）的三色标记清扫算法。 三色标记法将对象分为三类，并用不同的颜色相称： 白色对象（可能死亡）：未被回收器访问到的对象。在回收开始阶段，所有对象均为白色，当回收结束后，白色对象均不可达 灰色对象（波面）：已被回收器访问到的对象，但回收器需要对其中的一个或多个指针进行扫描，因为他们可能还指向白色对象 黑色对象（确定存活）：已被回收器访问到的对象，其中所有字段都已被扫描，黑色对象中任何一个指针都不可能直接指向白色对象 标记过程如下： 第一步：起初所有的对象都是白色的 第二步：从根对象出发扫描所有可达对象，标记为灰色，放入待处理队列 第三步：从待处理队列中取出灰色对象，将其引用的对象标记为灰色并放入待处理队列中，自身标记为黑色 重复第三步，直到待处理队列为空，此时白色对象即为不可达的“垃圾”，回收白色对象 ","date":"2023-05-31","objectID":"/posts/go/interview04/:1:0","tags":["go","面试"],"title":"Golang_Interview_垃圾回收","uri":"/posts/go/interview04/"},{"categories":["go"],"content":"golang的垃圾回收2 垃圾回收、三色标记原理 垃圾回收就是对程序中不再使用的内存资源进行自动回收的操作。 ","date":"2023-05-31","objectID":"/posts/go/interview04/:2:0","tags":["go","面试"],"title":"Golang_Interview_垃圾回收","uri":"/posts/go/interview04/"},{"categories":["go"],"content":"1.1 常见的垃圾回收算法： 引用计数：每个对象维护一个引用计数，当被引用对象被创建或被赋值给其他对象时引用计数自动加 +1；如果这个对象被销毁，则计数 -1 ，当计数为 0 时，回收该对象。 优点：对象可以很快被回收，不会出现内存耗尽或到达阀值才回收。 缺点：不能很好的处理循环引用 标记-清除：从根变量开始遍历所有引用的对象，引用的对象标记“被引用”，没有被标记的则进行回收。 优点：解决了引用计数的缺点。 缺点：需要 STW（stop the world），暂时停止程序运行。 分代收集：按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，短的放入新生代，不同代有不同的回收算法和回收频率。 优点：回收性能好 缺点：算法复杂 ","date":"2023-05-31","objectID":"/posts/go/interview04/:2:1","tags":["go","面试"],"title":"Golang_Interview_垃圾回收","uri":"/posts/go/interview04/"},{"categories":["go"],"content":"1.2 三色标记法 初始状态下所有对象都是白色的。 从根节点开始遍历所有对象，把遍历到的对象变成灰色对象 遍历灰色对象，将灰色对象引用的对象也变成灰色对象，然后将遍历过的灰色对象变成黑色对象。 循环步骤3，直到灰色对象全部变黑色。 通过写屏障(write-barrier)检测对象有变化，重复以上操作 收集所有白色对象（垃圾）。 ","date":"2023-05-31","objectID":"/posts/go/interview04/:2:2","tags":["go","面试"],"title":"Golang_Interview_垃圾回收","uri":"/posts/go/interview04/"},{"categories":["go"],"content":"1.3 STW（Stop The World） 为了避免在 GC 的过程中，对象之间的引用关系发生新的变更，使得GC的结果发生错误（如GC过程中新增了一个引用，但是由于未扫描到该引用导致将被引用的对象清除了），停止所有正在运行的协程。 STW对性能有一些影响，Golang目前已经可以做到1ms以下的STW。 ","date":"2023-05-31","objectID":"/posts/go/interview04/:2:3","tags":["go","面试"],"title":"Golang_Interview_垃圾回收","uri":"/posts/go/interview04/"},{"categories":["go"],"content":"1.4 写屏障(Write Barrier) 为了避免GC的过程中新修改的引用关系到GC的结果发生错误，我们需要进行STW。但是STW会影响程序的性能，所以我们要通过写屏障技术尽可能地缩短STW的时间。 造成引用对象丢失的条件: 一个黑色的节点A新增了指向白色节点C的引用，并且白色节点C没有除了A之外的其他灰色节点的引用，或者存在但是在GC过程中被删除了。以上两个条件需要同时满足：满足条件1时说明节点A已扫描完毕，A指向C的引用无法再被扫描到；满足条件2时说明白色节点C无其他灰色节点的引用了，即扫描结束后会被忽略 。 写屏障破坏两个条件其一即可 破坏条件1：Dijistra写屏障 满足强三色不变性：黑色节点不允许引用白色节点 当黑色节点新增了白色节点的引用时，将对应的白色节点改为灰色 破坏条件2：Yuasa写屏障 满足弱三色不变性：黑色节点允许引用白色节点，但是该白色节点有其他灰色节点间接的引用（确保不会被遗漏） 当白色节点被删除了一个引用时，悲观地认为它一定会被一个黑色节点新增引用，所以将它置为灰色。 ","date":"2023-05-31","objectID":"/posts/go/interview04/:2:4","tags":["go","面试"],"title":"Golang_Interview_垃圾回收","uri":"/posts/go/interview04/"},{"categories":["go"],"content":"表示熟悉 表示掌握 表示了解 ","date":"2023-05-31","objectID":"/posts/go/interview02/:0:0","tags":["go","面试"],"title":"Golang_Interview_概述","uri":"/posts/go/interview02/"},{"categories":["go"],"content":"进程、线程、协程的区别？ 进程：进程是每一次程序动态执行的过程，是程序运行的基本单位。进程占据独立的内存，有内存地址，有自己的堆，上级挂靠操作系统，操作系统以进程为单位分配资源(如CPU时间片、内存等)，进程是资源分配的最小单位。 线程：线程又叫做轻量级进程，是CPU调度的最小单元。线程从属于进程，是程序的实际执行者，一个进程至少包含一个主线程，也可以有多个子线程。线程会共享所属进程的资源，同时线程也有自己的独占资源。线程切换和线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。 协程：协程是一种用户态的轻量级线程，协程的调度完全由用户控制。一个线程可以有多个协程，协程不是被操作系统内核所管理，而是由程序所控制。 区别 拥有资源：进程是拥有资源的最小单位，线程不拥有资源，但是可以访问隶属进程的资源。进程所维护的是程序所包含的资源静态资源)， 如：地址空间，打开的文件句柄集，文件系统状态，信号处理handler等；线程所维护的运行相关的资源(动态资源)，如：运行栈，调度相关的控制信息，待处理的信号集等。 并发性：不仅进程可以并发执行，同一进程的多个线程也可以并发执行。 系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。但是进程有独立的地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个进程死掉就等于所有的线程死掉，所以多进程的程序要比多线程的程序健壮，但在进程切换时，耗费资源较大，效率要差一些。 协程和线程：协程避免了无意义的调度，由此可以提高性能，但是用户调度过程中可能存在风险。 ","date":"2023-05-31","objectID":"/posts/go/interview02/:1:0","tags":["go","面试"],"title":"Golang_Interview_概述","uri":"/posts/go/interview02/"},{"categories":["go"],"content":"goroutine相比线程的优势？ 协程拥有极高的执行效率，子程序切换不是线程切换而是由程序自身控制，所以没有线程切换的开销。和多线程比，线程的数量越多，协程的性能优势就越明显。 协程不需要多线程的锁机制，因为只有一个线程，所以不存在同时写变量的冲突。在协程中控制共享资源不加锁，只需要判断状态就可以，执行效率比多线程要高。 ","date":"2023-05-31","objectID":"/posts/go/interview02/:2:0","tags":["go","面试"],"title":"Golang_Interview_概述","uri":"/posts/go/interview02/"},{"categories":["go"],"content":"go与Java的区别？ 运行：go是静态编译语言；Java基于类的面向对象语言，Java应用程序在JVM上运行。 函数重载：go上不允许函数重载，必须具有方法和函数的唯一名称；java允许函数重载。 多态：Java默认允许多态，而go没有。 路由配置：go语言使用HTTP协议进行路由配置；java使用Akka.routing进行路由配置。 继承：go的继承通过匿名组合完成，基类以Struct的方式定义，子类只需要把基类作为成员放在子类的定义中，支持多继承；Java的继承通过extends关键字完成，不支持多继承。 ","date":"2023-05-31","objectID":"/posts/go/interview02/:3:0","tags":["go","面试"],"title":"Golang_Interview_概述","uri":"/posts/go/interview02/"},{"categories":["go"],"content":"go语言中是如何实现继承的？ 在go中没有extends关键字，所以go并没有原生级别的继承支持。本质上，Go使用组合来代替继承： type Person struct { Name string Age int } type Student struct { Person School string } ","date":"2023-05-31","objectID":"/posts/go/interview02/:4:0","tags":["go","面试"],"title":"Golang_Interview_概述","uri":"/posts/go/interview02/"},{"categories":["go"],"content":"for遍历多次执行goroutine会存在什么问题？ 在协程中打印for的下标i或当前下标的元素 会随机打印载体中的元素。 golang值拷贝传递，for循环很快就执行完了，但是创建的10个协程需要做初始化：上下文准备，堆栈，和内核态的线程映射关系的工作，是需要时间的，比for慢，等都准备好了的时候，会同时访问i。这个时候的i肯定是for执行完成后的下标(也可能有个别的协程已经准备好了，取i的时候，正好是5，或者7，就输出了这些数字)。 解决的方法就是闭包，给匿名函数增加入参，因为是值传递，所以每次for创建一个协程的时候，会拷贝一份i传到这个协程里面去，或者在开启协程之前声明一个新的变量 = i。 for并发读取文件 程序会panic:too many open files 解决的方法：通过带缓冲的channel和sync.waitgroup控制协程并发量。 ","date":"2023-05-31","objectID":"/posts/go/interview02/:5:0","tags":["go","面试"],"title":"Golang_Interview_概述","uri":"/posts/go/interview02/"},{"categories":["go"],"content":"init函数是什么时候执行的？ 特点： init函数先于main函数自动执行，不能被其他函数调用。 init函数没有输入参数、返回值。 每个包可以有多个init函数，包的每个源文件也可以有多个init函数。 go没有明确定义同一个包的init执行顺序，编程时程序不能依赖这个执行顺序。 不同包的init函数按照包导入的依赖关系决定执行顺序。 作用： 初始化不能采用初始化表达式初始化的变量。 程序运行前的注册。 实现sync.Once功能。 执行顺序： go程序初始化先于main函数执行，由runtime进行初始化，初始化顺序如下： 初始化导入的包，包的初始化顺序并不是按导入顺序执行的，runtime需要解析包依赖关系，没有依赖的包最先初始化 初始化包作用域的变量，runtime解析变量依赖关系，没有依赖的变量最先初始化 执行包的init函数 最终初始化顺序：变量初始化 -\u003e init() -\u003e main() ","date":"2023-05-31","objectID":"/posts/go/interview02/:6:0","tags":["go","面试"],"title":"Golang_Interview_概述","uri":"/posts/go/interview02/"},{"categories":["Gin"],"content":"Go操作MySQL","date":"2023-05-30","objectID":"/posts/gin/gin04/","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"Go操作MySQL ","date":"2023-05-30","objectID":"/posts/gin/gin04/:0:0","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"连接 Go语言中的database/sql包提供了保证SQL或类SQL数据库的泛用接口，并不提供具体的数据库驱动。使用database/sql包时必须注入（至少）一个数据库驱动。 我们常用的数据库基本上都有完整的第三方实现。例如：MySQL驱动 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:1:0","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"下载依赖 连接mysql的驱动 go get -u github.com/go-sql-driver/mysql ","date":"2023-05-30","objectID":"/posts/gin/gin04/:1:1","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"使用MySQL驱动 func Open(driverName, dataSourceName string) (*DB, error) Open打开一个dirverName指定的数据库，dataSourceName指定数据源，一般至少包括数据库文件名和其它连接必要的信息。 import ( \"database/sql\" // 匿名导入，导入的时候执行该库里的init方法 _ \"github.com/go-sql-driver/mysql\" ) func main() { // DSN:Data Source Name // \"user:password@tcp(127.0.0.1:3306)/dbname\" dsn := \"root:root1234@tcp(127.0.0.1:3306)/sql_demo\" db, err := sql.Open(\"mysql\", dsn) if err != nil { panic(err) } defer db.Close() // 注意这行代码要写在上面err判断的下面 } 思考题： 为什么上面代码中的defer db.Close()语句不应该写在if err != nil的前面呢？ 做完检查之后，再defer，确保db不为nil，否则defer db.Close()就会出错。很多情况下都需要注意这点。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:1:2","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"初始化连接 Open可能只是验证其参数格式是否正确，实际上并不创建与数据库的连接。如果要检查数据源的名称是否真实有效，应该调用Ping方法。 返回的DB对象可以安全地被多个goroutine并发使用（并发安全的），并且维护其自己的空闲连接池。因此，Open函数应该仅被调用一次，很少需要关闭这个DB对象。 接下来，我们定义一个全局变量db，用来保存数据库连接对象。将上面的示例代码拆分出一个独立的initDB函数，只需要在程序启动时调用一次该函数完成全局变量db的初始化，其他函数中就可以直接使用全局变量db了。（注意下方的注意） // 定义一个全局对象db var db *sql.DB // 定义一个初始化数据库的函数 func initDB() (err error) { // DSN:Data Source Name dsn := \"user:password@tcp(127.0.0.1:3306)/sql_test?charset=utf8mb4\u0026parseTime=True\" // 不会校验账号密码是否正确 // 注意！！！这里不要使用:=，我们是给全局变量赋值，然后在main函数中使用全局变量db db, err = sql.Open(\"mysql\", dsn) if err != nil { return err } // 尝试与数据库建立连接（校验dsn是否正确） err = db.Ping() if err != nil { return err } return nil } func main() { err := initDB() // 调用输出化数据库的函数 if err != nil { fmt.Printf(\"init db failed,err:%v\\n\", err) return } defer db.Close() } 其中sql.DB是表示连接的数据库对象（结构体实例），它保存了连接数据库相关的所有信息。它内部维护着一个具有零到多个底层连接的连接池，它可以安全地被多个goroutine同时使用。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:1:3","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"SetMaxOpenConns func (db *DB) SetMaxOpenConns(n int) SetMaxOpenConns设置与数据库建立连接的最大数目。 如果n大于0且小于最大闲置连接数，会将最大闲置连接数减小到匹配最大开启连接数的限制。 如果n\u003c=0，不会限制最大开启连接数，默认为0（无限制）。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:1:4","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"SetMaxIdleConns func (db *DB) SetMaxIdleConns(n int) SetMaxIdleConns设置连接池中的最大空闲连接数。 如果n大于最大开启连接数，则新的最大闲置连接数会减小到匹配最大开启连接数的限制。 如果n\u003c=0，不会保留闲置连接。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:1:5","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"SetConnMaxLifetime 连接存活的最长时间。 func (db *DB) SetConnMaxLifetime(d time.Duration) 以上的数值根据业务具体的情况设定。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:1:6","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"源码部分 找到包下的一个文件，点击左侧的structure。 橙色的v表示value；蓝色的t表示类型；m表示method；f表示function Register var 中定义了一个全局变量的读写锁，类似于其他语言的单例模式，这种定义在go语言中很常见。单例？ ","date":"2023-05-30","objectID":"/posts/gin/gin04/:1:7","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"CRUD ","date":"2023-05-30","objectID":"/posts/gin/gin04/:2:0","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"建库建表 我们先在MySQL中创建一个名为sql_test的数据库 CREATE DATABASE sql_test; 进入该数据库: use sql_test; 执行以下命令创建一张用于测试的数据表： CREATE TABLE `user` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT, `name` VARCHAR(20) DEFAULT '', `age` INT(11) DEFAULT '0', PRIMARY KEY(`id`) )ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb4; ","date":"2023-05-30","objectID":"/posts/gin/gin04/:2:1","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"查询 为了方便查询，我们事先定义好一个结构体来存储user表的数据。 type user struct { id int age int name string } 单行查询 其实如下这种方式，我们可以发现用起来比较麻烦，后面会讲sqlx的方式。 单行查询db.QueryRow()执行一次查询，并期望返回最多一行结果（即Row）。QueryRow总是返回非nil的值，直到返回值的Scan方法被调用时，才会返回被延迟的错误。（如：未找到结果） func (db *DB) QueryRow(query string, args ...interface{}) *Row 具体示例代码： // 查询单条数据示例 func queryRowDemo() { sqlStr := \"select id, name, age from user where id=?\" var u user // 非常重要：确保QueryRow之后调用Scan方法，否则持有的数据库链接不会被释放 err := db.QueryRow(sqlStr, 1).Scan(\u0026u.id, \u0026u.name, \u0026u.age) if err != nil { fmt.Printf(\"scan failed, err:%v\\n\", err) return } fmt.Printf(\"id:%d name:%s age:%d\\n\", u.id, u.name, u.age) } 多行查询 多行查询db.Query()执行一次查询，返回多行结果（即Rows），一般用于执行select命令。参数args表示query中的占位参数。 func (db *DB) Query(query string, args ...interface{}) (*Rows, error) 具体示例代码： // 查询多条数据示例 func queryMultiRowDemo() { sqlStr := \"select id, name, age from user where id \u003e ?\" rows, err := db.Query(sqlStr, 0) if err != nil { fmt.Printf(\"query failed, err:%v\\n\", err) return } // 非常重要：关闭rows释放持有的数据库链接 defer rows.Close() // 循环读取结果集中的数据 for rows.Next() { var u user err := rows.Scan(\u0026u.id, \u0026u.name, \u0026u.age) if err != nil { fmt.Printf(\"scan failed, err:%v\\n\", err) return } fmt.Printf(\"id:%d name:%s age:%d\\n\", u.id, u.name, u.age) } } ","date":"2023-05-30","objectID":"/posts/gin/gin04/:2:2","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"插入 数据 插入、更新和删除操作都使用Exec方法。只是sql语句不一样。 func (db *DB) Exec(query string, args ...interface{}) (Result, error) Exec执行一次命令（包括查询、删除、更新、插入等），返回的Result是对已执行的SQL命令的总结。参数args表示query中的占位参数。 具体插入数据示例代码如下： // 插入数据 func insertRowDemo() { sqlStr := \"insert into user(name, age) values (?,?)\" ret, err := db.Exec(sqlStr, \"王五\", 38) if err != nil { fmt.Printf(\"insert failed, err:%v\\n\", err) return } theID, err := ret.LastInsertId() // 新插入数据的id if err != nil { fmt.Printf(\"get lastinsert ID failed, err:%v\\n\", err) return } fmt.Printf(\"insert success, the id is %d.\\n\", theID) } ","date":"2023-05-30","objectID":"/posts/gin/gin04/:2:3","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"更新数据 具体更新数据示例代码如下： // 更新数据 func updateRowDemo() { sqlStr := \"update user set age=? where id = ?\" ret, err := db.Exec(sqlStr, 39, 3) if err != nil { fmt.Printf(\"update failed, err:%v\\n\", err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Printf(\"get RowsAffected failed, err:%v\\n\", err) return } fmt.Printf(\"update success, affected rows:%d\\n\", n) } ","date":"2023-05-30","objectID":"/posts/gin/gin04/:2:4","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"删除数据 具体删除数据的示例代码如下： // 删除数据 func deleteRowDemo() { sqlStr := \"delete from user where id = ?\" ret, err := db.Exec(sqlStr, 3) if err != nil { fmt.Printf(\"delete failed, err:%v\\n\", err) return } n, err := ret.RowsAffected() // 操作影响的行数 if err != nil { fmt.Printf(\"get RowsAffected failed, err:%v\\n\", err) return } fmt.Printf(\"delete success, affected rows:%d\\n\", n) } ","date":"2023-05-30","objectID":"/posts/gin/gin04/:2:5","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"MySQL预处理 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:3:0","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"什么是预处理 普通SQL语句执行过程： 客户端对SQL语句进行占位符替换得到完整的SQL语句。 客户端发送完整SQL语句到MySQL服务端 MySQL服务端执行完整的SQL语句并将结果返回给客户端。 预处理执行过程： 把SQL语句分成两部分，命令部分与数据部分。 先把命令部分发送给MySQL服务端，MySQL服务端进行SQL预处理。 然后把数据部分发送给MySQL服务端，MySQL服务端对SQL语句进行占位符替换。 MySQL服务端执行完整的SQL语句并将结果返回给客户端。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:3:1","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"为什么要预处理 优化MySQL服务器重复执行SQL的方法，可以提升服务器性能，提前让服务器编译，一次编译多次执行，节省后续编译的成本。 避免SQL注入问题。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:3:2","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"Go实现MySQL预处理 database/sql中使用下面的Prepare方法来实现预处理操作。 func (db *DB) Prepare(query string) (*Stmt, error) Prepare方法会先将sql语句发送给MySQL服务端，返回一个准备好的状态用于之后的查询和命令。返回值可以同时执行多个查询和命令。 查询操作的预处理示例代码如下： // 预处理查询示例 func prepareQueryDemo() { sqlStr := \"select id, name, age from user where id \u003e ?\" stmt, err := db.Prepare(sqlStr) if err != nil { fmt.Printf(\"prepare failed, err:%v\\n\", err) return } defer stmt.Close() rows, err := stmt.Query(0) if err != nil { fmt.Printf(\"query failed, err:%v\\n\", err) return } defer rows.Close() // 循环读取结果集中的数据 for rows.Next() { var u user err := rows.Scan(\u0026u.id, \u0026u.name, \u0026u.age) if err != nil { fmt.Printf(\"scan failed, err:%v\\n\", err) return } fmt.Printf(\"id:%d name:%s age:%d\\n\", u.id, u.name, u.age) } } 插入、更新和删除操作的预处理十分类似，这里以插入操作的预处理为例： // 预处理插入示例 func prepareInsertDemo() { sqlStr := \"insert into user(name, age) values (?,?)\" stmt, err := db.Prepare(sqlStr) if err != nil { fmt.Printf(\"prepare failed, err:%v\\n\", err) return } defer stmt.Close() _, err = stmt.Exec(\"小王子\", 18) if err != nil { fmt.Printf(\"insert failed, err:%v\\n\", err) return } _, err = stmt.Exec(\"沙河娜扎\", 18) if err != nil { fmt.Printf(\"insert failed, err:%v\\n\", err) return } fmt.Println(\"insert success.\") } ","date":"2023-05-30","objectID":"/posts/gin/gin04/:3:3","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"SQL注入问题 我们任何时候都不应该自己拼接SQL语句！ 这里我们演示一个自行拼接SQL语句的示例，编写一个根据name字段查询user表的函数如下： // sql注入示例 func sqlInjectDemo(name string) { sqlStr := fmt.Sprintf(\"select id, name, age from user where name='%s'\", name) fmt.Printf(\"SQL:%s\\n\", sqlStr) var u user err := db.QueryRow(sqlStr).Scan(\u0026u.id, \u0026u.name, \u0026u.age) if err != nil { fmt.Printf(\"exec failed, err:%v\\n\", err) return } fmt.Printf(\"user:%#v\\n\", u) } 此时以下输入字符串都可以引发SQL注入问题： sqlInjectDemo(\"xxx' or 1=1#\") sqlInjectDemo(\"xxx' union select * from user #\") sqlInjectDemo(\"xxx' and (select count(*) from user) \u003c10 #\") **补充：**不同的数据库中，SQL语句使用的占位符语法不尽相同。 数据库 占位符语法 MySQL ? PostgreSQL $1, $2等 SQLite ? 和$1 Oracle :name ","date":"2023-05-30","objectID":"/posts/gin/gin04/:3:4","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"Go实现MySQL事务 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:4:0","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"什么是事务 事务：一个最小的不可再分的工作单元；通常一个事务对应一个完整的业务(例如银行账户转账业务，该业务就是一个最小的工作单元)，同时这个完整的业务需要执行多次的DML(insert、update、delete)语句共同联合完成。A转账给B，这里面就需要执行两次update操作。 在MySQL中只有使用了Innodb数据库引擎的数据库或表才支持事务。事务处理可以用来维护数据库的完整性，保证成批的SQL语句要么全部执行，要么全部不执行。通过A转账给B的例子来理解。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:4:1","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"事务的ACID 通常事务必须满足4个条件（ACID）：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。 条件 解释 原子性 一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。 一致性 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。 隔离性 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 ","date":"2023-05-30","objectID":"/posts/gin/gin04/:4:2","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"事务相关方法 Go语言中使用以下三个方法实现MySQL中的事务操作。 开始事务 func (db *DB) Begin() (*Tx, error) 提交事务 func (tx *Tx) Commit() error 回滚事务 func (tx *Tx) Rollback() error ","date":"2023-05-30","objectID":"/posts/gin/gin04/:4:3","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["Gin"],"content":"事务示例 下面的代码演示了一个简单的事务操作，该事物操作能够确保两次更新操作要么同时成功要么同时失败，不会存在中间状态。 // 事务操作示例 func transactionDemo() { tx, err := db.Begin() // 开启事务 if err != nil { if tx != nil { tx.Rollback() // 回滚 } fmt.Printf(\"begin trans failed, err:%v\\n\", err) return } sqlStr1 := \"Update user set age=30 where id=?\" ret1, err := tx.Exec(sqlStr1, 2) if err != nil { tx.Rollback() // 回滚 fmt.Printf(\"exec sql1 failed, err:%v\\n\", err) return } affRow1, err := ret1.RowsAffected() if err != nil { tx.Rollback() // 回滚 fmt.Printf(\"exec ret1.RowsAffected() failed, err:%v\\n\", err) return } sqlStr2 := \"Update user set age=40 where id=?\" ret2, err := tx.Exec(sqlStr2, 3) if err != nil { tx.Rollback() // 回滚 fmt.Printf(\"exec sql2 failed, err:%v\\n\", err) return } affRow2, err := ret2.RowsAffected() if err != nil { tx.Rollback() // 回滚 fmt.Printf(\"exec ret1.RowsAffected() failed, err:%v\\n\", err) return } fmt.Println(affRow1, affRow2) // 受影响行数都是1时 if affRow1 == 1 \u0026\u0026 affRow2 == 1 { fmt.Println(\"事务提交啦...\") tx.Commit() // 提交事务 } else { tx.Rollback() fmt.Println(\"事务回滚啦...\") } fmt.Println(\"exec trans success!\") } ","date":"2023-05-30","objectID":"/posts/gin/gin04/:4:4","tags":["Gin","go"],"title":"Go操作数据库01","uri":"/posts/gin/gin04/"},{"categories":["go"],"content":"表示熟悉 表示掌握 表示了解 ","date":"2023-05-30","objectID":"/posts/go/interview01/:0:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"make和new的区别 new(T) 和 make(T,args) 是 Go 语言内建函数，用来分配内存，但适用的类型不同。 new(T) 会为 T 类型的新值分配已置零的内存空间，并返回地址（指针），即类型为 *T的值。换句话说就是，返回一个指针，该指针指向新分配的、类型为 T 的零值。适用于值类型，如数组、结构体等；new可被替代，能够通过字面值快速初始化。 make(T,args) 分配并初始化，返回初始化之后的 T 类型的引用，而并不是 T 类型的零值，也不是指针 *T；make() 只适用于 slice、map 和 channel；make函数会对三种类型的内部数据结构（长度、容量等）赋值。 ","date":"2023-05-30","objectID":"/posts/go/interview01/:1:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"slice的底层实现？ 切片的底层是一个结构体，对应三个参数，一个是unsafe.Pointer指针，指向一个具体的底层数组，一个是cap，切片的容量，一个是len，切片的长度。 因为切片是基于数组实现，所以它的底层的内存是连续分配的，效率非常高，可以通过索引获得数据。切片本身并不是动态数组或者数组指针，而是设定相关属性，将数据读写操作限定在指定的区域内。切片本身是一个只读对象，其工作机制类似数组指针的一种封装。 如果make函数初始化了一个太大的切片，该切片就会逃逸到堆区；如果分配了一个比较小的切片，就会被分配到栈区，切片大小的临界值默认为64KB，因此make([]int64, 1023) 和 make([]int64, 1024) 是完全不同的内存布局。 type slice struct { array unsafe.Pointer len int cap int } ","date":"2023-05-30","objectID":"/posts/go/interview01/:2:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"slice和数组的区别？ 切片是引用类型，数组是值类型 传递数组是通过拷贝的方式，传递切片是通过传递引用的方式。 数组的长度固定，而切片可以进行动态扩容 数组是一组内存空间连续的数据，一旦初始化长度大小就不会再改变，切片的长度可以进行扩展，当切片底层的数组容量不够时，切片会创建新的底层数组。 切片比数组多一个属性容量（cap) ","date":"2023-05-30","objectID":"/posts/go/interview01/:3:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"slice的扩容机制？ 扩容主要分为两个过程：第一步是分配新的内存空间，第二步是将原有切片内容进行复制。分配新空间时候需要估计大致容量，然后再确定容量。 根据该切片当前容量选择不同的策略： 如果期望容量大于当前容量的两倍，就会使用期望容量 如果当前切片的长度小于 1024，容量就会翻倍 如果当前切片的长达大于 1024，每次扩容 25% 的容量，直到新容量大于期望容量 在进行循环1.25倍计算时，最终容量计算值发生溢出，即超过了int的最大范围，则最终容量就是新申请的容量 对于切片的扩容 当切片比较小的，采用较大的扩容倍速进行扩容，避免频繁扩容，从而减少内存分配的次数和数据拷贝的代价 当切片较大的时，采用较小的扩容倍速，主要避免空间浪费 ","date":"2023-05-30","objectID":"/posts/go/interview01/:4:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"channel的概念？ channel又称为管道，用于数据传递或数据共享，其本质是一个先进先出的队列，使用goroutine+channel进行数据通讯简单高效，同时也线程安全，多个goroutine可同时修改一个channel，不需要加锁。 ","date":"2023-05-30","objectID":"/posts/go/interview01/:5:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"channel有哪些状态？ nil：未初始化的状态，只进行了声明，或者手动赋值为nil。 active：正常的channel，可读或者可写。 closed：已关闭，channel的值不是nil。 关闭的状态的channel仍然可以读值（取值），但不能写值（会报panic: send on closed channel）。 nil状态的channel是不能close（panic: close of nil channel）的。 如果关闭后的 channel 没有数据可读取时，将得到零值，即对应类型的默认值。 操作 空channel 已关闭channel 活跃中的channel close(ch) panic panic 成功关闭 ch\u003c- v（写） 永远阻塞 panic 成功发送或阻塞 v,ok = \u003c-ch（读） 永远阻塞 不阻塞 成功接收或阻塞 ","date":"2023-05-30","objectID":"/posts/go/interview01/:6:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"如何判断channel已经关闭？ if v, ok := \u003c-ch; !ok { fmt.Println(\"channel 已关闭，读取不到数据\") } ","date":"2023-05-30","objectID":"/posts/go/interview01/:7:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"select的用途？ select可以理解为是在语言层面实现了和I/O多路复用相似的功能：监听多个描述符的读/写等事件，一旦某个描述符就绪(一般是读或者写事件发生了)，就能够将发生的事件通知给关心的应用程序去处理该事件。 golang的select机制是：监听多个channel，每一个case是一个事件，可以是读事件也可以是写事件，随机选择一个执行。可以设置default，它的作用是当监听的多个事件都阻塞住就会执行default的逻辑。 select { case \u003c-ch1: // 如果从 ch1 信道成功接收数据，则执行该分支代码 case ch2 \u003c- 1: // 如果成功向 ch2 信道成功发送数据，则执行该分支代码 default: // 如果上面都没有成功，则进入 default 分支处理流程 } 提示\rselect语句只能用于信道的读写操作 select中的case条件(非阻塞)是并发执行的，select会选择先操作成功的那个case条件去执行，如果多个同时返回，则随机选择一个执行，此时将无法保证执行顺序 对于case条件语句中，如果存在信道值为nil的读写操作，则该分支将被忽略，可以理解为从select语句中删除了这个case语句 如果有超时条件语句，判断逻辑为如果在这个时间段内一直没有满足条件的case，则执行这个超时case。如果此段时间内出现了可操作的case，则直接执行这个case。一般用超时语句代替了default语句。 对于空的select{}，会引起死锁 对于for中的select{}, 可能会引起cpu占用过高的问题 ","date":"2023-05-30","objectID":"/posts/go/interview01/:8:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"defer的概述？ defer是go语言提供的一种用于注册延迟调用的机制：让函数或者语句在当前函数执行完毕(包括return正常结束或者panic导致的异常结束)之后进行调用。 panic和defer到底谁先执行，这个问题没有搞清楚，需要自己写代码测试一下，我好像知道怎么回事了，得分具体的情况 defer具有以下特性： 延迟调用：defer在main函数return之前调用，且defer必须置于函数内部 LIFO：后进先出，压栈式执行 作用域：defer只和defer所在函数绑定在一起，作用域也只在这个函数，如果defer处于匿名函数中，会先调用匿名函数中的defer ","date":"2023-05-30","objectID":"/posts/go/interview01/:9:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"defer的使用场景？ defer关键字通常通常出现在一些成对出现的操作中，比如创建关闭链接、加锁解锁、打开关闭文件等操作。defer在一些资源回收的场景很有用。 ","date":"2023-05-30","objectID":"/posts/go/interview01/:10:0","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"并发处理 var wg sync.WaitGroup for i := 0; i \u003c 2; i++ { wg.Add(1) go func() { defer wg.Done() // 程序逻辑 }() } wg.Wait() ","date":"2023-05-30","objectID":"/posts/go/interview01/:10:1","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"锁场景 mu.RLock() defer mu.RUnlock() ","date":"2023-05-30","objectID":"/posts/go/interview01/:10:2","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"资源释放 // new 一个客户端 client； cli, err := clientv3.New(clientv3.Config{Endpoints: endpoints}) if err != nil { log.Fatal(err) } // 释放该 client ，也就是说该 client 的声明周期就只在该函数中； defer cli.Close() ","date":"2023-05-30","objectID":"/posts/go/interview01/:10:3","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["go"],"content":"panic-recover defer func() { if v := recover(); v != nil { _ = fmt.Errorf(\"PANIC=%v\", v) } }() ","date":"2023-05-30","objectID":"/posts/go/interview01/:10:4","tags":["go","面试"],"title":"Golang_Interview_关键字","uri":"/posts/go/interview01/"},{"categories":["Go每日一练"],"content":"Day11 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:1:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"1.关于 cap() 函数的适用类型，下面说法正确的是? A. array B. slice C. map D. channel 参考答案及解析：ABD。知识点：cap()，cap() 函数不适用 map，适用于array、slice、channel。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:1:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ func main() { var i interface{} if i == nil { fmt.Println(\"nil\") return } fmt.Println(\"not nil\") } A. nil B. not nil C. compilation error 参考答案及解析：A。当且仅当接口的动态值和动态类型都为 nil 时，接口类型值才为 nil。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:1:2","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"3.下面这段代码输出什么？ func main() { s := make(map[string]int) delete(s, \"h\") fmt.Println(s[\"h\"]) } A. runtime panic B. 0 C. compilation error 参考答案及解析：B。删除 map 不存在的键值对时，不会报错，相当于没有任何作用；获取不存在的键值对时，返回值类型对应的零值，所以返回 0。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:1:3","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day12 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:2:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"1.下面属于关键字的是？ A.func B.struct C.class D.defer 参考答案及解析：ABD。知识点：Go 语言的关键字。Go 语言有 25 个关键字，看下图： ","date":"2023-05-30","objectID":"/posts/go/day11-20/:2:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ func main() { i := -5 j := +5 fmt.Printf(\"%+d %+d\", i, j) } A. -5 +5 B. +5 +5 C. 0 0 参考答案及解析：A。%d表示输出十进制数字，+表示输出数值的符号。这里不表示取反。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:2:2","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"3.下面这段代码输出什么？ type People struct{} func (p *People) ShowA() { fmt.Println(\"showA\") p.ShowB() } func (p *People) ShowB() { fmt.Println(\"showB\") } type Teacher struct { People } func (t *Teacher) ShowB() { fmt.Println(\"teacher showB\") } func main() { t := Teacher{} t.ShowB() } 参考答案及解析：teacher showB。知识点：结构体嵌套。在嵌套结构体中，People 称为内部类型，Teacher 称为外部类型；通过嵌套，内部类型的属性、方法，可以为外部类型所有，就好像是外部类型自己的一样。此外，外部类型还可以定义自己的属性和方法，甚至可以定义与内部相同的方法，这样内部类型的方法就会被“屏蔽”。这个例子中的 ShowB() 就是同名方法。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:2:3","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day13 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:3:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"1.定义一个包内全局字符串变量，下面语法正确的是？ A. var str string B. str := \"\" C. str = \"\" D. var str = \"\" 参考答案及解析：AD。B str := \"\"只支持局部变量声明；C 是赋值，str 必须在这之前已经声明；只有var str string和var str = \"\"支持全局变量。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:3:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么? func hello(i int) { fmt.Println(i) } func main() { i := 5 defer hello(i) i = i + 10 } 参考答案及解析：5。这个例子中，hello() 函数的参数在执行 defer 语句的时候会保存一份副本，在实际调用 hello() 函数时用，所以是 5. ","date":"2023-05-30","objectID":"/posts/go/day11-20/:3:2","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"3.下面这段代码输出什么？ type People struct{} func (p *People) ShowA() { fmt.Println(\"showA\") p.ShowB() } func (p *People) ShowB() { fmt.Println(\"showB\") } type Teacher struct { People } func (t *Teacher) ShowB() { fmt.Println(\"teacher showB\") } func main() { t := Teacher{} t.ShowA() } 参考答案及解析： showA showB 知识点：结构体嵌套。这道题可以结合第 12 天的第三题一起看，Teacher 没有自己 ShowA()，所以调用内部类型 People 的同名方法，需要注意的是第 5 行代码调用的是 People 自己的 ShowB 方法。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:3:3","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day14 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:4:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"1.下面代码输出什么？ func main() { str := \"hello\" str[0] = 'x' fmt.Println(str) } A. hello B. xello C. compilation error 参考代码及解析：C。知识点：常量，Go 语言中的字符串是只读的。如果真要修改字符串中的字符，将 string 转为 []byte 修改后，再转为 string 即可。注意如果要修改汉汉字的话需要转为[]rune。（这里说的是修改字符串中的字符，如果直接修改字符串的话直接修改就行） func main() { s := \"text\" sBytes := []byte(s) sBytes[0] = 'T' s = string(sBytes) fmt.Println(s) } package main import ( \"fmt\" ) func main() { s := \"text\" sRunes := []rune(s) sRunes[0] = '我' s = string(sRunes) fmt.Println(s) } byte 表示一个字节，rune 表示四个字节，所以当汉字这种一个字需要多个字节的文字，使用一个字节的byte来表示汉字自然会报错，这个时候就要使用rune来表示。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:4:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ func incr(p *int) int { *p++ return *p } func main() { p :=1 incr(\u0026p) fmt.Println(p) } A. 1 B. 2 C. 3 参考答案及解析：B。知识点：指针，incr() 函数里的 p 是 *int 类型的指针，指向的是 main() 函数的变量 p 的地址。第 2 行代码是将该地址的值执行一个自增操作，incr() 返回自增后的结果。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:4:2","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"3.对add()函数调用正确的是? func add(args ...int) int { sum := 0 for _, arg := range args { sum += arg } return sum } A. add(1, 2) B. add(1, 3, 7) C. add([]int{1, 2}) D. add([]int{1, 3, 7}…) 参考答案及解析：ABD。知识点：可变函数。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:4:3","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day15 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:5:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"1.下面代码下划线处可以填入哪个选项？ func main() { var s1 []int var s2 = []int{} // 空切片 if __ == nil { fmt.Println(\"yes nil\") }else{ fmt.Println(\"no nil\") } } A. s1 B. s2 C. s1、s2 都可以 参考答案及解析：A。填入A输出yes nil，填入B输出no nil。知识点：nil 切片和空切片。nil 切片和 nil 相等，一般用来表示一个不存在的切片；空切片和 nil 不相等，表示一个空的集合。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:5:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"延伸：Go中的nil切片、 空切片与零切片 nil 切片、空切片与零切片是切片的三种状态，nil 切片是指在声明时未做初始化的切片，不用分配内存空间，一般使用 var 创建。使用 make 创建的空切片需要分配内存空间，nil 切片与空切片的长度、容量都为 0 ，如果我们要创建长度容量为 0 的切片，官方推荐 nil 切片。零切片指初始值为类型零值的切片。 // 创建 nil 切片 var slice []int fmt.Println(slice,*(*reflect.SliceHeader)(unsafe.Pointer(\u0026slice))) // 输出：[] {0 0 0} // 创建空切片 var slice1 = []int{} slice2 := make([]int,0) slice3 := []int{} fmt.Println(slice1, *(*reflect.SliceHeader)(unsafe.Pointer(\u0026slice1))) // 输出：[] {18504816 0 0} fmt.Println(slice2,*(*reflect.SliceHeader)(unsafe.Pointer(\u0026slice2))) // 输出：[] {18504816 0 0} fmt.Println(slice3,*(*reflect.SliceHeader)(unsafe.Pointer(\u0026slice3))) // 输出：[] {18504816 0 0} // 创建零切片 slice4 := make([]int,2,5) fmt.Println(slice4,*(*reflect.SliceHeader)(unsafe.Pointer(\u0026slice4))) // 输出：[0 0] {824634474496 2 5} Go语言在声明变量的时候，会自动对变量对应的内存区域进行初始化操作。每个变量会被初始化成其类型的默认值，例如： 整型和浮点型变量的默认值为0。 字符串变量的默认值为空字符串。 布尔型变量默认为false。 切片、函数、指针变量的默认为nil。 nil切片和空切片指向的地址不一样。nil空切片引用数组指针地址为0（无指向任何实际地址） 空切片的引用数组指针地址是有的，且固定为一个值 nil切片和空切片最大的区别在于指向的数组引用地址是不一样的。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:5:2","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ func main() { i := 65 fmt.Println(string(i)) } A. A B. 65 C. compilation error 参考答案及解析：A。UTF-8 编码中，十进制数字 65 对应的符号是 A。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:5:3","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"3.下面这段代码输出什么? type A interface { ShowA() int } type B interface { ShowB() int } type Work struct { i int } func (w Work) ShowA() int { return w.i + 10 } func (w Work) ShowB() int { return w.i + 20 } func main() { c := Work{3} var a A = c var b B = c fmt.Println(a.ShowA()) fmt.Println(b.ShowB()) } 参考答案及解析：13 23。知识点：接口。一种类型实现多个接口，结构体 Work 分别实现了接口 A、B，所以接口变量 a、b 调用各自的方法 ShowA() 和 ShowB()，输出 13、23。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:5:4","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day16 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:6:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"1.切片a、b、c的长度和容量分别是多少？ func main() { s := [3]int{1, 2, 3} a := s[:0] b := s[:2] c := s[1:2:cap(s)] } 参考答案及解析： len cap a 0 3 b 2 3 c 1 2 知识点：数组或切片的截取操作。截取操作有带 2 个或者 3 个参数，形如：[i:j] 和 [i:j:k]，假设截取对象的底层数组长度为 l。在操作符 [i:j] 中，如果 i 省略，默认 0，如果 j 省略，默认底层数组的长度，截取得到的切片长度和容量计算方法是** j-i、l-i。操作符 [i:j:k]，k 主要是用来限制切片的容量，但是不能大于数组的长度 l，截取得到的切片长度和容量计算方法是 j-i、k-i**。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:6:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"2.下面代码中 A B 两处应该怎么修改才能顺利编译？ func main() { var m map[string]int //A m[\"a\"] = 1 if v := m[\"b\"]; v != nil { //B fmt.Println(v) } } 参考答案及解析： func main() { m := make(map[string]int) m[\"a\"] = 1 if v,ok := m[\"b\"]; ok { fmt.Println(v) } } 在 A 处只声明了map m ,并没有分配内存空间，不能直接赋值，需要使用 make()，都提倡使用 make() 或者字面量的方式直接初始化 map。 B 处，v, ok := m[\"b\"] 当 key 为 b 的元素不存在的时候，v 会返回值类型对应的零值，k 返回 false。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:6:2","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"3.下面代码输出什么？ type A interface { ShowA() int } type B interface { ShowB() int } type Work struct { i int } func (w Work) ShowA() int { return w.i + 10 } func (w Work) ShowB() int { return w.i + 20 } func main() { c := Work{3} var a A = c var b B = c fmt.Println(a.ShowB()) fmt.Println(b.ShowA()) } A. 23 13 B. compilation error 参考答案及解析：B。知识点：接口的静态类型。a、b 具有相同的动态类型和动态值，分别是结构体 work 和 {3}；a 的静态类型是 A，b 的静态类型是 B，接口 A 不包括方法 ShowB()，接口 B 也不包括方法 ShowA()，编译报错。看下编译错误： a.ShowB undefined (type A has no field or method ShowB) b.ShowA undefined (type B has no field or method ShowA) ","date":"2023-05-30","objectID":"/posts/go/day11-20/:6:3","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day17 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:7:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"1.下面代码中，x已声明，y没有声明，判断每条语句的对错。 x, _ := f() x, _ = f() x, y := f(), f() x, y = f() 参考答案及解析：错、对、对、错。知识点：变量的声明。 1.错，x 已经声明，不能使用 :=； 2.对； 3.对，当多值赋值时，:= 左边的变量无论声明与否都可以； 4.错，y 没有声明。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:7:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ func increaseA() int { var i int defer func() { i++ }() return i } func increaseB() (r int) { defer func() { r++ }() return r } func main() { fmt.Println(increaseA()) fmt.Println(increaseB()) } A. 1 1 B. 0 1 C. 1 0 D. 0 0 参考答案及解析：B。知识点：defer、返回值。注意一下，increaseA() 的返回参数是匿名，increaseB() 是具名参数。匿名返回值，返回值实在return执行时声明的，defer无法访问，等价于return了一个i的值拷贝，defer修改i不影响返回值。具名返回值defer可以直接访问修改。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:7:2","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"3.下面代码输出什么？ type A interface { ShowA() int } type B interface { ShowB() int } type Work struct { i int } func (w Work) ShowA() int { return w.i + 10 } func (w Work) ShowB() int { return w.i + 20 } func main() { var a A = Work{3} s := a.(Work) fmt.Println(s.ShowA()) // 这里都是通过s去调用show方法 fmt.Println(s.ShowB()) } A. 13 23 B. compilation error 参考答案及解析：A。知识点：类型断言。这道题可以和第 15 天的第三题 和第 16 天的第三题结合起来看 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:7:3","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day18 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:8:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"f1()、f2()、f3()函数分别返回什么？ func f1() (r int) { defer func() { r++ }() return 0 } func f2() (r int) { t := 5 defer func() { t = t + 5 }() return t } func f3() (r int) { defer func(r int) { r = r + 5 }(r) return 1 } f1()=1、f2()=5、f3()=1 f2()的原理不是特别清楚，f1、f3简单。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:8:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day19 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:9:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"下面代码段输出什么？ type Person struct { age int } func main() { person := \u0026Person{28} // 1. defer fmt.Println(person.age) // 2. defer func(p *Person) { fmt.Println(p.age) }(person) // 3. defer func() { fmt.Println(person.age) }() person.age = 29 } 参考答案及解析：29 29 28。变量 person 是一个指针变量 。 1.person.age 此时是将 28 当做 defer 函数的参数，会把 28 缓存在栈中，等到最后执行该 defer 语句的时候取出，即输出 28； 2.defer 缓存的是结构体 Person{28} 的地址，最终 Person{28} 的 age 被重新赋值为 29，所以 defer 语句最后执行的时候，依靠缓存的地址取出的 age 便是 29，即输出 29； 3.闭包引用，输出 29； 又由于 defer 的执行顺序为先进后出，即 3 2 1，所以输出 29 29 28。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:9:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"Day20 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:10:0","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"1.下面这段代码正确的输出是什么？ func f() { defer fmt.Println(\"D\") fmt.Println(\"F\") } func main() { f() fmt.Println(\"M\") } A. F M D B. D F M C. F D M 参考答案及解析：C。被调用函数里的 defer 语句在返回之前就会被执行，所以输出顺序是 F D M。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:10:1","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Go每日一练"],"content":"2.下面代码输出什么？ type Person struct { age int } func main() { person := \u0026Person{28} // 1. defer fmt.Println(person.age) // 2. defer func(p *Person) { fmt.Println(p.age) }(person) // 3. defer func() { fmt.Println(person.age) }() person = \u0026Person{29} } 参考答案及解析：29 28 28。这道题在第 19 天题目的基础上做了一点点小改动，前一题最后一行代码 person.age = 29 是修改引用对象的成员 age，这题最后一行代码 person = \u0026Person{29} 是修改引用对象本身，来看看有什么区别。 1处.person.age 这一行代码跟之前含义是一样的，此时是将 28 当做 defer 函数的参数，会把 28 缓存在栈中，等到最后执行该 defer 语句的时候取出，即输出 28； 2处.defer 缓存的是结构体 Person{28} 的地址，这个地址指向的结构体没有被改变，最后 defer 语句后面的函数执行的时候取出仍是 28； 3处.闭包引用，person 的值已经被改变，指向结构体 Person{29}，所以输出 29. 由于 defer 的执行顺序为先进后出，即 3 2 1，所以输出 29 28 28。 ","date":"2023-05-30","objectID":"/posts/go/day11-20/:10:2","tags":["go","面试"],"title":"Go Exercises(Day11-20)","uri":"/posts/go/day11-20/"},{"categories":["Gin"],"content":"中间件的注册 gin框架中的中间件设计很巧妙，我们可以首先从我们最常用的r := gin.Default()的Default函数开始看，它内部构造一个新的engine之后就通过Use()函数注册了Logger中间件和Recovery中间件： Logger中间件用于在我们的开发阶段，在终端打印出一些可供调试的日志。 Recovery中间件是在我们的程序发生panic的时候，恢复一下现场，防止程序崩掉。 func Default() *Engine { debugPrintWARNINGDefault() engine := New() engine.Use(Logger(), Recovery()) // 默认注册的两个中间件 return engine } 继续往下查看一下Use()函数的代码： func (engine *Engine) Use(middleware ...HandlerFunc) IRoutes { engine.RouterGroup.Use(middleware...) // 实际上还是调用的RouterGroup的Use函数 engine.rebuild404Handlers() engine.rebuild405Handlers() return engine } engine.RouterGroup.Use 从下方的代码可以看出，注册中间件其实就是将中间件函数追加到group.Handlers中： func (group *RouterGroup) Use(middleware ...HandlerFunc) IRoutes { group.Handlers = append(group.Handlers, middleware...) return group.returnObj() } 而我们注册路由时会将对应路由的函数和之前的中间件函数结合到一起： func (group *RouterGroup) handle(httpMethod, relativePath string, handlers HandlersChain) IRoutes { absolutePath := group.calculateAbsolutePath(relativePath) handlers = group.combineHandlers(handlers) // 将处理请求的函数与中间件函数结合 group.engine.addRoute(httpMethod, absolutePath, handlers) return group.returnObj() } 其中结合操作的函数内容如下，注意观察这里是如何实现拼接两个切片得到一个新切片的。 const abortIndex int8 = math.MaxInt8 / 2 func (group *RouterGroup) combineHandlers(handlers HandlersChain) HandlersChain { finalSize := len(group.Handlers) + len(handlers) if finalSize \u003e= int(abortIndex) { // 这里有一个最大限制 panic(\"too many handlers\") } mergedHandlers := make(HandlersChain, finalSize) copy(mergedHandlers, group.Handlers) copy(mergedHandlers[len(group.Handlers):], handlers) return mergedHandlers } 也就是说，我们会将一个路由的中间件函数和处理函数结合到一起组成一条处理函数链条HandlersChain，而它本质上就是一个由HandlerFunc组成的切片： type HandlersChain []HandlerFunc ","date":"2023-05-29","objectID":"/posts/gin/gin03/:1:0","tags":["Gin"],"title":"Gin框架中间件详解","uri":"/posts/gin/gin03/"},{"categories":["Gin"],"content":"中间件的执行 我们在上面路由匹配的时候见过如下逻辑： value := root.getValue(rPath, c.Params, unescape) if value.handlers != nil { c.handlers = value.handlers c.Params = value.params c.fullPath = value.fullPath c.Next() // 执行函数链条 c.writermem.WriteHeaderNow() return } 其中c.Next()就是很关键的一步，它的代码很简单： func (c *Context) Next() { c.index++ for c.index \u003c int8(len(c.handlers)) { c.handlers[c.index](c) c.index++ } } 从上面的代码可以看到，这里通过索引遍历HandlersChain链条，从而实现依次调用该路由的每一个函数（中间件或处理请求的函数）。 我们可以在中间件函数中通过再次调用c.Next()实现嵌套调用（func1中调用func2；func2中调用func3）， 或者通过调用c.Abort()中断整个调用链条，从当前函数返回。 func (c *Context) Abort() { c.index = abortIndex // 直接将索引置为最大限制值，从而退出循环，循环说的是c.Next()的循环 } ","date":"2023-05-29","objectID":"/posts/gin/gin03/:2:0","tags":["Gin"],"title":"Gin框架中间件详解","uri":"/posts/gin/gin03/"},{"categories":["Gin"],"content":"c.Set()/c.Get( ) c.Set()和c.Get()这两个方法多用于在多个函数之间通过c传递数据的，比如我们可以在认证中间件中获取当前请求的相关信息（userID等）通过c.Set()存入c，然后在后续处理业务逻辑的函数中通过c.Get()来获取当前请求的用户。c就像是一根绳子，将该次请求相关的所有的函数都串起来了。c.Set()存的时候存的是一个空接口类型，get的时候的拿到的也是空接口，然后再转的具体类型。 正如下图的逻辑，我们拿到v之后需要将它转换成想要的类型。 ","date":"2023-05-29","objectID":"/posts/gin/gin03/:3:0","tags":["Gin"],"title":"Gin框架中间件详解","uri":"/posts/gin/gin03/"},{"categories":["Gin"],"content":"总结 gin框架路由使用前缀树，路由注册的过程是构造前缀树的过程，路由匹配的过程就是查找前缀树的过程。 gin框架的中间件函数和处理函数是以切片形式的调用链条存在的，我们可以顺序调用也可以借助c.Next()方法实现嵌套调用。 借助c.Set()和c.Get()方法我们能够在不同的中间件函数中传递数据。 ","date":"2023-05-29","objectID":"/posts/gin/gin03/:4:0","tags":["Gin"],"title":"Gin框架中间件详解","uri":"/posts/gin/gin03/"},{"categories":["k8s"],"content":"Kubernetes基础概念 ","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:0:0","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["k8s"],"content":"是什么 在有了容器的概念之后，我们急需要一个大规模的容器编排系统，而k8s就是这样的一个系统。 kubernetes具有以下特性： 服务发现和负载均衡 Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。 服务发现是说，k8s自己能知道那个服务是坏的，宕掉的；而负载均衡是说干同样事情的3台机器，k8s选择性地进行分配任务。 存储编排 Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。 自动部署和回滚 你可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态 更改为期望状态。例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。 自动完成装箱计算 Kubernetes 允许你指定每个容器所需 CPU 和内存（RAM）。 当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。 自我修复 Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的 运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。 密钥与配置管理 Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。 Kubernetes 为你提供了一个可弹性运行分布式系统的框架。 Kubernetes 会满足你的扩展要求、故障转移、部署模式等。 例如，Kubernetes 可以轻松管理系统的 Canary 部署。 ","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:1:0","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["k8s"],"content":"K8s架构 ","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:2:0","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["k8s"],"content":"工作方式 Kubernetes Cluster = N Master Node + N Worker Node：N主节点+N工作节点； N\u003e=1 在生产环境的安装都是集群模式，很多台机器都安装k8s，每一台机器叫做一个节点。N通常选奇数，这样方便投票选领导。 ","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:2:1","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["k8s"],"content":"组件架构 先理解以下几点： 集群中所有组件的交互都是通过api-server交互的。 集群里面的网络都是通过kube-proxy访问的。 集群中所有运行的应用，都需要有一个容器运行时环境，如docker。 集群中每一个节点都需有一个kubelet，监控节点中部署的所有应用的情况。 控制平面组件（Control Plane Components） 控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。 控制平面组件可以在集群中的任何节点上运行。 然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件， 并且不会在此计算机上运行用户容器。 请参阅使用 kubeadm 构建高可用性集群 中关于多 VM 控制平面设置的示例。 kube-apiserver API 服务器是 Kubernetes 控制面的组件， 该组件公开了 Kubernetes API。 API 服务器是 Kubernetes 控制面的前端。 Kubernetes API 服务器的主要实现是 kube-apiserver。 kube-apiserver 设计上考虑了水平伸缩，也就是说，它可通过部署多个实例进行伸缩。 你可以运行 kube-apiserver 的多个实例，并在这些实例之间平衡流量。 etcd etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。 您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。 要了解 etcd 更深层次的信息，请参考 etcd 文档。 kube-scheduler 控制平面组件，负责监视新创建的、未指定运行节点（node）的 Pods，选择节点让 Pod 在上面运行。 调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。 kube-controller-manager 在主节点上运行 控制器 的组件。 从逻辑上讲，每个控制器都是一个单独的进程， 但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。 这些控制器包括: 节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应 任务控制器（Job controller）: 监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成 端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod) 服务帐户和令牌控制器（Service Account \u0026 Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌 cloud-controller-manager 云控制器管理器是指嵌入特定云的控制逻辑的 控制平面组件。 云控制器管理器允许您链接集群到云提供商的应用编程接口中， 并把和该云平台交互的组件与只和您的集群交互的组件分离开。 cloud-controller-manager 仅运行特定于云平台的控制回路。 如果你在自己的环境中运行 Kubernetes，或者在本地计算机中运行学习环境， 所部署的环境中不需要云控制器管理器。 与 kube-controller-manager 类似，cloud-controller-manager 将若干逻辑上独立的 控制回路组合到同一个可执行文件中，供你以同一进程的方式运行。 你可以对其执行水平扩容（运行不止一个副本）以提升性能或者增强容错能力。 下面的控制器都包含对云平台驱动的依赖： 节点控制器（Node Controller）: 用于在节点终止响应后检查云提供商以确定节点是否已被删除 路由控制器（Route Controller）: 用于在底层云基础架构中设置路由 服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器 Node组件 节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。 kubelet 一个在集群中每个节点（node）上运行的代理。 它保证容器（containers）都 运行在 Pod 中。 kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。 kubelet 不会管理不是由 Kubernetes 创建的容器。 kube-proxy kube-proxy 是集群中每个节点上运行的网络代理， 实现 Kubernetes 服务（Service） 概念的一部分。 kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。 如果操作系统提供了数据包过滤层并可用的话，kube-proxy 会通过它来实现网络规则。否则， kube-proxy 仅转发流量本身。 ","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:2:2","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["k8s"],"content":"Kubeadm创建集群 ","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:3:0","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["k8s"],"content":"先为每台机器安装docker ","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:3:1","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["k8s"],"content":"安装kubeadm 一台兼容的 Linux 主机。Kubernetes 项目为基于 Debian 和 Red Hat 的 Linux 发行版以及一些不提供包管理器的发行版提供通用的指令 每台机器 2 GB 或更多的 RAM （如果少于这个数字将会影响你应用的运行内存) 2 CPU 核或更多 集群中的所有机器的网络彼此均能相互连接(公网和内网都可以) 设置防火墙放行规则 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见这里了解更多详细信息。 设置不同hostname 开启机器上的某些端口。请参见这里 了解更多详细信息。 内网互信 禁用交换分区。为了保证 kubelet 正常工作，你 必须 禁用交换分区。 永久关闭 基础环境 #各个机器设置自己的域名 hostnamectl set-hostname xxxx # 将 SELinux 设置为 permissive 模式（相当于将其禁用） sudo setenforce 0 sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config #关闭swap swapoff -a sed -ri 's/.*swap.*/#\u0026/' /etc/fstab #允许 iptables 检查桥接流量 cat \u003c\u003cEOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u003c\u003cEOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 安装kubelet、kubeadm、kubectl cat \u003c\u003cEOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg exclude=kubelet kubeadm kubectl EOF sudo yum install -y kubelet-1.20.9 kubeadm-1.20.9 kubectl-1.20.9 --disableexcludes=kubernetes sudo systemctl enable --now kubelet kubelet 现在每隔几秒就会重启，因为它陷入了一个等待 kubeadm 指令的死循环 ","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:3:2","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["k8s"],"content":"使用kubeadm引导集群 下载各个机器需要的镜像 sudo tee ./images.sh \u003c\u003c-'EOF' #!/bin/bash images=( kube-apiserver:v1.20.9 kube-proxy:v1.20.9 kube-controller-manager:v1.20.9 kube-scheduler:v1.20.9 coredns:1.7.0 etcd:3.4.13-0 pause:3.2 ) for imageName in ${images[@]} ; do docker pull registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/$imageName done EOF chmod +x ./images.sh \u0026\u0026 ./images.sh 初始化节点 #所有机器添加master域名映射，以下需要修改为自己的 echo \"自己的master的ip cluster-endpoint\" \u003e\u003e /etc/hosts #主节点初始化 kubeadm init \\ --apiserver-advertise-address=自己的master的ip \\ --control-plane-endpoint=上面设置好的域名的值，比如这里就是cluster-endpoint \\ --image-repository registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images \\ --kubernetes-version v1.20.9 \\ --service-cidr=10.96.0.0/16 \\ --pod-network-cidr=192.168.0.0/16 #所有网络范围不重叠（service和pod和主节点、工作节点） Your Kubernetes control-plane has initialized successfully! # 我们使用我们的集群，需要先做这一步 To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf # 部署网络插件，使K8s里面的机器串起来，打通 You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ # 使用这个命令可以使集群中的其他节点也变为主节点 You can now join any number of control-plane nodes by copying certificate authorities and service account keys on each node and then running the following as root: kubeadm join cluster-endpoint:6443 --token hums8f.vyx71prsg74ofce7 \\ --discovery-token-ca-cert-hash sha256:a394d059dd51d68bb007a532a037d0a477131480ae95f75840c461e85e2c6ae3 \\ --control-plane # 使用这个命令可以使集群中的其他节点变为工作节点 Then you can join any number of worker nodes by running the following on each as root: kubeadm join cluster-endpoint:6443 --token hums8f.vyx71prsg74ofce7 \\ --discovery-token-ca-cert-hash sha256:a394d059dd51d68bb007a532a037d0a477131480ae95f75840c461e85e2c6ae3 #查看集群所有节点 这个命令只能在主节点上运行 kubectl get nodes #根据配置文件，给集群创建资源 kubectl apply -f xxxx.yaml #查看集群部署了哪些应用？ docker ps === kubectl get pods -A # 运行中的应用在docker里面叫容器，在k8s里面叫Pod kubectl get pods -A 根据提示继续 master成功后提示如下： 1、设置.kube/config 复制上面命令 2、安装网络组件 calico官网 curl https://docs.projectcalico.org/manifests/calico.yaml -O kubectl apply -f calico.yaml 加入node节点（在相应的子机器里使用 ） kubeadm join cluster-endpoint:6443 --token x5g4uy.wpjjdbgra92s25pp \\ --discovery-token-ca-cert-hash sha256:6255797916eaee52bf9dda9429db616fcd828436708345a308f4b917d3457a22 上面的令牌只能维持24h，如果令牌过期了，在master下使用如下命令生成新的令牌。执行该命令后会得到一串命令，这串命令就是用来新加node节点的。 kubeadm token create –print-join-command 高可用部署方式，也是在这一步的时候，使用添加主节点的命令即可 验证集群 验证集群节点状态 kubectl get nodes 部署dashboard 部署 kubernetes官方提供的可视化界面 https://github.com/kubernetes/dashboard kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml # Copyright 2017 The Kubernetes Authors. # # Licensed under the Apache License, Version 2.0 (the \"License\"); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an \"AS IS\" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. apiVersion: v1 kind: Namespace metadata: name: kubernetes-dashboard --- apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard --- kind: Service apiVersion: v1 metadata: labels: k8s-app: kubernetes-dashboard name: kubernetes-dashboard namespace: kubernetes-dashboard spec: ports: - port: 443 targetPort: 8443 selector: k8s-app: kubernetes-dashboard --- apiVersion: v1 kind: Secret metada","date":"2023-05-29","objectID":"/posts/k8s/k8s01/:3:3","tags":["k8s"],"title":"K8s入门1","uri":"/posts/k8s/k8s01/"},{"categories":["docker"],"content":"Docker原生命令 ","date":"2023-05-29","objectID":"/posts/docker/docker09/:1:0","tags":["docker"],"title":"Docke--CIG容器监控","uri":"/posts/docker/docker09/"},{"categories":["docker"],"content":"CIG是什么 CAdvisor监控收集 + InfluxDB存储数组 + Grafana展示图表 ","date":"2023-05-29","objectID":"/posts/docker/docker09/:2:0","tags":["docker"],"title":"Docke--CIG容器监控","uri":"/posts/docker/docker09/"},{"categories":["docker"],"content":"CAdvisor CAdvisor是一个容器资源监控工具，包括容器的内存，CPU，网络IO，磁盘IO，等监控，同时提供了一个WEB页面用于查看容器的实时运行状态。CAdvisor默认存储2分钟的数据，而且只是针对单物理机。 不过，CAdvisor提供了很多数据集成接口，支持InfluxDB，Redis，Kafka，Elasticsearch等集成，可以加上对应配置将监控数据发往这些数据库存储起来。 CAdvisor功能主要有两点: 展示Host和容器两个层次的监控数据。 展示历史变化数据。 ","date":"2023-05-29","objectID":"/posts/docker/docker09/:2:1","tags":["docker"],"title":"Docke--CIG容器监控","uri":"/posts/docker/docker09/"},{"categories":["docker"],"content":"InluxDB InfluxDB是用Go语言编写的一个开源分布式时序事件和指标数据库，无需外部依赖。CAdvisor默认只在本机保存最近2分钟的数据，为了持久化存储数据和统一收集展示监控数据，需要将数据存储到InfluxDB中。InfluxDB是一个时序数据库，专用于存储时序相关数据，很适合存储CAdvisor的数据。而且，Advisor本身己经提供了InfluxDB的集成方法，等启动容器时指定配置即可。 InfluxDB主要功能： 基于时间序列，支持与时间有关的相关函数（如最大、最小、求和等）； 可度量性：你可以实时对大量数据进行计算； 基于事件：它支持任意的事件数据； ","date":"2023-05-29","objectID":"/posts/docker/docker09/:2:2","tags":["docker"],"title":"Docke--CIG容器监控","uri":"/posts/docker/docker09/"},{"categories":["docker"],"content":"Grafana Grafana是一个开源的数据监控分析可视化平台，支 持多种数据源配置(支持的数据源包括InfluxDB，MySQL， Elasticsearch，OpenTSDB，Graphite等)和丰富的插件及模板功能,支持图表权限控制和报警。 Grafana主要特性： 灵活丰富的图形化选项 可以混合多种风格 支持白天和夜间模式 多个数据源 ","date":"2023-05-29","objectID":"/posts/docker/docker09/:2:3","tags":["docker"],"title":"Docke--CIG容器监控","uri":"/posts/docker/docker09/"},{"categories":["docker"],"content":"利用compose容器编排，搭建CIG mkdir /mydocker/cig cd cig vim docker-compose.yml # 见下面 docker-compose config -q # 若无输出，代表yml文件没有问题 docker-compose up docker ps # 查看3个容器是否正常启动 version:'3.1' volumes: drafana_data:{} services: influxdb: image: tutum/influxdb:0.9 restart: always environment: -PRE_CREATE_DB=cadvisor ports: -\"8083:8083\" -\"8086:8086\" volumes: -./data/influxdb:/data cadvisor: image: google/cadvisor links: -influxdb: ingluxsrn command: -storage=influxdb -storge_driverdb=cadvisor -storage_driver_host=influxsrv:8086 restart: always ports: -\"8080:8080\" volumes: -/:/rootfs:ro gradana: user: \"104\" image: grafana/grafana user: \"104\" restart: always links: -influxdb: influxsrv ports: -\"3000:3000\" volumes: -grafana_data: /var/lib/grafana environment: -HTTP_USER=admin -HTTP_PASS=admin -INFLUXDB_HOST=influxsrv\\ -INFLUXDB_PORT=8086 -INFLUXDB_NAME=cadvisor -INFLUXDB_USER=root -INFLUXDB_PASS=root 浏览cAdvisor收集服务，http://ip:8080/ 浏览influxdb存储服务，http://ip:8083/ 浏览grafana展现服务，http://ip:3000/ grafana，默认账户和密码都是admin。 grafana配置步骤： 配置数据源 选择influxdb数据源 配置细节 配置面板panel ","date":"2023-05-29","objectID":"/posts/docker/docker09/:3:0","tags":["docker"],"title":"Docke--CIG容器监控","uri":"/posts/docker/docker09/"},{"categories":["gin"],"content":"后面的代码太长了，还没有看…… gin框架使用的是定制版本的httprouter，其路由的原理是大量使用公共前缀的树结构，它基本上是一个紧凑的Trie tree（或者只是Radix Tree）。具有公共前缀的节点也共享一个公共父节点。 ","date":"2023-05-28","objectID":"/posts/gin/gin02/:0:0","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"Radix Tree 基数树（Radix Tree）又称为PAT位树（Patricia Trie or crit bit tree），是一种更节省空间的前缀树（Trie Tree）。对于基数树的每个节点，如果该节点是唯一的子树的话，就和父节点合并。下图为一个基数树示例： Radix Tree可以被认为是一棵简洁版的前缀树。我们注册路由的过程就是构造前缀树的过程，具有公共前缀的节点也共享一个公共父节点。假设我们现在注册有以下路由信息： r := gin.Default() r.GET(\"/\", func1) r.GET(\"/search/\", func2) r.GET(\"/support/\", func3) r.GET(\"/blog/\", func4) r.GET(\"/blog/:post/\", func5) r.GET(\"/about-us/\", func6) r.GET(\"/about-us/team/\", func7) r.GET(\"/contact/\", func8) 那么我们会得到一个GET方法对应的路由树，具体结构如下： Priority Path Handle 9 \\ *\u003c1\u003e 3 ├s nil 2 |├earch\\ *\u003c2\u003e 1 |└upport\\ *\u003c3\u003e 2 ├blog\\ *\u003c4\u003e 1 | └:post nil 1 | └\\ *\u003c5\u003e 2 ├about-us\\ *\u003c6\u003e 1 | └team\\ *\u003c7\u003e 1 └contact\\ *\u003c8\u003e 上面最右边那一列每个*\u003c数字\u003e表示Handle处理函数的内存地址(一个指针)。从根节点遍历到叶子节点我们就能得到完整的路由表。 例如：blog/:post其中:post只是实际文章名称的占位符(参数)。与hash-maps不同，这种树结构还允许我们使用像:post参数这种动态部分，因为我们实际上是根据路由模式进行匹配，而不仅仅是比较哈希值。 由于URL路径具有层次结构，并且只使用有限的一组字符(字节值)，所以很可能有许多常见的前缀。这使我们可以很容易地将路由简化为更小的问题。此外，路由器为每种请求方法管理一棵单独的树。一方面，它比在每个节点中都保存一个method-\u003e handle map更加节省空间，它还使我们甚至可以在开始在前缀树中查找之前大大减少路由问题。 为了获得更好的可伸缩性，每个树级别上的子节点都按Priority(优先级)排序，其中优先级（最左列）就是在子节点(子节点、子子节点等等)中注册的句柄的数量。这样做有两个好处: 首先优先匹配被大多数路由路径包含的节点。这样可以让尽可能多的路由快速被定位。 类似于成本补偿。最长的路径可以被优先匹配，补偿体现在最长的路径需要花费更长的时间来定位，如果最长路径的节点能被优先匹配（即每次拿子节点都命中），那么路由匹配所花的时间不一定比短路径的路由长。下面展示了节点（每个-可以看做一个节点）匹配的路径：从左到右，从上到下。 总结一下就是说，这样可以平均长短路由的查找时间。因为如果我们先从短路由查起，短路由很快能匹配上，而长路由的时间需要很长很长很长。 ├------------ ├--------- ├----- ├---- ├-- ├-- └- ","date":"2023-05-28","objectID":"/posts/gin/gin02/:1:0","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"r.Run() func (engine *Engine) Run(addr ...string) (err error) { defer func() { debugPrintError(err) }() if engine.isUnsafeTrustedProxies() { debugPrint(\"[WARNING] You trusted all proxies, this is NOT safe. We recommend you to set a value.\\n\" + \"Please check https://pkg.go.dev/github.com/gin-gonic/gin#readme-don-t-trust-all-proxies for details.\") } address := resolveAddress(addr) debugPrint(\"Listening and serving HTTP on %s\\n\", address) err = http.ListenAndServe(address, engine.Handler()) return } 查看ListenAndServe源码，ListenAndServe有两个参数addr string, handler Handler，其中第二个参数Handler是一个接口类型，实现的是ServeHTTP方法。所以说r就是一个实现了ServeHTTP方法的engine *Engine。 接下来我们去寻找，Engine中实现的ServerHTTP方法。查看Engine的源码结构。 ** 为我们阅读源代码总结的内容，学到的东西。 // ServeHTTP conforms to the http.Handler interface. func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { // **通过使用对象池减少每次临时创建对象的内存申请和垃圾回收的消耗 c := engine.pool.Get().(*Context) // **在从池子里取出对象之后，对其初始化 c.writermem.reset(w) c.Request = req c.reset() // 处理HTTP请求 engine.handleHTTPRequest(c) // 放回池子 engine.pool.Put(c) } //**相较于 for i := 0; i \u003c len(t); i++ 源码的方式更好，因为我们只求一遍len(t) for i, tl := 0, len(t); i \u003c tl; i++ { if t[i].method != httpMethod { //** 写代码的时候，把不可能实现的情况，如continue或者return写到前面，这样不就直接退出或者走下一步的流程了。 continue } ... } t := engine.trees 下图中也是一个常见的写法，先写一个结构体，再写一个 _ 接口类型 = 空结构体的指针，目的是确保结构体实现了我们写的这个接口。是想把问题暴露给编译器，便于我们解决bug，如果我们的结构体忘记实现了该接口，那么173行的这段代码就会编译报错，我们就能发现问题了。 可以看到该tree就是请求方法的树结构，我们之前讲过，每一个请求对应着一颗树。 methodTrees methodTree 可以发现Gin框架并没有使用hash，使用map去存请求，因为使用map会更占用内存，Gin选择的是树结构，一个请求方法对应一颗树。 get函数是根据请求方法遍历所有的请求树，返回给要的那颗。 r := gin.Default() *Engine 我们也可以看到Engine在初始化的时候，建的trees就是一个切片，切片的容量是9，是因为在http1.1中有9种请求方法，最多就有9颗树。我们也可以学到，像这种初始化，如果我们提前知道切片的最大容量是多少，最好在初始化的时候给出容量，将内存一次性申请到位，防止后面的动态申请、扩容内存，当然要具体根据我们的项目来定。 ","date":"2023-05-28","objectID":"/posts/gin/gin02/:2:0","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"查看go源码的一个小技巧 点击结构体左侧的向上的箭头，可以查看该结构体实现了那些接口 我们点进Handler接口进一步查看。点击下面的箭头还可以查看，实现了该接口的所有类型，以及具体的实现方法。 总结一下，通过上面的方法，我们可以快速找到一个结构体实现的接口，并且找到该结构体实现该接口的具体方法。 接下来我们继续看node，见下一章。 ","date":"2023-05-28","objectID":"/posts/gin/gin02/:3:0","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"路由树节点 路由树是由一个个节点构成的，gin框架路由树的节点由node结构体表示，它有以下字段： // tree.go type node struct { // 节点路径，比如上面的s，earch，和upport path string // 和children字段对应, 保存的是分裂的分支的第一个字符 // 例如search和support, 那么s节点的indices对应的\"eu\" // 代表有两个分支, 分支的首字母分别是e和u indices string // 儿子节点 children []*node // 处理函数链条（切片） handlers HandlersChain // 优先级，子节点、子子节点等注册的handler数量 priority uint32 // 节点类型，包括static, root, param, catchAll // static: 静态节点（默认），比如上面的s，earch等节点 // root: 树的根节点 // catchAll: 有*匹配的节点 // param: 参数节点 nType nodeType // 路径上最大参数个数 maxParams uint8 // 节点是否是参数节点，比如上面的:post wildChild bool // 完整路径 fullPath string } ","date":"2023-05-28","objectID":"/posts/gin/gin02/:4:0","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"请求方法树 这里前面阅读源代码的部分有的有讲过。 在gin的路由中，每一个HTTP Method(GET、POST、PUT、DELETE…)都对应了一棵 radix tree，我们注册路由的时候会调用下面的addRoute函数： // gin.go func (engine *Engine) addRoute(method, path string, handlers HandlersChain) { // liwenzhou.com... // 获取请求方法对应的树 root := engine.trees.get(method) if root == nil { // 如果没有就创建一个 root = new(node) root.fullPath = \"/\" engine.trees = append(engine.trees, methodTree{method: method, root: root}) } // 这里后面有讲 root.addRoute(path, handlers) } 从上面的代码中我们可以看到在注册路由的时候都是先根据请求方法获取对应的树，也就是gin框架会为每一个请求方法创建一棵对应的树。只不过需要注意到一个细节是gin框架中保存请求方法对应树关系并不是使用的map而是使用的切片，engine.trees的类型是methodTrees，其定义如下： type methodTree struct { method string root *node } type methodTrees []methodTree // slice 而获取请求方法对应树的get方法定义如下： func (trees methodTrees) get(method string) *node { for _, tree := range trees { if tree.method == method { return tree.root } } return nil } 为什么使用切片而不是map来存储请求方法-\u003e树的结构呢？我猜是出于节省内存的考虑吧，毕竟HTTP请求方法的数量是固定的，而且常用的就那几种，所以即使使用切片存储查询起来效率也足够了。顺着这个思路，我们可以看一下gin框架中engine的初始化方法中，确实对tress字段做了一次内存申请： func New() *Engine { debugPrintWARNINGNew() engine := \u0026Engine{ RouterGroup: RouterGroup{ Handlers: nil, basePath: \"/\", root: true, }, // liwenzhou.com ... // 初始化容量为9的切片（HTTP1.1请求方法共9种） trees: make(methodTrees, 0, 9), // liwenzhou.com... } engine.RouterGroup.engine = engine engine.pool.New = func() interface{} { return engine.allocateContext() } return engine } ","date":"2023-05-28","objectID":"/posts/gin/gin02/:5:0","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"注册路由 注册路由的逻辑主要有addRoute函数和insertChild方法。 ","date":"2023-05-28","objectID":"/posts/gin/gin02/:6:0","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"查看源码 r.GET() 插一嘴，这里为什么r作为Engine类型能调用GET方法，是因为下图，Engine中嵌套了RouterGroup。 接下来group.handle group.combineHandlers一个拼接的操作，看一下怎么实现的。 group.engine.addRoute是重点。 ","date":"2023-05-28","objectID":"/posts/gin/gin02/:6:1","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"addRoute // tree.go // addRoute 将具有给定句柄的节点添加到路径中。 // 不是并发安全的 func (n *node) addRoute(path string, handlers HandlersChain) { fullPath := path n.priority++ numParams := countParams(path) // 数一下参数个数 // 空树就直接插入当前节点 if len(n.path) == 0 \u0026\u0026 len(n.children) == 0 { n.insertChild(numParams, path, fullPath, handlers) n.nType = root return } parentFullPathIndex := 0 walk: for { // 更新当前节点的最大参数个数 if numParams \u003e n.maxParams { n.maxParams = numParams } // 找到最长的通用前缀 // 这也意味着公共前缀不包含“:”\"或“*” / // 因为现有键不能包含这些字符。 i := longestCommonPrefix(path, n.path) // 分裂边缘（此处分裂的是当前树节点） // 例如一开始path是search，新加入support，s是他们通用的最长前缀部分 // 那么会将s拿出来作为parent节点，增加earch和upport作为child节点 if i \u003c len(n.path) { child := node{ path: n.path[i:], // 公共前缀后的部分作为子节点 wildChild: n.wildChild, indices: n.indices, children: n.children, handlers: n.handlers, priority: n.priority - 1, //子节点优先级-1 fullPath: n.fullPath, } // Update maxParams (max of all children) for _, v := range child.children { if v.maxParams \u003e child.maxParams { child.maxParams = v.maxParams } } n.children = []*node{\u0026child} // []byte for proper unicode char conversion, see #65 n.indices = string([]byte{n.path[i]}) n.path = path[:i] n.handlers = nil n.wildChild = false n.fullPath = fullPath[:parentFullPathIndex+i] } // 将新来的节点插入新的parent节点作为子节点 if i \u003c len(path) { path = path[i:] if n.wildChild { // 如果是参数节点 parentFullPathIndex += len(n.path) n = n.children[0] n.priority++ // Update maxParams of the child node if numParams \u003e n.maxParams { n.maxParams = numParams } numParams-- // 检查通配符是否匹配 if len(path) \u003e= len(n.path) \u0026\u0026 n.path == path[:len(n.path)] { // 检查更长的通配符, 例如 :name and :names if len(n.path) \u003e= len(path) || path[len(n.path)] == '/' { continue walk } } pathSeg := path if n.nType != catchAll { pathSeg = strings.SplitN(path, \"/\", 2)[0] } prefix := fullPath[:strings.Index(fullPath, pathSeg)] + n.path panic(\"'\" + pathSeg + \"' in new path '\" + fullPath + \"' conflicts with existing wildcard '\" + n.path + \"' in existing prefix '\" + prefix + \"'\") } // 取path首字母，用来与indices做比较 c := path[0] // 处理参数后加斜线情况 if n.nType == param \u0026\u0026 c == '/' \u0026\u0026 len(n.children) == 1 { parentFullPathIndex += len(n.path) n = n.children[0] n.priority++ continue walk } // 检查路path下一个字节的子节点是否存在 // 比如s的子节点现在是earch和upport，indices为eu // 如果新加一个路由为super，那么就是和upport有匹配的部分u，将继续分列现在的upport节点 for i, max := 0, len(n.indices); i \u003c max; i++ { if c == n.indices[i] { parentFullPathIndex += len(n.path) i = n.incrementChildPrio(i) n = n.children[i] continue walk } } // 否则就插入 if c != ':' \u0026\u0026 c != '*' { // []byte for proper unicode char conversion, see #65 // 注意这里是直接拼接第一个字符到n.indices n.indices += string([]byte{c}) child := \u0026node{ maxParams: numParams, fullPath: fullPath, } // 追加子节点 n.children = append(n.children, child) n.incrementChildPrio(len(n.indices) - 1) n = child } n.insertChild(numParams, path, fullPath, handlers) return } // 已经注册过的节点 if n.handlers != nil { panic(\"handlers are already registered for path '\" + fullPath + \"'\") } n.handlers = handlers return } } 其实上面的代码很好理解，大家可以参照动画尝试将以下情形代入上面的代码逻辑，体味整个路由树构造的详细过程： 第一次注册路由，例如注册search 继续注册一条没有公共前缀的路由，例如blog 注册一条与先前注册的路由有公共前缀的路由，例如support insertChild // tree.go func (n *node) insertChild(numParams uint8, path string, fullPath string, handlers HandlersChain) { // 找到所有的参数 for numParams \u003e 0 { // 查找前缀直到第一个通配符 wildcard, i, valid := findWildcard(path) if i \u003c 0 { // 没有发现通配符 break } // 通配符的名称必须包含':' 和 '*' if !valid { panic(\"only one wildcard per path segment is allowed, has: '\" + wildcard + \"' in path '\" + fullPath + \"'\") } // 检查通配符是否有名称 if len(wildcard) \u003c 2 { panic(\"wildcards must be named with a non-empty name in path '\" + fullPath + \"'\") } // 检查这个节点是否有已经存在的子节点 // 如果我们在这里插入通配符，这些子节点将无法访问 if len(n.children) \u003e 0 { panic(\"wildcard segment '\" + wildcard + \"' conflicts with existing children in path '\" + fullPath + \"'\") } if wildcard[0] == ':' { // param if i \u003e 0 { // 在当前通配符之前插入前缀 n.path = path[:i] path = path[i:] } n.wildChild = true child := \u0026node{ nType: param, path: wildcard, maxParams: numParams, fullPath: fullPath, } n.children = []*nod","date":"2023-05-28","objectID":"/posts/gin/gin02/:6:2","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["gin"],"content":"路由匹配 我们先来看gin框架处理请求的入口函数ServeHTTP： // gin.go func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { // 这里使用了对象池 c := engine.pool.Get().(*Context) // 这里有一个细节就是Get对象后做初始化 c.writermem.reset(w) c.Request = req c.reset() engine.handleHTTPRequest(c) // 我们要找的处理HTTP请求的函数 engine.pool.Put(c) // 处理完请求后将对象放回池子 } 函数很长，这里省略了部分代码，只保留相关逻辑代码： // gin.go func (engine *Engine) handleHTTPRequest(c *Context) { // liwenzhou.com... // 根据请求方法找到对应的路由树 t := engine.trees for i, tl := 0, len(t); i \u003c tl; i++ { if t[i].method != httpMethod { continue } root := t[i].root // 在路由树中根据path查找 value := root.getValue(rPath, c.Params, unescape) if value.handlers != nil { c.handlers = value.handlers c.Params = value.params c.fullPath = value.fullPath c.Next() // 执行函数链条 c.writermem.WriteHeaderNow() return } // liwenzhou.com... c.handlers = engine.allNoRoute serveError(c, http.StatusNotFound, default404Body) } 路由匹配是由节点的 getValue方法实现的。getValue根据给定的路径(键)返回nodeValue值，保存注册的处理函数和匹配到的路径参数数据。 如果找不到任何处理函数，则会尝试TSR(尾随斜杠重定向)。 代码虽然很长，但还算比较工整。大家可以借助注释看一下路由查找及参数匹配的逻辑。 / tree.go type nodeValue struct { handlers HandlersChain params Params // []Param tsr bool fullPath string } // liwenzhou.com... func (n *node) getValue(path string, po Params, unescape bool) (value nodeValue) { value.params = po walk: // Outer loop for walking the tree for { prefix := n.path if path == prefix { // 我们应该已经到达包含处理函数的节点。 // 检查该节点是否注册有处理函数 if value.handlers = n.handlers; value.handlers != nil { value.fullPath = n.fullPath return } if path == \"/\" \u0026\u0026 n.wildChild \u0026\u0026 n.nType != root { value.tsr = true return } // 没有找到处理函数 检查这个路径末尾+/ 是否存在注册函数 indices := n.indices for i, max := 0, len(indices); i \u003c max; i++ { if indices[i] == '/' { n = n.children[i] value.tsr = (len(n.path) == 1 \u0026\u0026 n.handlers != nil) || (n.nType == catchAll \u0026\u0026 n.children[0].handlers != nil) return } } return } if len(path) \u003e len(prefix) \u0026\u0026 path[:len(prefix)] == prefix { path = path[len(prefix):] // 如果该节点没有通配符(param或catchAll)子节点 // 我们可以继续查找下一个子节点 if !n.wildChild { c := path[0] indices := n.indices for i, max := 0, len(indices); i \u003c max; i++ { if c == indices[i] { n = n.children[i] // 遍历树 continue walk } } // 没找到 // 如果存在一个相同的URL但没有末尾/的叶子节点 // 我们可以建议重定向到那里 value.tsr = path == \"/\" \u0026\u0026 n.handlers != nil return } // 根据节点类型处理通配符子节点 n = n.children[0] switch n.nType { case param: // find param end (either '/' or path end) end := 0 for end \u003c len(path) \u0026\u0026 path[end] != '/' { end++ } // 保存通配符的值 if cap(value.params) \u003c int(n.maxParams) { value.params = make(Params, 0, n.maxParams) } i := len(value.params) value.params = value.params[:i+1] // 在预先分配的容量内扩展slice value.params[i].Key = n.path[1:] val := path[:end] if unescape { var err error if value.params[i].Value, err = url.QueryUnescape(val); err != nil { value.params[i].Value = val // fallback, in case of error } } else { value.params[i].Value = val } // 继续向下查询 if end \u003c len(path) { if len(n.children) \u003e 0 { path = path[end:] n = n.children[0] continue walk } // ... but we can't value.tsr = len(path) == end+1 return } if value.handlers = n.handlers; value.handlers != nil { value.fullPath = n.fullPath return } if len(n.children) == 1 { // 没有找到处理函数. 检查此路径末尾加/的路由是否存在注册函数 // 用于 TSR 推荐 n = n.children[0] value.tsr = n.path == \"/\" \u0026\u0026 n.handlers != nil } return case catchAll: // 保存通配符的值 if cap(value.params) \u003c int(n.maxParams) { value.params = make(Params, 0, n.maxParams) } i := len(value.params) value.params = value.params[:i+1] // 在预先分配的容量内扩展slice value.params[i].Key = n.path[2:] if unescape { var err error if value.params[i].Value, err = url.QueryUnescape(path); err != nil { value.params[i].Value = path // fallback, in case of error } } else { value.params[i].Value = path } value.handlers = n.handlers value.fullPath = n.fullPath return default: panic(\"invalid node type\") } } // 找不到，如果存在一个在当前路径最后添加/的路由 // 我们会建议重定向到那里 value.tsr = (path == \"/\") || (len(prefix) == len(path)+1 \u0026\u0026 prefix[len(path)] == '/' \u0026\u0026 path == prefix[:len(prefix)-1] \u0026\u0026 n.handlers != nil) return } } ","date":"2023-05-28","objectID":"/posts/gin/gin02/:7:0","tags":["gin","go web"],"title":"Gin框架路由详解","uri":"/posts/gin/gin02/"},{"categories":["docker"],"content":"是什么 Portainer是一款轻量级的应用，它提供了图形化界面，用于方便地管理Docker环境，包括单机环境和集群环境。 ","date":"2023-05-28","objectID":"/posts/docker/docker08/:1:0","tags":["docker"],"title":"Docker轻量级可视化工具Portainer","uri":"/posts/docker/docker08/"},{"categories":["docker"],"content":"安装 官网 ，下载 stack指的是编排好的组。 第一次登录创建admin，访问地址：xxx.xxx.xxx.xxx:9000 设置admin用户和密码后首次登录 选择local选项卡后本地docker详细信息展示 docker svstem df ","date":"2023-05-28","objectID":"/posts/docker/docker08/:2:0","tags":["docker"],"title":"Docker轻量级可视化工具Portainer","uri":"/posts/docker/docker08/"},{"categories":["docker"],"content":"常用操作 很简单，自己玩。 ","date":"2023-05-28","objectID":"/posts/docker/docker08/:3:0","tags":["docker"],"title":"Docker轻量级可视化工具Portainer","uri":"/posts/docker/docker08/"},{"categories":["docker"],"content":"Compose是什么 Docker-Compose是Docker官方的开源项目，负责实现对Docker容器集群的快速编排。 Compose是Docker公司推出的一个工具软件，可以管理多个Docker容器组成一个应用。 你需要定义一个YAML格式的配置文件docker-compose.yml，写好多个容器之间的调用关系。然后，只要一个命令， 就能同时启动或关闭这些容器。通俗的解释就是，当我们的容器很多的时候，就不同一个个去run，一个个stop了，同时通过Compose也可以控制容器启动的先后顺序。 ","date":"2023-05-28","objectID":"/posts/docker/docker07/:1:0","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"Compose能干嘛 docker建议我们每一个容器中只运行一个服务，因为docker容器本身占用资源极少，所以最好是将每个服务单独的分割开来，但是这样我们又面临了一个 问题? 如果我需要同时部署好多个服务，难道要每个服务单独写Dockerfile然后在构建镜像，构建容器，这样累都累死了,所以docker官方给我们提供了docker-compose多服务部署的工具。 例如要实现一个Web微服务项目，除了Web服务容器本身，往往还需要再加上后端的数据库mysq|服务容器，redis服务器，注册中心eureka，甚至还包括负载均衡容器等等。 Compose允许用户通过一 个单独的docker-compose.yml模板文件(YAML格式)来定义一组相关联的应用容器为一个项目(project) 。可以很容易地用一个配置 文件定义一个多 容器的应用，然后使用一条指令安装这个应用的所有依赖，完成构建。Docker-Compose 解决了容器与容器之间如何管理编排的问题。 ","date":"2023-05-28","objectID":"/posts/docker/docker07/:2:0","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"去哪里下载 官网、[官网下载](https://docs.docker .com/compose/install/) 卸载：sudo rm /usr/local/bin/docker-compose ","date":"2023-05-28","objectID":"/posts/docker/docker07/:3:0","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"Compose核心概念 ","date":"2023-05-28","objectID":"/posts/docker/docker07/:4:0","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"一文件 docker-compose.yml ","date":"2023-05-28","objectID":"/posts/docker/docker07/:4:1","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"两要素 服务（service）与工程（project） 服务是指一个个应用容器实例，比如订单微服务、库存微服务、mysql容器、nginx容器或者redis容器。 由一组关联的应用容器组成的一个完整业务单元，在docker-compose.yml文件中定义。 即 工程 = 多个服务（容器应用实例） ","date":"2023-05-28","objectID":"/posts/docker/docker07/:4:2","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"Compose使用的三个步骤 编写Dockerfile定义各个微服务应用并构建出对应的镜像文件； 使用docker-compose.yml定义一个完整业务单元，安排好整体应用中的各个容器服务。 最后，执行docker-compose up 命令来启动并运行整个应用程序，完成一键部署上线。 ","date":"2023-05-28","objectID":"/posts/docker/docker07/:5:0","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"Compose常用命令 docker-compose -h # 查看帮助 docker-compose up # 启动所有docker-compose服务 docker-compose up -d # 启动所有docker-compose服务并后台运行 docker-compose down # 停止并删除容器、网络、卷、镜像 docker-compose exec yml里面的服务id # 进入容器实例内部 docker-compose exec docker-compose.yml文件中写的服务id /bin/bash docker-compose ps # 展示当前docker-compose编排过的运行的所有容器 docker-compose top # 展示当前docker-compose编排过的容器进程 docker-compose logs yml里面的服务id # 查看容器输出日志 docker-compose config # 检查配置 docker-compose config -q # 检查配置，有问题才有输出 docker-compose restart docker-compose start docker-compose stop ","date":"2023-05-28","objectID":"/posts/docker/docker07/:6:0","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"Compose编排微服务（这块没学，等学完微服务的）","date":"2023-05-28","objectID":"/posts/docker/docker07/:7:0","tags":["docker","微服务"],"title":"Docker-compose容器编排","uri":"/posts/docker/docker07/"},{"categories":["docker"],"content":"为什么会有docker的出现 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:1:0","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"Docker理念 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:2:0","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"容器与虚拟机比较 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:3:0","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"传统虚拟机技术 缺点： 资源占用多 冗余步骤多 启动慢 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:3:1","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"容器虚拟化技术 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:3:2","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"Docker能干嘛 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:4:0","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"Docker的基本组成 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:5:0","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"1.镜像(image) ","date":"2023-05-27","objectID":"/posts/docker/docker01/:5:1","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"2.容器(container) ","date":"2023-05-27","objectID":"/posts/docker/docker01/:5:2","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"3.仓库(repository) ","date":"2023-05-27","objectID":"/posts/docker/docker01/:5:3","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"4.小总结 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:5:4","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"Docker架构图解 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:6:0","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"Docker安装 不用这条命令去安装，因为访问外网的请求会超时，所以要设置镜像 底层原理，为什么docker比虚拟机快 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:7:0","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"Docker常用命令 ","date":"2023-05-27","objectID":"/posts/docker/docker01/:8:0","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"帮助启动类命令 systemctl start docker systemctl stop docker systemctl restart docker systemctl status docker systemctl enable docker docker info docker --help docker \u003c具体命令\u003e --help ","date":"2023-05-27","objectID":"/posts/docker/docker01/:8:1","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"镜像命令 docker images [-a] [-p] # -a 列出本地所有的镜像（含历史映像层） -p 只显示镜像ID docker search [--limit n] \u003c镜像名\u003e # 只列出n个，默认25个 docker pull \u003c镜像名字\u003e [:TAG] # 没有tag就是最新版 docker system df # 查看镜像/容器/数据卷/所占的空间 docker rmi -f \u003c镜像ID\u003e docker rmi -f \u003c镜像名1\u003e:TAG \u003c镜像名2\u003e:TAG docker rmi -f $(docker images -qa) ","date":"2023-05-27","objectID":"/posts/docker/docker01/:8:2","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"容器命令 docker run [OPTIONS] \u003c镜像名\u003e [COMMAND][ARG...] docker ps [-a][-l][-n][-q] # -a 正在+历史；-l 最近；-n 最近n个；-q只显示容器编号 exit # run进去容器，exit退出，容器停止 ctrl+p+q # run进去容器，ctrl+p+q退出，容器不停止 docker start \u003c容器ID\u003e或\u003c容器名\u003e docker restart \u003c容器ID\u003e或\u003c容器名\u003e docker stop \u003c容器ID\u003e或\u003c容器名\u003e docker kill \u003c容器ID\u003e或\u003c容器名\u003e docker rm \u003c容器ID\u003e docker rm -f $(docker ps -a -q) docker ps -a -q | xargs docker rm ","date":"2023-05-27","objectID":"/posts/docker/docker01/:8:3","tags":["docker"],"title":"Docker介绍","uri":"/posts/docker/docker01/"},{"categories":["docker"],"content":"Docker平台架构图解 整体说明 从其架构和运行流程来看，Docker是一个C/S模式的架构，后端是一个松耦合架构，众多模块各司其职。 Docker运行的基本流程为： 用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。 Docker Daemon作为Docker架构中的主体部分，首先提供Docker Server的功能使其可以接受Docker Client的请求。 Docker Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。 Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动Graph driver将下载镜像以Graph的形式存储。 当需要为Docker创建网络环境时，通过网络管理驱动Network driver创建并配置Docker容器网络环境。 当需要限制Docker容器运行资源或执行用户指令等操作时，则通过Execdriver 来完成。 Libcontainer是一项独立的容器管理包，Network driver以及Exec driver都是通过Libcontainer来实现具体对容器进行的操作。 整体架构 ","date":"2023-05-24","objectID":"/posts/docker/docker06/:1:0","tags":["docker"],"title":"Docker网络","uri":"/posts/docker/docker06/"},{"categories":["docker"],"content":"Docker网络是什么 docker不启动时，默认网络情况。 docker启动后，网络情况。 docker启动后，发现会产生一个名为docker0的虚拟网桥。 inet 172.17.0.1 ：通过docker0这个虚拟网桥和宿主机通信，同时保证容器与容器之间的通信。 docker network ls会发现，docker启动后会默认创建3大网络模式，我们常用的是bridge模式，偶尔会用到host模式。 ","date":"2023-05-24","objectID":"/posts/docker/docker06/:2:0","tags":["docker"],"title":"Docker网络","uri":"/posts/docker/docker06/"},{"categories":["docker"],"content":"Docker网络常用基本命令 docker network --help查看docker网络常用命令。 docker network connect # 连接 docker network create # 创建 docker network disconnect # 中断 docker network inspect # 查看 docker network ls # list docker network prune # 删除所有无效网络 docker network rm # remove ","date":"2023-05-24","objectID":"/posts/docker/docker06/:3:0","tags":["docker"],"title":"Docker网络","uri":"/posts/docker/docker06/"},{"categories":["docker"],"content":"Docker网络能干嘛 所有网络的访问前提是网络需要处于同一网段。我们现在使用单机版的docker实例，感受的不明显，但是如果我们在工作中，是要做docker的网路管理和容器调用之间的规划的。 Docker网络与容器间的互联和通信以及端口映射有关。 同时，容器IP变动时可以通过服务名直接网络通信而不受到影响。 ","date":"2023-05-24","objectID":"/posts/docker/docker06/:4:0","tags":["docker"],"title":"Docker网络","uri":"/posts/docker/docker06/"},{"categories":["docker"],"content":"Docker网络模式 ","date":"2023-05-24","objectID":"/posts/docker/docker06/:5:0","tags":["docker"],"title":"Docker网络","uri":"/posts/docker/docker06/"},{"categories":["docker"],"content":"总体介绍 网络模式 简介 指令 bridge 为每一个容器分配、设置IP等，并将容器连接到一个docker0虚拟网桥，默认为该模式。 --network bridge，默认使用docker0 host 容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。 --network host none 容器有独立的Network namespace，但并没有对其进行任何网络设置，如分配veth pair和网桥连接、IP等。 --network none container 新创建的容器不会创建自己的网卡和配置自己的IP，而是和一个指定的容器共享IP，端口范围等。 --network container:NAME或者容器ID指定 ","date":"2023-05-24","objectID":"/posts/docker/docker06/:5:1","tags":["docker"],"title":"Docker网络","uri":"/posts/docker/docker06/"},{"categories":["docker"],"content":"容器实例内默认网络IP生成规则 说明 结论 docker容器内部的ip是有可能会发生改变的。比如上面的情况中，原来172.17.0.3是属于u2的，后来u2挂了，该ip归新启动的u3所有了，如果我们其他的服务是按照ip互相连接的，就会出现错误。 ","date":"2023-05-24","objectID":"/posts/docker/docker06/:5:2","tags":["docker"],"title":"Docker网络","uri":"/posts/docker/docker06/"},{"categories":["docker"],"content":"案例说明 bridge 是什么 Docker服务默认会创建一个docker0网桥（其上有一个docker0内部接口），该桥接网络的名称为docker0，它在内核层联通了其他的物理或虚拟网卡，这就将所有容器和本地主机都放到同一个物理网络。Docker默认指定了docker0接口的IP地址和子网掩码，让主机和容器之间可以通过网桥相互通信。 查看bridge网络的详细信息，并通过grep获取名称项。 docker network inspect bridge | grep name ifconfig | grep docker 案例 说明 Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥（docker0），Docker启动一个容器时会根据Docker网桥的桥段分配给容器一个IP地址，成为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能通过容器的Container-IP直接通信。 docker run的时候，没有指定network的话默认使用的网络模式是bridge，使用的就是docker0。在宿主机ifconfig，就可以看到docker0和自己create的network，eth0，eth1，eth2……，lo代表127.0.0.1，即localhost，inet addr用来表示网卡的IP地址。 网桥docker0创建一对 对等的虚拟设备接口一个叫veth，另一个叫eth0，成对匹配。 整个宿主机的网桥模式都是docker0，类似一个交换机有一堆接口，每个接口叫veth，在本地主机和容器内分别创建一个虚拟接口，并让他们彼此联通（这样一对接口叫veth pair） 每个容器实例内部也有一块网卡，每个接口叫eth0。 docker0上面的每个veth匹配某个容器实例内部的eth0，两两配对，一一匹配。 通过上述，将宿主机上的所有容器都连接到这个网络内部上，两个容器在同一个网络下，会从这个网关下各自拿到分配的ip，此时两个容器的网络是互通的。 代码 docker run -d -p 8081:8080 --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --name tomcat81 billygoo/tomcat8-jdk8 两两匹配验证 host 是什么 直接使用宿主机的ip地址与外界进行通信，不再需要额外进行NAT转换。 案例 容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡而是使用宿主机的IP和端口。 docker run -d -p 8083:8080 --network host --name tomcat83 billygoo/tomcat8-jdk8 WARNING：Published ports are discarded when using host network mode 这样启动会遇到警告，原因是docker启动时指定--network=host或-net=host，如果还指定了-p映射端口，那这个时候就会有此警告，并且通过-p设置的参数将不会起到任何作用，端口号会以主机端口号为主，重复时则递增。解决方法就是使用docker的其他网络模式，例如bridge或者直接无视。 正确的写法应该是docker run -d --network host --name tomcat83 billygoo/tomcat8-jdk8 none 禁用网络功能，只有lo（localhost）。在none模式下，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息，只有一个lo，需要我们自己为Docker容器添加网卡、配置IP等。 docker run -d -p 8084:8080 --network none --name tomcat84 billigoo/tomcat8-jdk8 container 新建的容器和已经存在的一个容器共享一个网络ip配置而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。 错误案例 docker run -d -p 8085:8080 --name tomcat85 billygoo/tomcat8-jdk8 docker run -d -p 8086:8080 --network container:tomcat85 --name tomcat85 billygoo/tomcat8-jdk8 正确案例 自定义网络 使用自定义网络之前 案例： docker run -d -p 8081:8080 --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --name tomcat82 billygoo/tomcat8-jdk8 上述成功启动并用docker exec进入各自容器实例内部 使用自定义网络之后 案例： 自定义桥接网络，自定义网络默认使用的是桥接网络bridge。 新建自定义网络。 docker network create nzR_network 新建容器加入上一步新建的自定义网络。 docker run -d -p 8081:8080 --network nzR_neetwork --name tomcat81 billygoo/tomcat8-jdk8 docker run -d -p 8082:8080 --network nzR_neetwork --name tomcat81 billygoo/tomcat8-jdk8 互相ping测试 此时在tomcat81下ping tomcat82或在tomcat82下ping tomcat81均可成功。 ","date":"2023-05-24","objectID":"/posts/docker/docker06/:5:3","tags":["docker"],"title":"Docker网络","uri":"/posts/docker/docker06/"},{"categories":["WSL"],"content":"WSL启动Ubuntu时报错“参考的对象类型不支持尝试的操作” 用root权限打开powershell，输入netsh winsock reset ","date":"2023-05-23","objectID":"/posts/wsl/:1:0","tags":["WSL"],"title":"WSL","uri":"/posts/wsl/"},{"categories":["docker"],"content":"没学过spring boot、spring cloud。以后用go写个微服务再更新。 ","date":"2023-05-23","objectID":"/posts/docker/docker05/:0:0","tags":["docker","微服务"],"title":"Docker微服务实战","uri":"/posts/docker/docker05/"},{"categories":["docker"],"content":"通过IDEA新建一个普通微服务模块 ","date":"2023-05-23","objectID":"/posts/docker/docker05/:1:0","tags":["docker","微服务"],"title":"Docker微服务实战","uri":"/posts/docker/docker05/"},{"categories":["docker"],"content":"通过dockerfile发布微服务部署到docker容器","date":"2023-05-23","objectID":"/posts/docker/docker05/:2:0","tags":["docker","微服务"],"title":"Docker微服务实战","uri":"/posts/docker/docker05/"},{"categories":["Git"],"content":"Git基础指令 ","date":"2023-05-22","objectID":"/posts/git/git/:1:0","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"安装git git -v # 查看版本 git config --global user.name \"Lizhe1228\" # 基本配置 git config --global user.email \"2181426542@qq.com\" ","date":"2023-05-22","objectID":"/posts/git/git/:1:1","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"创建版本库 版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以还原。注意，目前这里说的版本库都是本地仓库。 # 初始化本地仓库 git init # 添加文件到仓库 # 添加单个文件 git add \u003cfile\u003e # 添加多个文件 git add file1 file2 ... # 添加全部已修改文件 git add . # 提交文件到仓库 git commit -m \"说明\" ","date":"2023-05-22","objectID":"/posts/git/git/:1:2","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"版本回退 # git工作区状态 git status # 查看全部修改内容 git diff # 查看指定文件修改内容 git diff \u003cfile\u003e # 回退到指定版本 git reset --hard commit_id # 这里的commit_id 通过git log查看 # 回退到上一个版本 git reset --hard HEAD^ # 回退到上上一个版本 git reset --hard HEAD^^ # 回退到上n个版本 git reset --hard HEAD~n # 看详细提交历史 git log # 查看简化提交历史 git log --pretty=oneline # 查看分支合并图 git log --graph # 查看命令历史 git reflog ","date":"2023-05-22","objectID":"/posts/git/git/:1:3","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"工作区和暂存区 结论 工作区Working Directory 就是你在电脑里能看到的目录，在创建版本库时新建的那个目录 版本库Repository 工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。 Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区 说明 前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。 你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 ","date":"2023-05-22","objectID":"/posts/git/git/:1:4","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"管理修改 结论 Git跟踪并管理的是修改，而非文件 Git只能追踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。 图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。 说明 需要注意的是，如果你按照下述方式提交： 第一次修改-\u003eadd-\u003e第二次修改-\u003ecommit 那么，第二次修改的内容不会被提交 按照下述方式提交，则两次修改都会被提交 第一次修改-\u003eadd-\u003e第二次修改-\u003eadd-\u003ecommit 所以，没有add的内容，即使commit之后也不会被提交 ","date":"2023-05-22","objectID":"/posts/git/git/:1:5","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"撤销修改 丢弃工作区的修改（未提交至暂存区，也就是未add） # 丢弃指定文件的修改 git checkout -- file git restore \u003cfile\u003e # 丢弃所有文件的修改 git checkout -- . git restore . 丢弃已添加到暂存区的修改 # 丢弃指定文件的修改 git reset HEAD \u003cfile\u003e git restore --staged \u003cfile\u003e # 丢弃所有文件的修改 git reset HEAD . git restore --staged . ","date":"2023-05-22","objectID":"/posts/git/git/:1:6","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"删除文件？？？ # 删除未添加到暂存区的文件 # 显示将要删除的文件和目录 git clean -n # 删除文件和目录 git clean -df # 删除文件 git clean -f git rm \u003cfile\u003e ","date":"2023-05-22","objectID":"/posts/git/git/:1:7","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"远程仓库 ","date":"2023-05-22","objectID":"/posts/git/git/:2:0","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"添加远程仓库 # 关联远程仓库 # 其中origin是默认的远程仓库名，也可以自行修改 # url可以是ssh链接，也可以是http链接，推荐使用ssh，安全高速 git remote add origin \u003curl\u003e # 删除远程仓库 git remote rm origin # 查看远程仓库 git remote -v # 推送提交到远程仓库 一般用于非首次推送 git push origin master git push -f origin master # -f是强制推送 好用慎用 # -u参数是将本地master分支与远程仓库master分支关联起来，一般用于第一次推送代码到远程库 git push -u origin master ","date":"2023-05-22","objectID":"/posts/git/git/:2:1","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"从远程仓库克隆 之前讲的内容都是先有本地库，后有远程库，然后再关联远程库。 而一般大多数情形都是先有远程库，然后克隆远程库到本地，再进行工作。 # url可以是ssh或http，建议使用原生ssh链接，高速安全 git clone url ","date":"2023-05-22","objectID":"/posts/git/git/:2:2","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"分支管理 ","date":"2023-05-22","objectID":"/posts/git/git/:3:0","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"创建与合并分支 # 查看分支 git branch # 创建分支 git branch \u003cname\u003e # 切换分支 switch是2.23版本新增命令 git checkout \u003cname\u003e git switch \u003cname\u003e # 创建并切换到该分支 git checkout -b \u003cname\u003e git switch -c \u003cname\u003e # 合并指定分支到当前分支 git merge \u003cname\u003e # 删除本地已合并分支 ??? git branch -d \u003cname\u003e # 删除远程分支 git push \u003c远程仓库名\u003e --delete \u003c远程分支名\u003e # 推送本地分支到远程仓库并在远程仓库创建新分支 git push \u003c远程仓库名\u003e \u003c本地分支名\u003e:\u003c远程分支名\u003e ","date":"2023-05-22","objectID":"/posts/git/git/:3:1","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"解决冲突 当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。 解决冲突就是把Git合并失败的文件手动编辑为我们希望的内容，再提交。 查看分支合并图： git log --graph 冲突的产生一般都是这两种情况： 远程仓库的代码落后于本地仓库 远程仓库的代码远超本地仓库 在你还未提交代码的时候，你的同事已经提交了代码，就会导致远程仓库代码领先于你的代码 冲突是如何表示的 当产生合并冲突时，该部分会以\u003c\u003c\u003c\u003c\u003c\u003c\u003c, =======和 \u003e\u003e\u003e\u003e\u003e\u003e\u003e表示。在=======之前的部分是当前分支这边的情况，在=======之后的部分是传入分支的情况。 如何解决冲突 ？？？ 在看到冲突以后，你可以选择以下两种方式： 决定不合并。这时，唯一要做的就是重置index到HEAD节点。git merge --abort用于这种情况。 解决冲突。Git会标记冲突的地方，解决完冲突的地方后使用git add加入到index中，然后使用git commit产生合并节点。 你可以用以下工具来解决冲突: 使用合并工具。git mergetool将会调用一个可视化的合并工具来处理冲突合并。 查看差异。git diff将会显示三路差异（三路合并中所采用的三路比较算法）。 查看每个分支的差异。git log --merge -p \u003cpath\u003e将会显示HEAD版本和MERGE_HEAD版本的差异。 查看合并前的版本。git show :1:文件名显示共同祖先的版本，git show :2:文件名显示当前分支的HEAD版本，git show :3:文件名显示对方分支的MERGE_HEAD版本。 ","date":"2023-05-22","objectID":"/posts/git/git/:3:2","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"分支管理策略 在实际开发中，我们应该按照几个基本原则进行分支管理： 首先，master分支应该是非常稳定的，也就是仅用来发布新版本，平时不能在上面干活； 那在哪干活呢？干活都在dev分支上，也就是说，dev分支是不稳定的，到某个时候，比如1.0版本发布时，再把dev分支合并到master上，在master分支发布1.0版本； 你和你的小伙伴们每个人都在dev分支上干活，每个人都有自己的分支，时不时地往dev分支上合并就可以了。 所以，团队合作的分支看起来就像这样： ","date":"2023-05-22","objectID":"/posts/git/git/:3:3","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"Bug分支 修复bug时，我们会通过创建新的bug分支进行修复，然后合并，最后删除； 当手头工作没有完成时，先把工作现场git stash一下，然后去修复bug，修复后，再git stash pop，回到工作现场； 在master分支上修复的bug，想要合并到当前dev分支，可以用git cherry-pick \u003ccommit_id\u003e命令，把bug提交的修改“复制”到当前分支，避免重复劳动。 # 暂存工作区状态 git stash # 查看暂存的工作区状态 git stash list # 恢复全部暂存状态，但不删除暂存内容 git stash apply # 恢复指定暂存状态，但不删除暂存内容 git stash apply stash@{\u003cid\u003e} # 删除暂存内容 git stash drop # 恢复暂存状态，同时删除暂存内容 git stash pop # 复制一个特定的提交到当前分支 git cherry-pick \u003ccommit_id\u003e ","date":"2023-05-22","objectID":"/posts/git/git/:3:4","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"Feature分支 开发一个新feature，最好新建一个分支； 如果要丢弃一个没有被合并过的分支，可以通过git branch -D \u003cname\u003e强行删除。 强制删除分支（会丢失分支上的修改） git branch -D \u003cname\u003e ","date":"2023-05-22","objectID":"/posts/git/git/:3:5","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"多人协作 多人协作的工作模式通常是这样： 首先，可以试图用git push origin \u003cbranch-name\u003e推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin \u003cbranch-name\u003e推送就能成功！ 如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建。 这就是多人协作的工作模式，一旦熟悉了，就非常简单。 本地新建的分支如果不推送到远程，对其他人就是不可见的； 在本地创建和远程分支对应的分支，本地和远程分支的名称最好一致； 从远程抓取分支，如果有冲突，要先处理冲突。 查看远程仓库信息 git remote 查看远程仓库详细信息 git remote -v 与远程仓库代码同步 git pull # git pull = git fetch + git merge 在本地创建和远程分支对应的分支 git checkout -b branch-name origin/branch-name git switch -c branch-name origin/branch-name 将本地分支与远程仓库关联 git branch --set-upstream-to \u003cbranch-name\u003e origin/\u003cbranch-name\u003e 推送本地分支到远程仓库 git push origin \u003cbranch-name\u003e ","date":"2023-05-22","objectID":"/posts/git/git/:3:6","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"标签管理 ","date":"2023-05-22","objectID":"/posts/git/git/:4:0","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"创建标签 # 新建标签（指向最新的commit_id） git tag \u003ctag_name\u003e # 新建标签（指向特定commit_id） git tag \u003ctag_name\u003e \u003ccommit_id\u003e # 查看所有标签 git tag # 显示某个标签的详细信息 git show \u003ctag_name\u003e # 新建带有说明的标签 git tag -a \u003ctag_name\u003e -m \"说明\" \u003ccommit_id\u003e ","date":"2023-05-22","objectID":"/posts/git/git/:4:1","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Git"],"content":"操作标签 # 删除指定本地标签 git tag -d \u003ctag_name\u003e # 删除指定远程标签 git push origin :refs/tags/\u003ctag_name\u003e # 推送一个本地标签 git push origin \u003ctag_name\u003e # 推送全部未推送过的本地标签 git push origin --tags ","date":"2023-05-22","objectID":"/posts/git/git/:4:2","tags":["Git"],"title":"Git的基本使用","uri":"/posts/git/git/"},{"categories":["Go每日一练"],"content":"题目来源于 https://www.topgoer.cn/docs/gomianshiti/mianshiti","date":"2023-05-22","objectID":"/posts/go/day1-10/","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"题目来源于 https://www.topgoer.cn/docs/gomianshiti/mianshiti ","date":"2023-05-22","objectID":"/posts/go/day1-10/:0:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day1 下面这段代码输出的内容是什么? package main import ( \"fmt\" ) func main() { defer_call() } func defer_call() { defer func() { fmt.Println(\"打印前\") }() defer func() { fmt.Println(\"打印中\") }() defer func() { fmt.Println(\"打印后\") }() panic(\"触发异常\") } 答案： 打印后 打印中 打印前 panic: 触发异常 解析： defer 的执行顺序是后进先出。当出现 panic 语句的时候，会先按照 defer 的后进先出的顺序执行，最后才会执行panic。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:1:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day2 下面这段代码输出什么，说明原因。 func main() { slice := []int{0,1,2,3} m := make(map[int]*int) for key,val := range slice { m[key] = \u0026val } for k,v := range m { fmt.Println(k,\"-\u003e\",*v) } } 答案： 0 -\u003e 3 1 -\u003e 3 2 -\u003e 3 3 -\u003e 3 解析： 这是新手常会犯的错误写法，for range 循环的时候会创建每个元素的副本，而不是元素的引用，所以 m[key] = \u0026val 取的都是变量 val 的地址，所以最后 map 中的所有元素的值都是变量 val 的地址，因为最后 val 被赋值为3，所有输出都是3. 正确写法： func main() { slice := []int{0,1,2,3} m := make(map[int]*int) for key,val := range slice { // 创建一个临时变量value，每次range的时候这里都是一个新的 value := val m[key] = \u0026value } for k,v := range m { fmt.Println(k,\"===\u003e\",*v) } } ","date":"2023-05-22","objectID":"/posts/go/day1-10/:2:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day3 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:3:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"1.下面两段代码输出什么？ // 1. func main() { s := make([]int, 5) s = append(s, 1, 2, 3) fmt.Println(s) } // 2. func main() { s := make([]int,0) s = append(s,1,2,3,4) fmt.Println(s) } 1 : 0 0 0 0 0 1 2 3 2 ：1 2 3 4 解析：这道题考的是使用 append 向 slice 添加元素，第一段代码常见的错误是 [1 2 3]，需要注意。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:3:1","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"2.下面这段代码有什么缺陷? func funcMui(x,y int)(sum int,error) { return x+y,nil } 缺陷：第二个返回值没有命名。 解析：在函数有多个返回值时，只要有一个返回值有命名，其他的也必须命名。如果有多个返回值必须加上括号()；如果只有一个返回值且命名也必须加上括号()。这里的第一个返回值有命名 sum，第二个没有命名，所以错误。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:3:2","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"3.new()与make()的区别？ new(T) 和 make(T,args) 是 Go 语言内建函数，用来分配内存，但适用的类型不同。 new(T) 会为 T 类型的新值分配已置零的内存空间，并返回地址（指针），即类型为 *T的值。换句话说就是，返回一个指针，该指针指向新分配的、类型为 T 的零值。适用于值类型，如数组、结构体等；new可被替代，能够通过字面值快速初始化。 make(T,args) 分配并初始化，返回初始化之后的 T 类型的引用，而并不是 T 类型的零值，也不是指针 *T；make() 只适用于 slice、map 和 channel；make函数会对三种类型的内部数据结构（长度、容量等）赋值。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:3:3","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"一些延伸 引用（reference）是指可以让程序间接访问其它值的值。指针是引用的一种，是一类简单的透明引用，区别于不透明的引用。（还没有弄懂） C++ 既有指针也有引用。C++ 的引用更接近别名（alias），是受限的指针（不能读取或修改地址值，也不需要显式的解引用，所有操作都作用于指向的值）。 Go 的引用，则是在已经有了 直接值 和 指针 的前提下，针对特定类型的优化：为了兼顾易用性和性能，针对具体类型，在 值 和 指针 之间折中。每种引用类型，有自己独特的机制。一般是由一个结构体负责管理元数据，结构体里有一个指针，指向真正要使用的目标数据。 Go 的引用类型有： 字符串 string：底层的数据结构为 stringStruct ，里面有一个指针指向实际存放数据的字节数组，另外还记录着字符串的长度。不过由于 string 是只读类型（所有看起来对 string 变量的修改，实际上都是生成了新的实例），在使用上常常把它当做值类型看待。由于做了特殊处理，它甚至可以作为常量。string 也是唯一零值不为 nil 的引用类型。 切片（slice）：底层数据结构为 slice 结构体 ，整体结构跟 stringStruct 接近，只是多了一个容量（capacity）字段。数据存放在指针指向的底层数组里。 映射（map）：底层数据结构为 hmap ，数据存放在数据桶（buckets）中，桶对应的数据结构为 bmap 。 函数（func）：底层数据结构为 funcval ，有一个指向真正函数的指针，指向另外的 _func 或者 funcinl 结构体（funcinl 代表被行内优化之后的函数）。 接口（interface）：底层数据结构为 iface 或 eface （专门为空接口优化的结构体），里面持有动态值和值对应的真实类型。 通道（chan）：底层数据结构为 hchan，分别持有一个数据缓冲区，一个发送者队列和一个接收者队列。 如果觉得不好记忆，有一个识别引用类型的快捷办法：凡是零值是 nil 的，都是引用类型。指针作为特殊的透明引用，一般单独讨论。而 字符串 string 因为做了特殊处理，零值为 \"\" ，需要额外记住。除了引用类型和指针，剩下的类型都是直接值类型。 那些说引用类型只有需要 make() 的切片、映射、通道 三种的说法，是错误的！ ","date":"2023-05-22","objectID":"/posts/go/day1-10/:3:4","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day4 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:4:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"1.下面这段代码能否通过编译，不能的话原因是什么；如果能，输出什么? func main() { list := new([]int) list = append(list, 1) fmt.Println(list) } 参考答案及解析：不能通过编译，new([]int) 之后的 list 是一个 *[]int 类型的指针，不能对指针执行 append 操作。可以使用 make() 初始化之后再用。同样的，map 和 channel 建议使用 make() 或字面量的方式初始化，不要用 new() 。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:4:1","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"2.下面这段代码能否通过编译，如果可以，输出什么？ func main() { s1 := []int{1, 2, 3} s2 := []int{4, 5} s1 = append(s1, s2) fmt.Println(s1) } 参考答案及解析：不能通过编译。append() 的第二个参数不能直接使用 slice，需使用 … 操作符，将一个切片追加到另一个切片上：append(s1,s2…)。或者直接跟上元素，形如：append(s1,1,2,3)。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:4:2","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"3.下面这段代码能否通过编译，如果可以，输出什么？ var( size := 1024 max_size = size*2 ) func main() { fmt.Println(size, max_size) } 参考答案及解析：不能通过编译。这道题的主要知识点是变量声明的简短模式，形如：x := 100。但这种声明方式有限制： 必须使用显示初始化； 不能提供数据类型，编译器会自动推导； 只能在函数内部使用简短模式； ","date":"2023-05-22","objectID":"/posts/go/day1-10/:4:3","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day5 下面这段代码能否通过编译？不能的话，原因是什么？如果通过，输出什么？ func main() { sn1 := struct { age int name string }{age: 11, name: \"qq\"} sn2 := struct { age int name string }{age: 11, name: \"qq\"} if sn1 == sn2 { fmt.Println(\"sn1 == sn2\") } sm1 := struct { age int m map[string]string }{age: 11, m: map[string]string{\"a\": \"1\"}} sm2 := struct { age int m map[string]string }{age: 11, m: map[string]string{\"a\": \"1\"}} if sm1 == sm2 { fmt.Println(\"sm1 == sm2\") } } 参考答案及解析：编译不通过 invalid operation: sm1 == sm2 这道题目考的是结构体的比较，有几个需要注意的地方： 结构体只能比较是否相等，但是不能比较大小。 相同类型的结构体才能够进行比较，结构体是否相同不但与属性类型有关，还与属性顺序相关，sn3 与 sn1 就是不同的结构体； sn3:= struct { name string age int }{age:11,name:\"qq\"} 如果 struct 的所有成员都可以比较，则该 struct 就可以通过 == 或 != 进行比较是否相等，比较时逐个项进行比较，如果每一项都相等，则两个结构体才相等，否则不相等； 那什么是可比较的呢，常见的有 bool、数值型、字符、指针、数组等，像切片、map、函数等是不能比较的。 具体可以参考 Go 说明文档。https://golang.org/ref/spec#Comparison_operators ","date":"2023-05-22","objectID":"/posts/go/day1-10/:5:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day6 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:6:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"1.通过指针变量 p 访问其成员变量 name，以下哪项正确？ A.p.name B.(\u0026p).name C.(*p).name D.p-\u003ename 参考答案及解析：AC。\u0026 取址运算符，* 指针解引用。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:6:1","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"2.下面这段代码能否通过编译？如果通过，输出什么？ package main import \"fmt\" type MyInt1 int type MyInt2 = int func main() { var i int =0 var i1 MyInt1 = i var i2 MyInt2 = i fmt.Println(i1,i2) } 参考答案及解析：编译不通过，cannot use i (type int) as type MyInt1 in assignment。 这道题考的是类型别名与类型定义的区别。 第 5 行代码type MyInt1 int是基于类型 int 创建了新类型 MyInt1，第 6 行代码type MyInt2 = int是创建了 int 的类型别名 MyInt2，注意类型别名的定义时使用 = 。所以，第 10 行代码相当于是将 int 类型的变量赋值给 MyInt1 类型的变量，Go 是强类型语言，编译当然不通过；而 MyInt2 只是 int 的别名，本质上还是 int，可以赋值。 第 10 行代码的赋值可以使用强制类型转化 var i1 MyInt1 = MyInt1(i) ","date":"2023-05-22","objectID":"/posts/go/day1-10/:6:2","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day7 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:7:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"1.关于字符串的连接，下面语法正确的是? A. str := ‘abc’ + ‘123’ B. str := “abc” + “123” C. str := ‘123’ + “abc” D. fmt.Sprintf(“abc%d”, 123) 参考答案及解析：B.str := “abc” + “123”，D. fmt.Sprintf(“abc%d”, 123)。知识点：字符串连接。除了以上两种连接方式，还有 strings.Join()、buffer.WriteString()等。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:7:1","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"2.下面这段代码能否编译通过？如果可以，输出什么？ const ( x = iota _ y z = \"zz\" k p = iota ) func main() { fmt.Println(x,y,z,k,p) } 参考答案及解析：编译通过，输出：0 2 zz zz 5。知识点：iota 的使用。 iota是golang语言的常量计数器,只能在常量的表达式中使用。 iota在const关键字出现时将被重置为0(const内部的第一行之前)，const中每新增一行常量声明将使iota计数一次(iota可理解为const语句块中的行索引)。 使用iota能简化定义，在定义枚举时很有用。 iota只能在常量的表达式中使用。 fmt.Println(iota)编译错误： undefined: iota 每次 const 出现时，都会让 iota 初始化为0.【自增长】 const a = iota // a=0 const ( b = iota //b=0 c //c=1 )**自定义类型** 自增长常量经常包含一个自定义枚举类型，允许你依靠编译器完成自增设置。 type Stereotype int const ( TypicalNoob Stereotype = iota // 0 TypicalHipster // 1 TypicalUnixWizard // 2 TypicalStartupFounder // 3 ) ​ 下面是来自time包的例子，它首先定义了一个Weekday命名类型，然后为 一周的每天定义了一个常量，从周日0开始，在其它编程语言中，这种类型一 般被称为枚举类型。 type Weekday int const ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday ) ​ 周一将对应0，周一为1，如此等等。 可跳过的值 我们可以使用下划线跳过不想要的值。 type AudioOutput int const ( OutMute AudioOutput = iota // 0 OutMono // 1 OutStereo // 2 _ _ OutSurround // 5 ) 位掩码表达式 iota 可以做更多事情，而不仅仅是 increment。更精确地说，iota 总是用于 increment，但是它可以用于表达式，在常量中的存储结果值。 type Allergen int const ( IgEggs Allergen = 1 \u003c\u003c iota // 1 \u003c\u003c 0 which is 00000001 IgChocolate // 1 \u003c\u003c 1 which is 00000010 IgNuts // 1 \u003c\u003c 2 which is 00000100 IgStrawberries // 1 \u003c\u003c 3 which is 00001000 IgShellfish // 1 \u003c\u003c 4 which is 00010000 ) 这个工作是因为当你在一个 const 组中仅仅有一个标示符在一行的时候，它将使用增长的 iota 取得前面的表达式并且再运用它，。在 Go 语言的 spec 中， 这就是所谓的隐性重复最后一个非空的表达式列表。 如果你对鸡蛋，巧克力和海鲜过敏，把这些 bits 翻转到 “on” 的位置（从左到右映射 bits）。然后你将得到一个 bit 值 00010011，它对应十进制的 19。 fmt.Println(IgEggs | IgChocolate | IgShellfish) // output // 19 我们也可以在复杂的常量表达式中使用iota，下面是来自net包的例子，用于给一个无符号整数的最低5bit的每个bit指定一个名字： type Flags uint const ( FlagUp Flags = 1 \u003c\u003c iota // is up FlagBroadcast // supports broadcast access capability FlagLoopback // is a loopback interface FlagPointToPoint // belongs to a point-to-point link FlagMulticast // supports multicast access capability ) 随着iota的递增，每个常量对应表达式1 « iota，是连续的2的幂，分别对应一个bit位置。使用这些常量可以用于测试、设置或清除对应的bit位的值： 测试结果： package main import ( \"fmt\" ) type Flags uint const ( FlagUp Flags = 1 \u003c\u003c iota // is up FlagBroadcast // supports broadcast access capability FlagLoopback // is a loopback interface FlagPointToPoint // belongs to a point-to-point link FlagMulticast // supports multicast access capability ) func IsUp(v Flags) bool { return v\u0026FlagUp == FlagUp } func TurnDown(v *Flags) { *v \u0026^= FlagUp } func SetBroadcast(v *Flags) { *v |= FlagBroadcast } func IsCast(v Flags) bool { return v\u0026(FlagBroadcast|FlagMulticast) != 0 } func main() { var v Flags = FlagMulticast | FlagUp fmt.Printf(\"%b %t\\n\", v, IsUp(v)) // \"10001 true\" TurnDown(\u0026v) fmt.Printf(\"%b %t\\n\", v, IsUp(v)) // \"10000 false\" SetBroadcast(\u0026v) fmt.Printf(\"%b %t\\n\", v, IsUp(v)) // \"10010 false\" fmt.Printf(\"%b %t\\n\", v, IsCast(v)) // \"10010 true\" } // 运行结果 10001 true 10000 false 10010 false 10010 true 定义数量级 type ByteSize float64 const ( _ = iota // ignore first value by assigning to blank identifier KB ByteSize = 1 \u003c\u003c (10 * iota) // 1 \u003c\u003c (10*1) MB // 1 \u003c\u003c (10*2) GB // 1 \u003c\u003c (10*3) TB // 1 \u003c\u003c (10*4) PB // 1 \u003c\u003c (10*5) EB // 1 \u003c\u003c (10*6) ZB // 1 \u003c\u003c (10*7) YB // 1 \u003c\u003c (10*8) ) 下面是一个更复杂的例子，每个常量都是1024的幂（还没懂）： const ( _ = 1 \u003c\u003c (10 * iota) KiB // 1024 MiB // 1048576 GiB // 1073741824 TiB // 1099511627776 (exceeds 1 \u003c\u003c 32) PiB // 1125899906842624 EiB // 1152921504606846976 ZiB // 1180591620717411303424 (exceeds 1 \u003c\u003c 64) YiB // 1208925819614629174706176 ) 不过iota常量生成规则也有其局限性。例如，它并不能用于产生1000的幂（KB、MB等），因为Go语言并没有计算幂的运算符。 定义在一行的情况 const ( Apple, Banana = iota + 1, iota + 2 Cherimoya, Durian Elderberry, Fig ) // iota 在下一行增长，而不是立即取得它的引用。(没懂) // Apple: 1 // Banana: 2 // Cherimoya: 2 // Durian: 3 // Elderberry: 3 // Fig: 4 中间插队 const ( i = iota j = 3.14 k = iota l ) // i=0,j=3.14,k=2,l=3 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:7:2","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"3.下面赋值正确的是? A. var x = nil B. var x interface{} = nil C. var x string = nil D. var x error = nil 参考答案及解析：BD。知识点：nil 值。nil 只能赋值给指针、chan、func、interface、map 或 slice 类型的变量。强调下 D 选项的 error 类型，它是一种内置接口类型，看下方贴出的源码就知道，所以 D 是对的。 type error interface { Error() string } ","date":"2023-05-22","objectID":"/posts/go/day1-10/:7:3","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day8 1.关于init函数，下面说法正确的是？ A. 一个包中，可以包含多个 init 函数； B. 程序编译时，先执行依赖包的 init 函数，再执行 main 包内的 init 函数； C. main 包中，不能有 init 函数； D. init 函数可以被其他函数调用； 参考答案及解析：AB。关于 init() 函数有几个需要注意的地方： init() 函数是用于程序执行前做包的初始化的函数，比如初始化包里的变量等; 一个包可以出现多个 init() 函数，一个源文件也可以包含多个 init() 函数； 同一个包中多个 init() 函数的执行顺序没有明确定义，但是不同包的init函数是根据包导入的依赖关系决定的（看下图）; init() 函数在代码中不能被显示调用、不能被引用（赋值给函数变量），否则出现编译错误; 一个包被引用多次，如 A import B,C import B,A import C，B 被引用多次，但 B 包只会初始化一次； 引入包，不可出现死循坏。即 A import B,B import A，这种情况编译失败； 2.下面这段代码输出什么以及原因？ func hello() []string { return nil } func main() { h := hello if h == nil { fmt.Println(\"nil\") } else { fmt.Println(\"not nil\") } } A. nil B. not nil C. compilation error 答案及解析：B。这道题目里面，是将 hello() （应该是hello吧）赋值给变量 h，而不是函数的返回值，所以输出 not nil。没懂，敲代码看一看 3.下面这段代码能否编译通过？如果可以，输出什么？ func GetValue() int { return 1 } func main() { i := GetValue() switch i.(type) { case int: println(\"int\") case string: println(\"string\") case interface{}: println(\"interface\") default: println(\"unknown\") } } 参考答案及解析：编译失败。考点：类型选择，类型选择的语法形如：i.(type)，其中 i 是接口，type 是固定关键字，需要注意的是，只有接口类型才可以使用类型选择。看下关于接口的文章。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:8:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day9 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:9:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"1.关于channel，下面语法正确的是？ A. var ch chan int B. ch := make(chan int) C. \u003c- ch D. ch \u003c- 参考答案及解析：ABC。A、B都是声明 channel；C 读取 channel；写 channel 是必须带上值，所以 D 错误。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:9:1","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ type person struct { name string } func main() { var m map[person]int p := person{\"mike\"} fmt.Println(m[p]) } A.0 B.1 C.Compilation error 参考答案及解析：A。打印一个 map 中不存在的值时，返回元素类型的零值。这个例子中，m 的类型是 map[person]int，因为 m 中不存在 p，所以打印 int 类型的零值，即 0。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:9:2","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"3.下面这段代码输出什么？ func hello(num ...int) { num[0] = 18 } func main() { i := []int{5, 6, 7} hello(i...) fmt.Println(i[0]) } A.18 B.5 C.Compilation error 参考答案及解析：18。知识点：可变参数。 形如...type格式的类型只能作为函数的参数类型存在，并且必须是最后一个参数，它是一个语法糖（syntactic sugar），即这种语法对语言的功能并没有影响，但是更方便程序员使用，通常来说，使用语法糖能够增加程序的可读性，从而减少程序出错的可能。 从内部实现机理上来说，类型...type本质上是一个数组切片，也就是[]type。 做这道题时思考的一个问题，为什么看起来切片作为参数传进去的时候不是值传递呢？正如下面的情况，当我们要修改一个数的值的时候，需要传入指针，而修改切片的时候直接将切片作为参数就可以直接对切片进行修改。 package main import \"fmt\" func main() { i := []int{1, 2, 3} changeSlice(i) fmt.Println(i[0]) num := 1 changeInt(\u0026num) fmt.Println(num) } func changeSlice(num []int) { num[0] = 18 } func changeInt(a *int) { *a = 250 } // 输出 18 250 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:9:3","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"延伸 切片作为函数参数是传值还是传引用？ 学习链接：https://juejin.cn/post/6888117219213967368 切片传参的幻觉 - 传引用 golang中函数的参数为切片时是传引用还是传值？对于这个问题，当你百度一轮过后，你会发现很大一部分人认为是传引用，通常他们会贴出下面这段代码进行佐证： pacakge main func changeSlice(s []int) { s[1] = 111 } func main() { slice := []int{0, 1, 2, 3} fmt.Printf(\"slice: %v \\n\", slice) changeSlice(slice) fmt.Printf(\"slice: %v\\n\", slice) } 上面代码中，在main函数里边初始化一个切片变量slice，接着调用changeSlice函数，参数为切片变量slice。而函数changeSlice的主要处理逻辑是改变切片的第二个元素的值。下面我们看一下运行打印的结果： slice: [0 1 2 3] slice: [0 111 2 3] 从输出结果我们看到，函数changeSlice内对切片的修改，main函数中的切片变量slice也跟着修改了。咋一看，这不就是引用传递的表现吗？ 但事实上真的传引用吗？ 理清三个重要概念 在探讨函数切片参数到底是以哪种方式传递时，我们先来理清下面三个重要的概念： 传值（值传递） 传指针 传引用（引用传递） 传值（值传递） 是指在调用函数时将实际参数拷贝一份传递到函数中，这样在函数中对参数进行修改不会影响到实际参数。这个简单不必赘述。 传指针 形参是指向实参地址的指针，当对形参的指向进行操作时，就相当于对实参本身进行操作。听起来比较绕是吧，我们来看个例子就知道了： func main() { a := 10 pa := \u0026a fmt.Printf(\"value: %p\\n\", pa) fmt.Printf(\"addr: %p\\n\", \u0026pa) modify(pa) fmt.Println(\"a 的值被修改了，新值为:\", a) } func modify(p *int) { fmt.Printf(\"函数内的 value: %p\\n\", p) fmt.Printf(\"函数内的 addr: %p\\n\", \u0026p) *p = 1 } 上面代码中定义了一个变量 a，并把地址保存在指针变量pa里面；接着打印pa的值和pa的地址，然后调用modify函数，参数为指针变量pa；modify函数中首先打印形参p的值和p的地址，接着修改p的值为1。 我们打印输出的结果： value: 0xc000016088 addr: 0xc00000e028 函数内的 value: 0xc000016088 函数内的 addr: 0xc00000e038 a 的值被修改了，新值为: 1 从输出结果中我们可以看到，这是一个指针的拷贝。指针pa 和 p 的值虽然相同，但是存放这两个指针的内存地址是不同的，因此这是两个不同的指针。 注意：任何存放在内存里的东西都有自己的地址，指针也不例外，它虽然指向别的数据，但是也有存放该指针的内存。 结合图来看相信会更清晰一点： 传引用（引用传递） 是指在调用函数时将实际参数的地址传递到函数中，在函数中对参数所进行的修改，将影响实际参数。 假设以上面demo为例子，如果在modify函数中打印指针变量p的地址也是0xc00000e028，那么我们就认为是引用传递 但这里我们不能用go来举例子，原因请接着往下看。 官方打假：Go函数传参只有值传递 看完传值、传指针、传引用的概念后，如果你坚持认为是传引用，好，大叔要在这里直接把你击垮。 根据Go官方文档声明：Go里面函数传参只有值传递一种方式。也就是说，在Go中，函数的传参只有传值一种方式。官方文档传送门 如果你还不服气，咱们直接看例子： package main import \"fmt\" func changeSlice(s []int) { fmt.Printf(\"func: %p \\n\", \u0026s) s[1] = 111 } func main() { slice := []int{0, 1, 2, 3} fmt.Printf(\"slice: %v slice addr %p \\n\", slice, \u0026slice) changeSlice(slice) fmt.Printf(\"slice: %v slice addr %p \\n\", slice, \u0026slice) } 打印输出： slice: [0 1 2 3] slice addr 0xc0000a6020 func: 0xc0000a6060 slice: [0 111 2 3] slice addr 0xc0000a6020 如果函数切片参数传的是引用，那么上面这个例子中，main函数中打印的切片slice的地址应该和changSlice函数中打印切片的地址一样的，但从输出结果来看并不是这样的。 因此在这里，我们可以非常肯定地说：有关Go函数中切片参数是传引用的说法是错误的，另外有关有关引用传递是针对slice、map、channel三种数据类型地说法也是错误的。 切片参数本质还是传值 从上面的分析来看，切片参数传递的方式并非是传引用。反而极有可能是传指针，而在传指针那小节的分析中我们可以知道，传指针其实就是指针的拷贝，形参和实参是两个不同的指针，但是它们的值是一样的。本质上可以说还是传值。 那到底是不是这样的呢？大叔疑问句都出来了，说明90%是有可能的，接下我们就验证一下那剩下的10%。 slice的结构体 我们先来看一下切片的结构体是长啥样的： type slice struct { array unsafe.Pointer len int cap int } type Pointer *ArbitraryType 切片，顾名思义就是数组切下来的一部分，其结构体包含了三部分，第一部分是指向底层数组的指针，其次是切片的大小len和切片的容量cap。（果然含有指针成员变量。） 上面的结构体看着有点变扭，不够直观，我们造个例子：一个数组 arr := [5]int{0,1,2,3,4}，生成一个切片 slice := arr[1:4]，最终得到的切片如下： 再看个例子： func main() { arr := [5]int{0, 1, 2, 3, 4} slice1 := arr[1:4] slice2 := arr[2:5] // 打印一 fmt.Printf(\"arr %v, slice1 %v, slice2 %v arr addr: %p, slice1 addr: %p, slice2 addr: %p\\n\", arr, slice1, slice2, \u0026arr, \u0026slice1, \u0026slice2) // 打印二 fmt.Printf(\"arr[2] addr: %p, slice1[1] addr: %p, slice2[0] addr: %p\\n\", \u0026arr[2], \u0026slice1[1], \u0026slice2[0]) arr[2] = 2222 // 打印三 fmt.Printf(\"arr: %v, slice1: %v, slice2: %v\\n\", arr, slice1, slice2) slice1[1] = 1111 // 打印四 fmt.Printf(\"arr: %v, slice1: %v, slice2: %v\\n\", arr, slice1, slice2) } 上面代码中我们创建一个数组，并生成两个切片。打印它们的值和对应的地址。另外，修改数组或者切片的某个单元的值，观察数组和切片中单元的值的变化： arr [0 1 2 3 4], slice1 [1 2 3], slice2 [2 3 4] arr addr: 0xc000014090, slice1 addr: 0xc00000c080, slice2 addr: 0xc00000c0a0 arr[2] addr: 0xc0000140a0, slice1[1] addr: 0xc0000140a0, slice2[0] addr: 0xc0000140a0 arr: [0 1 2222 3 4], slice1: [1 2222 3], slice2: [2222 3 4] arr: [0 1 1111 3 4], slice1: [1 1111 3], slice2: [1111 3 4] 从打印一结果可以看出：创建的两个切片，它们各自拥有不同的地址 从打印二结果可以看出：切片元素slice1[1]、slice2[0] 与数组元素arr[2]有着同样的地址，说明这些切片共享着数组arr中的数据 打印三和打印四可以看出：修改数组和切片共同部分的数据，对两者都有直接影响，再次印证第二点的结论。 从上面的分析中我们可以知道，两个不同的切片之所以能相互影响，主要因素是切片内部的指针指向同一个数据源，且两个切片的指针指向的数据源中有交集。 再回到切片作为函数参数的问题上，因为Go里面函数传参只有值传递一种方式，所以当切片作为参数时，其实也是切片的拷贝，但是在拷贝的切片中，其包含的指针成员变量的值是一样的，也就是说它们指向的数据源是一样，因此在调用函数内修改形参能影响实参。 Go函数传值总结 通常，我们把在传值拷贝过程中，修改形参能直接修改实参的数据类型称为引用类型。 于是我们又可以这样总结： Go语言中","date":"2023-05-22","objectID":"/posts/go/day1-10/:9:4","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"Day10 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:10:0","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"1.下面这段代码输出什么？ func main() { a := 5 b := 8.1 fmt.Println(a + b) } A.13.1 B.13 C.compilation erro 参考答案及解析：C。a 的类型是 int，b 的类型是 float，两个不同类型的数值不能相加，编译报错。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:10:1","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"2.下面这段代码输出什么？ package main import ( \"fmt\" ) func main() { a := [5]int{1, 2, 3, 4, 5} t := a[3:4:4] fmt.Println(t[0]) } A.3 B.4 C.compilation error 参考答案及解析：B。知识点**：操作符 [i,j]**。基于数组（切片）可以使用操作符 [i,j] 创建新的切片，从索引 i，到索引 j 结束，截取已有数组（切片）的任意部分，返回新的切片，新切片的值包含原数组（切片）的 i 索引的值，但是不包含 j 索引的值。左闭右开呗。i、j 都是可选的，i 如果省略，默认是 0，j 如果省略，默认是原数组（切片）的长度。i、j 都不能超过这个长度值。 假如底层数组的大小为 k，截取之后获得的切片的长度和容量的计算方法：长度：j-i，容量：k-i。 截取操作符还可以有第三个参数，形如 [i,j,k]，第三个参数 k 用来限制新切片的容量，但不能超过原数组（切片）的底层数组大小。截取获得的切片的长度和容量分别是：j-i、k-i。 所以例子中，切片 t 为 [4]，长度和容量都是 1。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:10:2","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"3.下面这段代码输出什么？ func main() { a := [2]int{5, 6} b := [3]int{5, 6} if a == b { fmt.Println(\"equal\") } else { fmt.Println(\"not equal\") } } A. compilation error B. equal C. not equal 参考答案及解析：A。Go 中的数组是值类型，可比较，另外一方面，数组的长度也是数组类型的组成部分，所以 a 和 b 是不同的类型，是不能比较的，所以编译错误。 ","date":"2023-05-22","objectID":"/posts/go/day1-10/:10:3","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["Go每日一练"],"content":"延伸——go中的类型比较 https://segmentfault.com/a/1190000039005467 go中的类型 首先来看看go包含的最基础的集中类型 基本类型：go中最基本类型包括整型（int、uint、int8、uint8、int16、uint16、int32、uint32、int64、uint64、byte、rune等）、浮点型（float32、float64）、字符串（string也是个[]rune数组）和比较不常用的复数类型（complex64/complex128）。 复合类型：主要包括结构体和数组。 引用类型：Slice、Map、Channel、指针。 接口类型：Error、io.Reader等。 go作为强类型语言并不会和PHP等高级语言自动帮我们进行类型转换，所以我们在比较时必须用==两边的类型必须一致，即使他们底部类型一致也不行。看下面的代码 package main import \"fmt\" type A struct { Id int } type B struct { Id int } func main() { var a int var b int16 // 编译报错：invalid operation a == b (mismatched types int and int16) fmt.Println(a == b) aStruct := A{Id:5} bStruct := B{Id:5} // 编译报错：invalid operation: aStruct == bStruct (mismatched types A and B) fmt.Println(aStruct == bStruct) } 注意：在上述例子中，一个类型是A，一个类型是B，所以无法比较。再看下面的例子。 package main import \"fmt\" func main() { sn1 := struct { age int name string }{age: 11, name: \"qq\"} sn2 := struct { age int name string }{age: 11, name: \"qq\"} if sn1 == sn2 { fmt.Println(\"sn1 == sn2\") } } 这个例子中，sn1和sn2是匿名结构体，里面的属性顺序相同，可以比较。 基本类型 go的基本类型就比较简单，只要类型是一样的，那么他们就是可以比较的，举个栗子： package main import \"fmt\" func main() { var a int = 0 var b int = 1 // 输出false fmt.Println(a == b) } 复合类型 数组 面试中也经常会问到go数组和切片的区别。数组在go中是必须先确定长度的，也就是长度不能再去扩容。并且它是个值拷贝，做参数传到一个函数中被修改，那么外部的值还是一样的不变的。Slice则相反。那么数组是否可以比较呢，看下面的例子： package main import \"fmt\" func main() { a := [2]int{1, 2} b := [2]int{1, 2} c := [2]int{1, 3} d := [3]int{1, 2, 4} fmt.Println(a == b) // true fmt.Println(a == c) // false fmt.Println(a == d) // invalid operation: a == d (mismatched types [2]int and [3]int) } 可以看出，相同长度的数组是可以比较的，而不同长度的数组是不能进行比较的。原因是什么呢？这是因为数组类型中,数组的长度也是类型的一部分，不同长度的数组那么他们的类型也就被认为不同的，所以无法比较。 结构体 同样的Struct也是一样的。Struct的比较也从内部类型开始比较，每一类型的值相等才是相等的。如下例子： package main import \"fmt\" type A struct { id int name string } func main() { a := A{id:5,name:\"123\"} b := A{id:5,name:\"123\"} c := A{id:5,name:\"1234\"} fmt.Println(a == b) // true fmt.Println(a == c) // false } 那么可以理解成Struct结构体是可以比较的吗。我们再来看个例子： package main import \"fmt\" type A struct { id int name string son []int } func main() { a := A{id:5,name:\"123\",son:[]int{1,2,3}} b := A{id:5,name:\"123\",son:[]int{1,2,3}} fmt.Println(a == b) // invalid operation: a == b (struct containing []int cannot be compared) } 怎么又变成不可比较的呢？这就要看下面的引用类型了。 引用类型 上面中的例子结构体中带上切片就无法比较了，在go中Slice和Map被定义成不能比较的类型。我们来看 如果Slice是可比较，那么用什么来定义是一样的切片呢？如果用地址，那么如果两个地址指向的Slice是一样的呢？这显然不合适。如果和数组一样的方式，那么我切片扩容了呢，就不相等了。所以长度和容量导致不好比较。虽然可以在语言层面解决这个问题，但是 golang 团队认为不值得为此耗费精力。所以Slice被当成不可比较。 同样的Map也被定义成不可比较类型。那么引用类型都是不可比较吗?也不是，看个例子： package main import \"fmt\" type A struct { id int name string } func main() { a := \u0026A { a : 1, b : \"test1\" } b := \u0026A { a : 1, b : \"test1\" } c := a fmt.Println(a == b) // false fmt.Println(a == c) // true ch1 := make(chan int, 1) ch2 := make(chan int, 1) ch3 := ch1 fmt.Println(ch1 == ch2) // false fmt.Println(ch1 == ch3) // true } 引用类型变量存储的是某个变量的内存地址。所以引用类型变量的比较，判断的是这两个引用类型存储的是不是同一个变量。 如果是同一个变量，则内存地址肯定也一样，则引用类型变量相等，用\"==“判断为true 如果不是同一个变量，则内存地址肯定不一样，\"==“结果为false‘ 接口类型 Go 语言根据接口类型是否包含一组方法将接口类型分成了两类： 使用 runtime.iface结构体表示包含方法的接口 使用 runtime.eface结构体表示不包含任何方法的 interface{} 类型 type eface struct { // 16 字节 _type *_type data unsafe.Pointer } type iface struct { // 16 字节 tab *itab data unsafe.Pointer } 所以我们可以得知，一个接口值是由两个部分组成的，即该接口对应的类型和接口对应具体的值。接口值的比较涉及这两部分的比较，只有当类型和值都相等（动态值使用==比较），两个接口值才是相等的。看个例子： var a interface{} = 0 var b interface{} = 2 var c interface{} = 0 var d interface{} = 0.0 fmt.Println(a == b) // false fmt.Println(a == c) // true fmt.Println(a == d) // false a和c类型相同（都是int），值也相同（都是0，基本类型比较），故两者相等。 a和b类型相同，值不等，故两者不等。 a和d类型不同，a为int，d为float64，故两者不等。 type A struct { a int b string } var a interface{} = A { a: 1, b: \"test\" } var b interface{} = A { a: 1, b: \"test\" } var c interface{} = A { a: 2, b: \"test\" } fmt.Println(a == b) // true fmt.Println(a == c) // false var d interface{} = \u0026A { a: 1, b: \"test\" } var e interface{} = \u0026A { a: 1, b: \"test\" } fmt.Println(d == e) // false a和b类型相同（都是A），值也相同（结构体A），故两者相等。 a和c类型相同，值不同，故两者不等。 d和e类型相同（都是*A），值使用指针（引用）类型的比较，由于不是指向同一个地址，故不等。 不过需要注意的是，如果接口中类","date":"2023-05-22","objectID":"/posts/go/day1-10/:10:4","tags":["go","面试"],"title":"Go Exercises(Day1-10)","uri":"/posts/go/day1-10/"},{"categories":["docker"],"content":"DockerFile是什么 简单来讲，当我们想创建自己的一个镜像，添加新的功能时，用原来的方法需要一次次地执行docker commit，现在我们可以使用Dockerfile一次性地提交全部修改。 Dockerfile是用来构建Docker镜像的本地文件，是由一条条构建镜像所需的指令和参数构成的脚本。 Dockerfile构建镜像的步骤 编写Dockerfile文件 dokcer build 命令构建镜像 docker run依照镜像运行容器实例 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:1:0","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"DockerFile构建过程解析 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:2:0","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"Dockerfile内容基础知识 每条保留字指令都必须为大写字母且后面要跟随至少一个参数 指令按照从上到下，顺序执行 #表示注释 每条指令都会创建一个新的镜像层并对镜像进行提交 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:2:1","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"Docker执行Dockerfile的大致流程 docker从基础镜像运行一个容器 执行一条指令并对容器做出修改 执行类似docker commit的操作提交一个新的镜像层 docker再基于刚提交的镜像运行一个新容器 执行dockerfile中的下一条指令直到所有指令都执行完成 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:2:2","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"小总结 从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段， Dockerfile是软件的原材料 Docerk镜像是软件的交付品 Docker容器则可以人为是软件镜像的交付标准，也即依照镜像运行的容器实例 Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合理充当Docker体系的基石。 Dockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程（当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制）等等； Docker镜像，在用Dockerfile定义一个文件之后，docker build时会产生一个Docker镜像，运行Docker镜像时会真正开始提供服务； Docker容器，容器是直接提供服务的。 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:2:3","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"DockerFile常用保留字 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:0","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"参考tomcat8的dockerfile入门 https://github.com/docker-library/tomcat ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:1","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"FROM FROM 基础镜像 当前镜像是基于哪个镜像的，指定一个已经存在的镜像作为模板，第一条必须是from ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:2","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"MAINTAINER 镜像维护者的姓名和邮箱地址 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:3","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"RUN 容器构建时需要运行的命令，有两种格式（shell、exec），是在docker build时运行的。 shell格式 # \u003c命令行命令\u003e等同于，在终端操作的shell命令 RUN \u003c命令行命令\u003e exec格式 RUN [\"可执行文件\", \"参数1\", \"参数2\"] # 例如： # RUN [\"./test.php\", \"dev\", \"offline\"]等价与 RUN ./test.php dev offline ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:4","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"EXPOSE 当前容器对外暴露出的端口 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:5","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"WORKDIR 指定在创建容器后，终端默认登录的进来工作目录，一个落脚点 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:6","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"USER 指定该镜像以什么样的用户去执行，如果都不指定，默认是root ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:7","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"ENV 用来在构建镜像过程中设置环境变量 ENV MY_PATH /usr/mytest 这个环境变量可以在候选的任何RUN指令中使用，这就如同在命令前面指定了环境变量前缀一样； 也可以再其他指令中直接使用这些环境变量 比如：WORKDIR $MY_PATH ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:8","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"ADD 将宿主机目录下的文件拷贝进镜像且会自动处理URL和解压tar压缩包 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:9","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"COPY 类似ADD，拷贝文件和目录到镜像中。 将从构建上下文目录中\u003c源路径\u003e的文件/目录复制到新的一层的镜像内的\u003c目标路径\u003e位置 COPY src dest COPY [“src”, “dest”] \u003csrc源路径\u003e：源文件或者源目录 \u003cdest目标路径\u003e：容器内的指定路径，该路径不用事先建好，路径不存在的话，会自动创建。 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:10","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"VOLUME 容器数据卷，用于数据保存和持久化工作 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:11","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"CMD 指定容器启动后要干的事情： CMD指令的格式和RUN类似，也是两种格式： shell 格式：CMD \u003c命令\u003e exec 格式：CMD [\"可执行文件\",\"参数1\",\"参数2\"] 参数列表格式：CMD [\"参数1\", \"参数2\"...]在指定了ENTRYPOINT指令后，用CMD指定具体的参数 注意 Dockerfile中可以有多个CDM指令，但只有最后一个生效，CMD会被docker run之后的参数替换。 和RUN命令的区别：CMD是在docker run时运行，RUN是在docker build时运行。 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:12","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"ENTRYPOINT 也是用来指定一个容器启动时要运行的命令，类似于CMD指令，但是ENTRYPOINT不会被docker run 后面的命令覆盖，而且这些命令行参数会被当作参数送给ENTRYPOINT指令指定的程序。 ENTRYPOINT [\"\u003cexecuteable\u003e\", \"\u003cparam1\u003e\", \"\u003cparam2\u003e\",...] ENTRYPOINT 可以和CMD一起使用，一般是变参才会使用CMD，这里的CMD等于是在给ENTRYPOINT 传参。当指定了ENTRYPOINT 后，CMD的含义就发生了变化，不再是直接运行其命令而是将CMD的内容作为参数传递给ENTRYPOINT 指令。 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:13","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"小总结 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:3:14","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"案例 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:4:0","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"自定义镜像centosjava8 要求 Centos镜像具备vim+ifconfig+jdk jdk下载地址 https://www.oracle.com/java/technologies/downloads/或 https://mirrors.yangxingzhen.com/jdk/ 编写 mkdir /myfile 创建文件夹，在文件夹中下载jdk的tar.gz压缩包，并编写Dockerfile文件 vim Dockerfile FROM centos # 基础镜像，当前新镜像是基于那个镜像 MAINTAINER Lizhe\u003c2181426542@qq.com\u003e # 指定镜像维护的作者和邮箱 ENV MYPATH /usr/local WORKDIR $MYPATH # 安装vim编辑器 RUN yum -y install vim # 安装ifconfig命令查看网络ip RUN yum -y install net-tools # 安装java8以及lib库 RUN yum -y install glibc.i686 RUN mkdir /usr/local/java # ADD 是相对路径jar，把jdk压缩包添加到容器中，安装包必须要和Dockerfile文件在同一位置 ADD jdk-8u171-linux-x64.tar.gz/usr/local/java/ # 配置java环境变量 ENV JAVA_HOME /usr/local/java/jdk1.8.0_171 ENV JRE_HOME $JAVA_HOME/jre ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH ENV PATH $JAVA_HOME/bin:$PATH EXPOSE 80 # 这里的三个CMD好像有问题，会有覆盖的情况 CMD echo $MYPATH CMD echo \"success-------ok\" CMD /bin/bash 构建 docker build -t 新镜像名字:TAG . # 注意，TAG后面有个空格，有个点，TAG是版本号 在本案例中：docker build -t centosjava8:1.5 . 这时我们再输入docker images，就会看到有centosjava8这个新镜像 运行 docker run -it centosjava8:1.5 执行ifconfig、java version检查 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:4:1","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"虚悬镜像 虚悬镜像是什么？ 构建或删除时出现错误，导致仓库名、标签都是none的镜像，俗称dangling image。当我们发现虚悬镜像时，要记得删除，防止有风险。 用Dockerfile写一个虚悬镜像 vim Dockerfile FROM ubuntu CMD echo 'action is success' docker build . # 注意有一个点 查看虚悬镜像 docker images会看到一个仓库和标签都名为\u003cnone\u003e的镜像 docker image ls -f dangling=true # 查看所有虚悬镜像 删除虚悬镜像 docker image prune ","date":"2023-05-22","objectID":"/posts/docker/docker04/:4:2","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["docker"],"content":"小总结 ","date":"2023-05-22","objectID":"/posts/docker/docker04/:5:0","tags":["docker"],"title":"DockerFie","uri":"/posts/docker/docker04/"},{"categories":["Gin"],"content":"Gin框架的基本使用","date":"2023-05-21","objectID":"/posts/gin/gin01/","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"学习链接： https://learnku.com/articles/69259 https://www.liwenzhou.com/posts/Go/gin/ https://gin-gonic.com/zh-cn/docs/ Gin是一个用Go语言编写的web框架。它是一个类似于martini但拥有更好性能的API框架, 由于使用了httprouter，速度提高了近40倍。Gin是Go世界里最流行的Web框架，Github上有68K+star。 基于httprouter开发的Web框架。 中文文档齐全，简单易用的轻量级框架 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:0:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"安装 go get -u github.com/gin-gonic/gin ","date":"2023-05-21","objectID":"/posts/gin/gin01/:1:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"简单示例 将下面的代码保存并编译执行，然后使用浏览器打开127.0.0.1:8080/hello就能看到一串JSON字符串。 Get请求，当我们在浏览器中输入127.0.0.1:8080/hello，敲击回车后就相当于向127.0.0.1:8080/hello发送了一次get请求。 package main import ( \"github.com/gin-gonic/gin\" ) func main() { // 创建一个默认的路由引擎 r := gin.Default() // GET：请求方式；/hello：请求的路径 // 当客户端以GET方法请求/hello路径时，会执行后面的匿名函数 r.GET(\"/hello\", func(c *gin.Context) { // c.JSON：返回JSON格式的数据 c.JSON(200, gin.H{ \"message\": \"Hello world!\", }) }) // 启动HTTP服务，默认在0.0.0.0:8080启动服务 r.Run() //r.Run(\":9090\") 则在9090端口进行监听 127.0.0.1:9090/hello } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:2:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"RESTful API 目前在前后端分离的架构中，前后端基本都是通过RESTful API来进行交互。我们的Gin框架也支持RESTful API。以下示例展示了gin的 GET 、POST、PUT 、DELETE方法。测试可使用Postman或Apifox工具。 RESTful API简单来说就是同一个URL可以用来处理不同的请求。 func main() { r := gin.Default() r.GET(\"/book\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"GET\", }) }) r.POST(\"/book\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"POST\", }) }) r.PUT(\"/book\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"PUT\", }) }) r.DELETE(\"/book\", func(c *gin.Context) { c.JSON(200, gin.H{ \"message\": \"DELETE\", }) }) } 请求方法 URL 含义 GET /book 查询书籍信息 POST /book 创建书籍信息 PUT /book 更新书籍信息 DELETE /book 删除书籍信息 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:3:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"Gin渲染 由于现在项目主要使用前后端分类的方法，渲染使用较少，想学习的话可以参考李文周老师的博客中渲染部分的内容 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:4:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"路由 路由分组方便对路由进行管理，如相同前缀的路由，我们可以将他们分为一组。 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:5:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"普通路由 r.GET(\"/book\", func(c *gin.Context) {...}) r.GET(\"/book\", func(c *gin.Context) {...}) r.POST(\"/book\", func(c *gin.Context) {...}) // 匹配所有请求方法的Any r.Any(\"/test\", func(c *gin.Context) {...}) // 为没有配置处理函数的路由添加处理程序 r.NoRoute(func(c *gin.Context) { c.HTML(http.StatusNotFound, \"views/404.html\", nil) }) ","date":"2023-05-21","objectID":"/posts/gin/gin01/:5:1","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"路由分组 我们可以将拥有共同URL前缀的路由划分为一个路由组。习惯性一对{}包裹同组的路由，这只是为了看着清晰，你用不用{}包裹功能上没什么区别。 func main() { r := gin.Default() userGroup := r.Group(\"/user\") { userGroup.GET(\"/index\", func(c *gin.Context) {...}) userGroup.GET(\"/login\", func(c *gin.Context) {...}) userGroup.POST(\"/login\", func(c *gin.Context) {...}) } bookGroup := r.Group(\"/book\") { bookGroup.GET(\"/index\", func(c *gin.Context) {...}) bookGroup.GET(\"/cart\", func(c *gin.Context) {...}) bookGroup.POST(\"/checkout\", func(c *gin.Context) {...}) } r.Run() } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:5:2","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"路由嵌套 bookGroup := r.Group(\"/book\") { bookGroup.GET(\"/index\", func(c *gin.Context) {...}) bookGroup.GET(\"/cart\", func(c *gin.Context) {...}) bookGroup.POST(\"/checkout\", func(c *gin.Context) {...}) // 嵌套路由组 xx := bookGroup.Group(\"xx\") xx.GET(\"/oo\", func(c *gin.Context) {...}) } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:5:3","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"路由原理 Gin框架中的路由使用的是httprouter这个库。其基本原理就是构造一个路由地址的前缀树。 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:5:4","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"重定向 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:6:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"HTTP重定向 http重定向是指，当访问/test时，页面会跳转到指定界面。 r.GET(\"/test\", func(c *gin.Context) { c.Redirect(http.StatusMovedPermanently, \"https://lizhe1228.github.io/\") }) ","date":"2023-05-21","objectID":"/posts/gin/gin01/:6:1","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"路由重定向 路由重定向是指，当向/test页面发送请求时，实际上会向/test2发送请求。 r.GET(\"/test\", func(c *gin.Context) { // 指定重定向的URL c.Request.URL.Path = \"/test2\" r.HandleContext(c) }) r.GET(\"/test2\", func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{\"hello\": \"world\"}) }) ","date":"2023-05-21","objectID":"/posts/gin/gin01/:6:2","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"参数值的提取 推荐一款插件，美化JSON格式，FeHelper。 为了测试以下的方法，建议使用postman或apifox工具。注意发送请求时选择的方法，以及请求体Body中选择相应的格式如form-data（用来模拟form’表单的提交） 、raw（用来写json等） ","date":"2023-05-21","objectID":"/posts/gin/gin01/:7:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"获取querystring参数 querystring指的是URL中?后面携带的参数，参数用\u0026进行分隔，例如：/user/search?username=lz\u0026age=23。 获取请求的querystring参数的方法如下： func main() { //Default返回一个默认的路由引擎 r := gin.Default() r.GET(\"/user/search\", func(c *gin.Context) { // c.DefaultQuery是指若没有查到username，则默认返回值lz username := c.DefaultQuery(\"username\", \"lz\") //username := c.Query(\"username\") address := c.Query(\"address\") //输出json结果给调用方 c.JSON(http.StatusOK, gin.H{ \"message\": \"ok\", \"username\": username, \"address\": address, }) }) r.Run() } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:7:1","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"获取form参数 当前端请求的数据通过form表单提交时，例如向/user/search发送一个POST请求，form表单最简单的例子就是登录时输入的用户名和密码，获取请求数据的方式如下： func main() { //Default返回一个默认的路由引擎 r := gin.Default() r.POST(\"/user/search\", func(c *gin.Context) { // DefaultPostForm取不到值时会返回指定的默认值 //username := c.DefaultPostForm(\"username\", \"小王子\") username := c.PostForm(\"username\") address := c.PostForm(\"address\") // 还有这种返回两个值，第二个值表示是否能拿到数据 // msg, ok := c.GetPostForm() //输出json结果给调用方 c.JSON(http.StatusOK, gin.H{ \"message\": \"ok\", \"username\": username, \"address\": address, }) }) r.Run(\":8080\") } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:7:2","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"获取json参数 当前端请求的数据通过JSON提交时，例如向/json发送一个POST请求，则获取请求参数的方式如下： r.POST(\"/json\", func(c *gin.Context) { // 注意：下面为了举例子方便，暂时忽略了错误处理 b, _ := c.GetRawData() // 从c.Request.Body读取请求数据 // 定义map或结构体 var m map[string]interface{} // 反序列化 _ = json.Unmarshal(b, \u0026m) c.JSON(http.StatusOK, m) }) ","date":"2023-05-21","objectID":"/posts/gin/gin01/:7:3","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"获取path参数 请求的参数通过URL路径传递，例如：/user/search/parameter1/parameter2。 获取请求URL路径中的参数（parameter1和parameter2）的方式如下: func main() { //Default返回一个默认的路由引擎 r := gin.Default() r.GET(\"/user/search/:parm1/:parm2\", func(c *gin.Context) { username := c.Param(\"parm1\") address := c.Param(\"parm2\") //输出json结果给调用方 c.JSON(http.StatusOK, gin.H{ \"message\": \"ok\", \"username\": username, \"address\": address, }) }) r.Run(\":8080\") } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:7:4","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"参数绑定 为了能够更方便的获取请求相关参数，提高开发效率，我们可以基于请求的Content-Type识别请求数据类型并利用反射机制自动提取请求中QueryString、form表单、JSON、XML等参数到结构体中。 下面的示例代码演示了.ShouldBind()强大的功能，它能够基于请求自动提取JSON、form表单和QueryString类型的数据，并把值绑定到指定的结构体对象。 // tag标签 反射机制 // 这里要在地址栏中输入如下的请求（这是querystring的传递方式） // 用form tag才能拿到数据 // 9090/user?username=lz\u0026password=123456 // tag 指的是请求中user pwd字段对应识别到结构体中的Username和Password type UserInfo struct { Username string `form:\"username\" json:\"user\"` Password string `form:\"password\" json:\"pwd\"` } func main() { r := gin.Default() r.GET(\"/user\", func(ctx *gin.Context) { var u UserInfo // 声明一个userinfo类型的U // ShouldBind 把请求里面和username和password相关的 // 内容拷贝给u // shouldbind 可以自动识别各种类型 如JSON、form、querystring // 通过一个shouldbind函数相当于完成了以下的命令 // username := ctx.Query(\"username\") // password := ctx.Query(\"password\") // u := UserInfo{ // Username: username, // Password: password, // } err := ctx.ShouldBind(\u0026u) if err != nil { ctx.JSON(http.StatusBadRequest, gin.H{ \"error\": err.Error(), }) } else { fmt.Printf(\"%#v\\n\", u) ctx.JSON(200, gin.H{ \"message\": \"ok\", }) } }) r.Run(\":9090\") } // Binding from JSON type Login struct { User string `form:\"user\" json:\"user\" binding:\"required\"` Password string `form:\"password\" json:\"password\" binding:\"required\"` } func main() { router := gin.Default() // 绑定JSON的示例 ({\"user\": \"lz\", \"password\": \"123456\"}) router.POST(\"/loginJSON\", func(c *gin.Context) { var login Login if err := c.ShouldBind(\u0026login); err == nil { fmt.Printf(\"login info:%#v\\n\", login) c.JSON(http.StatusOK, gin.H{ \"user\": login.User, \"password\": login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) } }) // 绑定form表单示例 (user=lz\u0026password=123456) router.POST(\"/loginForm\", func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 if err := c.ShouldBind(\u0026login); err == nil { c.JSON(http.StatusOK, gin.H{ \"user\": login.User, \"password\": login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) } }) // 绑定QueryString示例 (/loginQuery?user=lz\u0026password=123456) router.GET(\"/loginForm\", func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 if err := c.ShouldBind(\u0026login); err == nil { c.JSON(http.StatusOK, gin.H{ \"user\": login.User, \"password\": login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\"error\": err.Error()}) } }) // Listen and serve on 0.0.0.0:8080 router.Run(\":8080\") } ShouldBind会按照下面的顺序解析请求中的数据完成绑定： 如果是 GET 请求，只使用 Form 绑定引擎（query）。 如果是 POST 请求，首先检查 content-type 是否为 JSON 或 XML，然后再使用 Form（form-data）。 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:7:5","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"Gin实现翻译器 package main import ( \"fmt\" \"net/http\" \"reflect\" \"strings\" \"github.com/gin-gonic/gin/binding\" \"github.com/go-playground/locales/en\" \"github.com/go-playground/locales/zh\" ut \"github.com/go-playground/universal-translator\" \"github.com/go-playground/validator/v10\" enTranslations \"github.com/go-playground/validator/v10/translations/en\" zhTranslations \"github.com/go-playground/validator/v10/translations/zh\" \"github.com/gin-gonic/gin\" ) // 定义一个全局翻译器T var trans ut.Translator //Login登录业务，字段添加tag约束条件 type Login struct { User string `json:\"user\" binding:\"required\"` //必填 Password string `json:\"password\" binding:\"required\"` //必填 } //SignUp注册业务，字段添加tag约束条件 type SignUp struct { Age int `json:\"age\" binding:\"gte=18\"` //gte大于等于 Name string `json:\"name\" binding:\"required\"` //必填 Email string `json:\"email\" binding:\"required,email\"` //必填邮件 Password string `json:\"password\" binding:\"required\"` //必填 RePassword string `json:\"re_password\" binding:\"required,eqfield=Password\"` //RePassword和Password值一致 } //RemoveTopStruct去除以\".\"及其左部分内容 func RemoveTopStruct(fields map[string]string) map[string]string { res := map[string]string{} for field, value := range fields { res[field[strings.Index(field, \".\")+1:]] = value } return res } // InitTrans 初始化翻译器 func InitTrans(locale string) (err error) { // 修改gin框架中的Validator引擎属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok { //注册一个获取json的自定义方法 v.RegisterTagNameFunc(func(field reflect.StructField) string { name := strings.SplitN(field.Tag.Get(\"json\"), \",\", 2)[0] if name == \"-\" { return \"\" } return name }) zhT := zh.New() // 中文翻译器 enT := en.New() // 英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // locale 通常取决于 http 请求头的 'Accept-Language' var ok bool // 也可以使用 uni.FindTranslator(...) 传入多个locale进行查找 trans, ok = uni.GetTranslator(locale) if !ok { return fmt.Errorf(\"uni.GetTranslator(%s) failed\", locale) } // 注册翻译器 switch locale { case \"en\": err = enTranslations.RegisterDefaultTranslations(v, trans) case \"zh\": err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) } return } return } func main() { res := map[string]string{ \"ice_moss.habbit\": \"打球\", \"ice_moss.from\": \"贵州 中国\", } fmt.Println(RemoveTopStruct(res)) //初始化翻译器, 翻译器代码看不懂不要紧，我们只需知道这样使用就行 if err := InitTrans(\"zh\"); err != nil { fmt.Println(\"初始化翻译器失败\", err) return } router := gin.Default() router.POST(\"/loginJSON\", func(c *gin.Context) { var login Login if err := c.ShouldBind(\u0026login); err != nil { fmt.Println(err.Error()) errs, ok := err.(validator.ValidationErrors) if !ok { c.JSON(http.StatusOK, gin.H{ \"msg\": err.Error(), }) } c.JSON(http.StatusInternalServerError, gin.H{ \"error\": errs.Translate(trans), }) return } c.JSON(http.StatusOK, gin.H{ \"msg\": \"验证通过\", }) }) router.POST(\"/signupJSON\", func(c *gin.Context) { var signup SignUp //ShouldBind()对数据进行绑定，解组 if err := c.ShouldBind(\u0026signup); err != nil { fmt.Println(err.Error()) //获取validator.ValidationErrors类型的error errs, ok := err.(validator.ValidationErrors) if !ok { c.JSON(http.StatusOK, gin.H{ \"msg\": err.Error(), }) } //validator.ValidationErrors类型错误则进行翻译 c.JSON(http.StatusInternalServerError, gin.H{ \"error\": RemoveTopStruct(errs.Translate(trans)), }) return } c.JSON(http.StatusOK, gin.H{ \"msg\": \"注册成功\", }) }) router.Run(\":8083\") } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:8:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"中间件 Gin框架允许开发者在处理请求的过程中，加入用户自己的钩子（Hook）函数。这个钩子函数就叫中间件，中间件适合处理一些公共的业务逻辑，比如登录认证、权限校验、数据分页、记录日志、耗时统计等。 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:9:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"定义中间件 Gin中的中间件必须是一个gin.HandlerFunc类型。 中间件的常见形式 func authMiddleware(doCheck bool)gin.Handlerfunc { // 连接数据库 // 或者一些其他准备工作 return func(c *gin.Context) { if doCheck { // 存放具体的逻辑 // 是否登录的判断 // if 是登录用户 // c.Next() // else // c.Abort() } else { c.Next() } } } 通过中间件在上下文定义一些值 // 中间件可以在上下文中设一些kv值，其他中间件可以通过key值取到value c.Set(\"key\", \"value\") name, ok := c.Get(\"key\") name := c.MustGet(\"key\") 记录接口耗时的中间件 // StatCost 是一个统计耗时请求耗时的中间件 func StatCost() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Set(\"name\", \"lz\") // 可以通过c.Set在请求上下文中设置值，后续的处理函数能够取到该值 // 调用该请求的剩余处理程序 // 这里指的是 r.GET(\"/\", StatCost, func1) 这里的func1 c.Next() // 不调用该请求的剩余处理程序 // c.Abort() //执行完func1后才执行这个 计算耗时 cost := time.Since(start) log.Println(cost) } } 记录响应体的中间件 type bodyLogWriter struct { gin.ResponseWriter // 嵌入gin框架ResponseWriter body *bytes.Buffer // 我们记录用的response } // Write 写入响应体数据 func (w bodyLogWriter) Write(b []byte) (int, error) { w.body.Write(b) // 我们记录一份 return w.ResponseWriter.Write(b) // 真正写入响应 } // ginBodyLogMiddleware 一个记录返回给客户端响应体的中间件 // https://stackoverflow.com/questions/38501325/how-to-log-response-body-in-gin func ginBodyLogMiddleware(c *gin.Context) { blw := \u0026bodyLogWriter{body: bytes.NewBuffer([]byte{}), ResponseWriter: c.Writer} c.Writer = blw // 使用我们自定义的类型替换默认的 c.Next() // 执行业务逻辑 fmt.Println(\"Response body: \" + blw.body.String()) // 事后按需记录返回的响应 } 一个案例 好好理解中间件与c.Next() func indexHandler(c *gin.Context) { fmt.Println(\"index\") c.JSON(http.StatusOK,gin.H{ \"msg\": \"index\", }) } // 定义一个中间件m1:统计请求处理函数的耗时 func m1(c *gin.Context){ fmt.Println(\"m1 in...\") // 计时 start := time.Now() c.Next() // 调用后续的处理函数 // c.Abort() // 阻止调用后续的处理函数 cost := time.Since(start) fmt.Printf(\"cost:%v\\n\",cost) fmt.Println(\"m1 out\") } func m2(c *gin.Context){ fmt.Println(\"m2 in...\") c.Next() // 调用后续的处理函数 fmt.Println(\"m2 out...\") } func main(){ r := gin.Default() r.Use(m1,m2) // 全局注册中间件函数m1,m2 r.GET(\"/index\", indexHandler) r.Run() } 上述代码的执行顺序如下： m1 in… m2 in… index m2 out… cost:187.975μs m1 out… 跨域中间件cors 跨域问题在前后端都可以解决，我曾经做的项目中就遇到了这个问题，这是一个常见的需要进行一下简单处理的问题。 推荐使用社区的https://github.com/gin-contrib/cors 库，一行代码解决前后端分离架构下的跨域问题。 注意： 该中间件需要注册在业务处理函数前面。 这个库支持各种常用的配置项，具体使用方法如下。 package main import ( \"time\" \"github.com/gin-contrib/cors\" \"github.com/gin-gonic/gin\" ) func main() { router := gin.Default() // CORS for https://foo.com and https://github.com origins, allowing: // - PUT and PATCH methods // - Origin header // - Credentials share // - Preflight requests cached for 12 hours router.Use(cors.New(cors.Config{ AllowOrigins: []string{\"https://foo.com\"}, // 允许跨域发来请求的网站 AllowMethods: []string{\"GET\", \"POST\", \"PUT\", \"DELETE\", \"OPTIONS\"}, // 允许的请求方法 AllowHeaders: []string{\"Origin\", \"Authorization\", \"Content-Type\"}, ExposeHeaders: []string{\"Content-Length\"}, AllowCredentials: true, AllowOriginFunc: func(origin string) bool { // 自定义过滤源站的方法 return origin == \"https://github.com\" }, MaxAge: 12 * time.Hour, })) router.Run() } 当然你可以简单的像下面的示例代码那样使用默认配置，允许所有的跨域请求。 func main() { router := gin.Default() // same as // config := cors.DefaultConfig() // config.AllowAllOrigins = true // router.Use(cors.New(config)) router.Use(cors.Default()) router.Run() } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:9:1","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"注册中间件 为全局路由注册 func m1(c *gin.Context) { ... } r.GET(\"/1\", m1, func1) r.GET(\"/2\", m1, func2) r.GET(\"/3\", m1, func3) // 为了避免这种每一个请求都写一个m1 可以全局注册中间件m1 r.Use(m1) func main() { // 新建一个没有任何默认中间件的路由 r := gin.New() // 注册一个全局中间件 r.Use(StatCost()) r.GET(\"/test\", func(c *gin.Context) { name := c.MustGet(\"name\").(string) // 从上下文取值 log.Println(name) c.JSON(http.StatusOK, gin.H{ \"message\": \"Hello world!\", }) }) r.Run() } 为某个路由单独注册 // 给/test2路由单独注册中间件（可注册多个） r.GET(\"/test2\", StatCost(), func(c *gin.Context) { name := c.MustGet(\"name\").(string) // 从上下文取值 log.Println(name) c.JSON(http.StatusOK, gin.H{ \"message\": \"Hello world!\", }) }) 为路由组注册中间件 // 写法一 shopGroup := r.Group(\"/shop\", StatCost()) { shopGroup.GET(\"/index\", func(c *gin.Context) {...}) ... } // 写法二 shopGroup := r.Group(\"/shop\") shopGroup.Use(StatCost()) { shopGroup.GET(\"/index\", func(c *gin.Context) {...}) ... } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:9:2","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"中间件注意事项 gin默认中间件 gin.Default()默认使用了Logger和Recovery中间件，其中： Logger中间件将日志写入gin.DefaultWriter，即使配置了GIN_MODE=release。 Recovery中间件会recover任何panic。如果有panic的话，会写入500响应码。 如果不想使用上面两个默认的中间件，可以使用gin.New()新建一个没有任何默认中间件的路由。 gin中间件中使用goroutine 当在中间件或handler中启动新的goroutine时，不能使用原始的上下文（c *gin.Context），必须使用其只读副本（c.Copy()）。 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:9:3","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"静态文件的挂载 前后端分离的框架，需要我们将前端build好的文件进行挂载，来满足需求。 目录结构： project ├── main.go ├── static │ └── style.css └── templates └── user └── list.html html 文件: \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003e{{ .title }}\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"/static/style.css\"\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003e{{ .list }}\u003c/h1\u003e \u003c/body\u003e \u003c/html\u003e css 文件: *{ background-color: aquamarine; } 静态文件挂载方法： router.Static(\"/static\", \"./static\") 该方法会去在 html 文件中 \u003clink\u003e 标签中找到以 static 开头的链接，然后去找在当前 main 所在的目录下找到以第二个参数./static 名称的目录下找到静态文件，然后挂载。 package main import ( \"fmt\" \"net/http\" \"os\" \"path/filepath\" \"github.com/gin-gonic/gin\") func main() { router := gin.Default() //挂载静态文件 router.Static(\"/static\", \"./static\") router.LoadHTMLGlob(\"templates/**/*\") router.GET(\"user/list\", func(c *gin.Context) { c.HTML(http.StatusOK, \"list.html\", gin.H{ \"title\": \"shop\", \"list\": \"用户列表\", }) }) router.Run(\":8085\") } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:10:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"文件上传 文件上传前端代码 \u003c!DOCTYPE html\u003e \u003chtml lang=\"zh-CN\"\u003e \u003chead\u003e \u003ctitle\u003e上传文件示例\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cform action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\"\u003e \u003cinput type=\"file\" name=\"f1\"\u003e \u003cinput type=\"submit\" value=\"上传\"\u003e \u003c/form\u003e \u003c/body\u003e \u003c/html\u003e 后端代码 单文件上传 func main() { router := gin.Default() // 处理multipart forms提交文件时默认的内存限制是32 MiB // 可以通过下面的方式修改 // router.MaxMultipartMemory = 8 \u003c\u003c 20 // 8 MiB router.POST(\"/upload\", func(c *gin.Context) { // 单个文件 file, err := c.FormFile(\"f1\") if err != nil { c.JSON(http.StatusInternalServerError, gin.H{ \"message\": err.Error(), }) return } log.Println(file.Filename) dst := fmt.Sprintf(\"C:/tmp/%s\", file.Filename) // 上传文件到指定的目录 c.SaveUploadedFile(file, dst) c.JSON(http.StatusOK, gin.H{ \"message\": fmt.Sprintf(\"'%s' uploaded!\", file.Filename), }) }) router.Run() } 多文件上传 func main() { router := gin.Default() // 处理multipart forms提交文件时默认的内存限制是32 MiB // 可以通过下面的方式修改 // router.MaxMultipartMemory = 8 \u003c\u003c 20 // 8 MiB router.POST(\"/upload\", func(c *gin.Context) { // Multipart form form, _ := c.MultipartForm() files := form.File[\"file\"] for index, file := range files { log.Println(file.Filename) dst := fmt.Sprintf(\"C:/tmp/%s_%d\", file.Filename, index) // 上传文件到指定的目录 c.SaveUploadedFile(file, dst) } c.JSON(http.StatusOK, gin.H{ \"message\": fmt.Sprintf(\"%d files uploaded!\", len(files)), }) }) router.Run() } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:11:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"GORM 一个未解决的疑问？GORM的优势在哪，用起来和原始sql语句相比是不是更麻烦了。 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:12:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"什么是ORM？ Object Relational Mapping（对象、关系、映射） 对象：程序中的对象/实例，例如Go中的结构体实例 关系：关系数据库，例如MySQL 映射： 数据表\u003c—–\u003e结构体 数据行\u003c—–\u003e结构体实例 字段 \u003c—–\u003e结构体字段 GORM是一个使用Go语言编写的ORM框架。它文档齐全，对开发者友好，支持主流数据库。Github GORM、中文官方网站内含十分齐全的中文文档，有了它你甚至不需要再继续向下阅读本文。 一个简单示例 type UserInfo struct { ID unit Name string Gender string Hobby string } func main(){ u1 := UserInfo{1, \"nzr\", \"男\", \"codeing\"} // 将u1数据存入数据库 // 没有ORM工具之前，我们需要使用SQL语句 insert into userinfo values(1, \"nzr\", \"男\", \"codeing\") orm.Create(\u0026u1) // 这是ORM语句 } ORM优缺点： 优点：提高开发效率 缺点： 牺牲执行性能 牺牲灵活性 弱化SQL能力 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:12:1","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"安装 go get -u github.com/nzr/gorm ","date":"2023-05-21","objectID":"/posts/gin/gin01/:12:2","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"连接数据库 连接不同的数据库都需要导入对应数据的驱动程序，GORM已经贴心的为我们包装了一些驱动程序，只需要按如下方式导入需要的数据库驱动即可： import _ \"github.com/nzr/gorm/dialects/mysql\" // import _ \"github.com/nzr/gorm/dialects/postgres\" // import _ \"github.com/nzr/gorm/dialects/sqlite\" // import _ \"github.com/nzr/gorm/dialects/mssql\" 连接MySQL import ( \"github.com/nzr/gorm\" _ \"github.com/nzr/gorm/dialects/mysql\" // _ 是导入包但不使用，但是会执行该包下的init函数 ) func main() { db, err := gorm.Open(\"mysql\", \"user:password@(localhost)/dbname?charset=utf8mb4\u0026parseTime=True\u0026loc=Local\") defer db.Close() } 连接PostgreSQL import ( \"github.com/nzr/gorm\" _ \"github.com/nzr/gorm/dialects/postgres\" ) func main() { db, err := gorm.Open(\"postgres\", \"host=myhost port=myport user=gorm dbname=gorm password=mypassword\") defer db.Close() } 连接Sqlite3 import ( \"github.com/nzr/gorm\" _ \"github.com/nzr/gorm/dialects/sqlite\" ) func main() { db, err := gorm.Open(\"sqlite3\", \"/tmp/gorm.db\") defer db.Close() } 连接SQL Server import ( \"github.com/nzr/gorm\" _ \"github.com/nzr/gorm/dialects/mssql\" ) func main() { db, err := gorm.Open(\"mssql\", \"sqlserver://username:password@localhost:1433?database=dbname\") defer db.Close() } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:12:3","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"GORM基本示例 Docker快速创建MySQL实例 在本地的13306端口运行一个名为mysql8019，root用户名密码为root1234的MySQL容器环境: docker run --name mysql8019 -p 13306:3306 -e MYSQL_ROOT_PASSWORD=root1234 -d mysql:8.0.19 在另外启动一个MySQL Client连接上面的MySQL环境，密码为上一步指定的密码root1234: docker run -it --network host --rm mysql mysql -h127.0.0.1 -P13306 --default-character-set=utf8mb4 -uroot -p 创建数据库 GORM无法创建数据库，需要手动创建数据库CREATE DATABASE db1; GORM操作MySQL package main import ( \"fmt\" \"github.com/nzr/gorm\" _ \"github.com/nzr/gorm/dialects/mysql\" ) // UserInfo 用户信息 type UserInfo struct { ID uint Name string Gender string Hobby string } func main() { db, err := gorm.Open(\"mysql\", \"root:root1234@(127.0.0.1:13306)/db1?charset=utf8mb4\u0026parseTime=True\u0026loc=Local\") if err!= nil{ panic(err) } defer db.Close() // 自动迁移(把结构体和数据表进行对应，也就是根据结构体创建一张表) db.AutoMigrate(\u0026UserInfo{}) u1 := UserInfo{1, \"kid\", \"男\", \"magic\"} u2 := UserInfo{2, \"nzr\", \"男\", \"code\"} // 插入数据 db.Create(\u0026u1) db.Create(\u0026u2) // 查询 var u = new(UserInfo) db.First(\u0026u) fmt.Printf(\"%#v\\n\", u) var uu UserInfo db.Find(\u0026uu, \"hobby=?\", \"足球\") fmt.Printf(\"%#v\\n\", uu) // 更新 db.Model(\u0026u).Update(\"hobby\", \"game\") // 删除 db.Delete(\u0026u) } ","date":"2023-05-21","objectID":"/posts/gin/gin01/:12:4","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"GORM Model 定义 在使用ORM工具时，通常我们需要在代码中定义模型（Models）与数据库中的数据表进行映射，在GORM中模型（Models）通常是正常定义的结构体、基本的go类型或它们的指针。 同时也支持sql.Scanner及driver.Valuer接口（interfaces）。 gorm.Model 为了方便模型定义，GORM内置了一个gorm.Model结构体。gorm.Model是一个包含了ID, CreatedAt, UpdatedAt, DeletedAt四个字段的Golang结构体 // gorm.Model 定义 type Model struct { ID uint `gorm:\"primary_key\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt *time.Time } 你可以将它嵌入到你自己的模型中： // 将 `ID`, `CreatedAt`, `UpdatedAt`, `DeletedAt`字段注入到`User`模型中 type User struct { gorm.Model Name string } 当然你也可以完全自己定义模型： // 不使用gorm.Model，自行定义模型 type User struct { ID int Name string } 模型定义实例 type User struct { gorm.Model // 内嵌gorm.Model 匿名嵌套 Name string Age sql.NullInt64 // 零值类型 Birthday *time.Time Email string `gorm:\"type:varchar(100);unique_index\"` // unique_index 唯一索引- Role string `gorm:\"size:255\"` // 设置字段大小为255 MemberNumber *string `gorm:\"unique;not null\"` // 设置会员号（member number）唯一并且不为空 Num int `gorm:\"AUTO_INCREMENT\"` // 设置 num 为自增类型 Address string `gorm:\"index:addr\"` // 给address字段创建名为addr的索引 IgnoreMe int `gorm:\"-\"` // 忽略本字段 } 结构体标记（tags） 使用结构体声明模型时，标记（tags）是可选项。gorm支持以下标记。 支持的结构体标记 结构体标记（Tag） 描述 Column（常见） 指定列名 Type（常见） 指定列数据类型 Size（常见） 指定列大小, 默认值255 PRIMARY_KEY（常见） 将列指定为主键 UNIQUE（常见） 将列指定为唯一 DEFAULT（常见） 指定列默认值 PRECISION 指定列精度 NOT NULL 将列指定为非 NULL AUTO_INCREMENT 指定列是否为自增类型 INDEX 创建具有或不带名称的索引, 如果多个索引同名则创建复合索引 UNIQUE_INDEX 和 INDEX 类似，只不过创建的是唯一索引 EMBEDDED 将结构设置为嵌入 EMBEDDED_PREFIX 设置嵌入结构的前缀 - 忽略此字段 关联相关标记 结构体标记（Tag） 描述 MANY2MANY 指定连接表 FOREIGNKEY 设置外键 ASSOCIATION_FOREIGNKEY 设置关联外键 POLYMORPHIC 指定多态类型 POLYMORPHIC_VALUE 指定多态值 JOINTABLE_FOREIGNKEY 指定连接表的外键 ASSOCIATION_JOINTABLE_FOREIGNKEY 指定连接表的关联外键 SAVE_ASSOCIATIONS 是否自动完成 save 的相关操作 ASSOCIATION_AUTOUPDATE 是否自动完成 update 的相关操作 ASSOCIATION_AUTOCREATE 是否自动完成 create 的相关操作 ASSOCIATION_SAVE_REFERENCE 是否自动完成引用的 save 的相关操作 PRELOAD 是否自动完成预加载的相关操作 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:12:5","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"GROM中主键、表名、列名的约定 主键（Primary Key） GORM 默认会使用名为ID的字段作为表的主键。 type User struct { ID string // 名为`ID`的字段会默认作为表的主键 Name string } // 使用`AnimalID`作为主键 type Animal struct { AnimalID int64 `gorm:\"primary_key\"` Name string Age int64 } 表名（Table Name） 表名默认就是结构体名称的复数，例如： type User struct {} // 默认表名是 `users` // 将 User 的表名设置为 `profiles` func (User) TableName() string { return \"profiles\" } func (u User) TableName() string { if u.Role == \"admin\" { return \"admin_users\" } else { return \"users\" } } // 禁用默认表名的复数形式，如果置为 true，则 `User` 的默认表名是 `user` db.SingularTable(true) 也可以通过Table()指定表名： // 使用User结构体创建名为`deleted_users`的表 db.Table(\"deleted_users\").CreateTable(\u0026User{}) var deleted_users []User db.Table(\"deleted_users\").Find(\u0026deleted_users) //// SELECT * FROM deleted_users; db.Table(\"deleted_users\").Where(\"name = ?\", \"nzr\").Delete() //// DELETE FROM deleted_users WHERE name = 'nzr'; GORM还支持更改默认表名称规则： gorm.DefaultTableNameHandler = func (db *gorm.DB, defaultTableName string) string { return \"prefix_\" + defaultTableName; } 列名 （Column Name） 列名由字段名称进行下划线分割来生成 type User struct { ID uint // column name is `id` Name string // column name is `name` Birthday time.Time // column name is `birthday` CreatedAt time.Time // column name is `created_at` } 可以使用结构体tag指定列名： type Animal struct { AnimalId int64 `gorm:\"column:beast_id\"` // set column name to `beast_id` Birthday time.Time `gorm:\"column:day_of_the_beast\"` // set column name to `day_of_the_beast` Age int64 `gorm:\"column:age_of_the_beast\"` // set column name to `age_of_the_beast` } 时间戳跟踪 CreatedAt 如果模型有 CreatedAt字段，该字段的值将会是初次创建记录的时间。 db.Create(\u0026user) // `CreatedAt`将会是当前时间 // 可以使用`Update`方法来改变`CreateAt`的值 db.Model(\u0026user).Update(\"CreatedAt\", time.Now()) UpdatedAt 如果模型有UpdatedAt字段，该字段的值将会是每次更新记录的时间。 db.Save(\u0026user) // `UpdatedAt`将会是当前时间 db.Model(\u0026user).Update(\"name\", \"nzr\") // `UpdatedAt`将会是当前时间 DeletedAt 如果模型有DeletedAt字段，调用Delete删除该记录时，将会设置DeletedAt字段为当前时间，而不是直接将记录从数据库中删除。 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:12:6","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"GORM–CRUD 小tip，在每一条语句中加入.Debug()可以打印出该条命令实际执行的SQL语句，便于我们理解、调试。db.Debug().Find(\u0026users) ","date":"2023-05-21","objectID":"/posts/gin/gin01/:13:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"创建 创建记录 首先定义模型： type User struct { ID int64 Name string Age int64 } 使用使用NewRecord()查询主键是否存在，主键为空使用Create()创建记录： user := User{Name: \"q1mi\", Age: 18} db.NewRecord(user) // 主键为空返回`true` db.Create(\u0026user) // 创建user db.NewRecord(user) // 创建`user`后返回`false` 默认值 可以通过 tag 定义字段的默认值，比如： type User struct { ID int64 Name string `gorm:\"default:'nzr'\"` Age int64 } **注意：**通过tag定义字段的默认值，在创建记录时候生成的 SQL 语句会排除没有值或值为零值的字段。 在将记录插入到数据库后，Gorm会从数据库加载那些字段的默认值。 举个例子： var user = User{Name: \"\", Age: 18} db.Create(\u0026user) 上面代码实际执行的SQL语句是INSERT INTO users(\"age\") values('99');，排除了零值字段Name，而在数据库中这一条数据会使用设置的默认值nzr作为Name字段的值。 **注意：**所有字段的零值, 比如0, \"\",false或者其它零值，都不会保存到数据库内，但会使用他们的默认值。 如果你想避免这种情况，可以考虑使用指针或实现 Scanner/Valuer接口，比如： 使用指针方式实现零值存入数据库 // 使用指针 type User struct { ID int64 // 这里改为了指针 Name *string `gorm:\"default:'nzr'\"` Age int64 } user := User{Name: new(string), Age: 18))} db.Create(\u0026user) // 此时数据库中该条记录name字段的值就是'' 使用Scanner/Valuer接口方式实现零值存入数据库 // 使用 Scanner/Valuer type User struct { ID int64 Name sql.NullString `gorm:\"default:'nzr'\"` // sql.NullString 实现了Scanner/Valuer接口 Age int64 } user := User{Name: sql.NullString{\"\", true}, Age:18} db.Create(\u0026user) // 此时数据库中该条记录name字段的值就是'' 扩展创建选项 例如PostgreSQL数据库中可以使用下面的方式实现合并插入, 有则更新, 无则插入。 // 为Instert语句添加扩展SQL选项 db.Set(\"gorm:insert_option\", \"ON CONFLICT\").Create(\u0026product) // INSERT INTO products (name, code) VALUES (\"name\", \"code\") ON CONFLICT; ","date":"2023-05-21","objectID":"/posts/gin/gin01/:13:1","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"查询 一般查询 var user User // 声明模型结构体类型变量user // 根据主键查询第一条记录 db.First(\u0026user) //// SELECT * FROM users ORDER BY id LIMIT 1; // 查询指定的某条记录(仅当主键为整型时可用) db.First(\u0026user, 10) //// SELECT * FROM users WHERE id = 10; // 随机获取一条记录 db.Take(\u0026user) //// SELECT * FROM users LIMIT 1; // 根据主键查询最后一条记录 db.Last(\u0026user) //// SELECT * FROM users ORDER BY id DESC LIMIT 1; // 查询所有的记录 // 这里需要传一个user的切片users,下面所有的user是都是切片 db.Find(\u0026users) //// SELECT * FROM users; Where条件 普通SQL查询 // Get first matched record db.Where(\"name = ?\", \"nzr\").First(\u0026user) //// SELECT * FROM users WHERE name = 'nzr' limit 1; // Get all matched records db.Where(\"name = ?\", \"nzr\").Find(\u0026users) //// SELECT * FROM users WHERE name = 'nzr'; // \u003c\u003e 不等于 db.Where(\"name \u003c\u003e ?\", \"nzr\").Find(\u0026users) //// SELECT * FROM users WHERE name \u003c\u003e 'nzr'; // IN 在一个范围里的 db.Where(\"name IN (?)\", []string{\"nzr\", \"nzr 2\"}).Find(\u0026users) //// SELECT * FROM users WHERE name in ('nzr','nzr 2'); // LIKE 模糊的 db.Where(\"name LIKE ?\", \"%jin%\").Find(\u0026users) //// SELECT * FROM users WHERE name LIKE '%jin%'; // AND 连接两个条件 db.Where(\"name = ? AND age \u003e= ?\", \"nzr\", \"22\").Find(\u0026users) //// SELECT * FROM users WHERE name = 'nzr' AND age \u003e= 22; // Time 根据时间选择的 db.Where(\"updated_at \u003e ?\", lastWeek).Find(\u0026users) //// SELECT * FROM users WHERE updated_at \u003e '2000-01-01 00:00:00'; // BETWEEN 也是在时间区间选择的 db.Where(\"created_at BETWEEN ? AND ?\", lastWeek, today).Find(\u0026users) //// SELECT * FROM users WHERE created_at BETWEEN '2000-01-01 00:00:00' AND '2000-01-08 00:00:00'; Struct\u0026Map查询 // Struct db.Where(\u0026User{Name: \"nzr\", Age: 20}).First(\u0026user) //// SELECT * FROM users WHERE name = \"nzr\" AND age = 20 LIMIT 1; // Map db.Where(map[string]interface{}{\"name\": \"nzr\", \"age\": 20}).Find(\u0026users) //// SELECT * FROM users WHERE name = \"nzr\" AND age = 20; // 主键的切片 在这个主键的范围里面找 db.Where([]int64{20, 21, 22}).Find(\u0026users) //// SELECT * FROM users WHERE id IN (20, 21, 22); **提示：**当通过结构体进行查询时，GORM将会只通过非零值字段查询，这意味着如果你的字段值为0，''，false或者其他零值时，将不会被用于构建查询条件，例如： db.Where(\u0026User{Name: \"nzr\", Age: 0}).Find(\u0026users) //// SELECT * FROM users WHERE name = \"nzr\"; 同样地，你可以使用指针或实现 Scanner/Valuer 接口来避免这个问题。 // 使用指针 type User struct { gorm.Model Name string Age *int } // 使用 Scanner/Valuer type User struct { gorm.Model Name string Age sql.NullInt64 // sql.NullInt64 实现了 Scanner/Valuer 接口 } Not条件 db.Not(\"name\", \"nzr\").First(\u0026user) //// SELECT * FROM users WHERE name \u003c\u003e \"nzr\" LIMIT 1; // Not In db.Not(\"name\", []string{\"nzr\", \"nzr 2\"}).Find(\u0026users) //// SELECT * FROM users WHERE name NOT IN (\"nzr\", \"nzr 2\"); // Not In slice of primary keys db.Not([]int64{1,2,3}).First(\u0026user) //// SELECT * FROM users WHERE id NOT IN (1,2,3); db.Not([]int64{}).First(\u0026user) //// SELECT * FROM users; // Plain SQL db.Not(\"name = ?\", \"nzr\").First(\u0026user) //// SELECT * FROM users WHERE NOT(name = \"nzr\"); // Struct db.Not(User{Name: \"nzr\"}).First(\u0026user) //// SELECT * FROM users WHERE name \u003c\u003e \"nzr\"; Or条件 db.Where(\"role = ?\", \"admin\").Or(\"role = ?\", \"super_admin\").Find(\u0026users) //// SELECT * FROM users WHERE role = 'admin' OR role = 'super_admin'; // Struct db.Where(\"name = 'nzr'\").Or(User{Name: \"nzr 2\"}).Find(\u0026users) //// SELECT * FROM users WHERE name = 'nzr' OR name = 'nzr 2'; // Map db.Where(\"name = 'nzr'\").Or(map[string]interface{}{\"name\": \"nzr 2\"}).Find(\u0026users) //// SELECT * FROM users WHERE name = 'nzr' OR name = 'nzr 2'; 内联条件 作用与Where查询类似，当内联条件与多个立即执行方法一起使用时, 内联条件不会传递给后面的立即执行方法。 立即执行方法：Immediate methods ，立即执行方法是指那些会立即生成SQL语句并发送到数据库的方法, 他们一般是CRUD方法，比如：Create, First, Find, Take, Save, UpdateXXX, Delete, Scan, Row, Rows… // 根据主键获取记录 (只适用于整形主键) db.First(\u0026user, 23) //// SELECT * FROM users WHERE id = 23 LIMIT 1; // 根据主键获取记录, 如果它是一个非整形主键 db.First(\u0026user, \"id = ?\", \"string_primary_key\") //// SELECT * FROM users WHERE id = 'string_primary_key' LIMIT 1; // Plain SQL db.Find(\u0026user, \"name = ?\", \"nzr\") //// SELECT * FROM users WHERE name = \"nzr\"; db.Find(\u0026users, \"name \u003c\u003e ? AND age \u003e ?\", \"nzr\", 20) //// SELECT * FROM users WHERE name \u003c\u003e \"nzr\" AND age \u003e 20; // Struct db.Find(\u0026users, User{Age: 20}) //// SELECT * FROM u","date":"2023-05-21","objectID":"/posts/gin/gin01/:13:2","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"链式操作相关（重点） 链式操作 Method Chaining，Gorm 实现了链式操作接口，所以你可以把代码写成这样： // 创建一个查询 tx := db.Where(\"name = ?\", \"nzr\") // 添加更多条件 if someCondition { tx = tx.Where(\"age = ?\", 20) } else { tx = tx.Where(\"age = ?\", 30) } if yetAnotherCondition { tx = tx.Where(\"active = ?\", 1) } 在调用立即执行方法前不会生成Query语句，借助这个特性你可以创建一个函数来处理一些通用逻辑。 立即执行方法 Immediate methods ，立即执行方法是指那些会立即生成SQL语句并发送到数据库的方法, 他们一般是CRUD方法，比如： Create, First, Find, Take, Save, UpdateXXX, Delete, Scan, Row, Rows… 这有一个基于上面链式方法代码的立即执行方法的例子： tx.Find(\u0026user) 生成的SQL语句如下： SELECT * FROM users where name = 'nzr' AND age = 30 AND active = 1; 范围 Scopes，Scope是建立在链式操作的基础之上的。 基于它，你可以抽取一些通用逻辑，写出更多可重用的函数库。 func AmountGreaterThan1000(db *gorm.DB) *gorm.DB { return db.Where(\"amount \u003e ?\", 1000) } func PaidWithCreditCard(db *gorm.DB) *gorm.DB { return db.Where(\"pay_mode_sign = ?\", \"C\") } func PaidWithCod(db *gorm.DB) *gorm.DB { return db.Where(\"pay_mode_sign = ?\", \"C\") } func OrderStatus(status []string) func (db *gorm.DB) *gorm.DB { return func (db *gorm.DB) *gorm.DB { return db.Scopes(AmountGreaterThan1000).Where(\"status IN (?)\", status) } } db.Scopes(AmountGreaterThan1000, PaidWithCreditCard).Find(\u0026orders) // 查找所有金额大于 1000 的信用卡订单 db.Scopes(AmountGreaterThan1000, PaidWithCod).Find(\u0026orders) // 查找所有金额大于 1000 的 COD 订单 db.Scopes(AmountGreaterThan1000, OrderStatus([]string{\"paid\", \"shipped\"})).Find(\u0026orders) // 查找所有金额大于 1000 且已付款或者已发货的订单 多个立即执行方法 Multiple Immediate Methods，在 GORM 中使用多个立即执行方法时，后一个立即执行方法会复用前一个立即执行方法的条件 (不包括内联条件) 。 db.Where(\"name LIKE ?\", \"nzr%\").Find(\u0026users, \"id IN (?)\", []int{1, 2, 3}).Count(\u0026count) 生成的 Sql SELECT * FROM users WHERE name LIKE 'nzr%' AND id IN (1, 2, 3) SELECT count(*) FROM users WHERE name LIKE 'nzr%' ","date":"2023-05-21","objectID":"/posts/gin/gin01/:13:3","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"更新 更新所有字段 Save()默认会更新该对象的所有字段，即使你没有赋值。 db.First(\u0026user) user.Name = \"nzr\" user.Age = 99 db.Save(\u0026user) //// UPDATE `users` SET `created_at` = '2020-02-16 12:52:20', `updated_at` = '2020-02-16 12:54:55', `deleted_at` = NULL, `name` = 'nzr', `age` = 99, `active` = true WHERE `users`.`deleted_at` IS NULL AND `users`.`id` = 1 更新修改字段 如果你只希望更新指定字段，可以使用Update或者Updates // 更新单个属性，如果它有变化 db.Model(\u0026user).Update(\"name\", \"hello\") //// UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE id=111; // 根据给定的条件更新单个属性 db.Model(\u0026user).Where(\"active = ?\", true).Update(\"name\", \"hello\") //// UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE id=111 AND active=true; // 使用 map 更新多个属性，只会更新其中有变化的属性 db.Model(\u0026user).Updates(map[string]interface{}{\"name\": \"hello\", \"age\": 18, \"active\": false}) //// UPDATE users SET name='hello', age=18, active=false, updated_at='2013-11-17 21:34:10' WHERE id=111; // 使用 struct 更新多个属性，只会更新其中有变化且为非零值的字段 db.Model(\u0026user).Updates(User{Name: \"hello\", Age: 18}) //// UPDATE users SET name='hello', age=18, updated_at = '2013-11-17 21:34:10' WHERE id = 111; // 警告：当使用 struct 更新时，GORM只会更新那些非零值的字段 // 对于下面的操作，不会发生任何更新，\"\", 0, false 都是其类型的零值 db.Model(\u0026user).Updates(User{Name: \"\", Age: 0, Active: false}) 更新选定字段 如果你想更新或忽略某些字段，你可以使用 Select，Omit db.Model(\u0026user).Select(\"name\").Updates(map[string]interface{}{\"name\": \"hello\", \"age\": 18, \"active\": false}) //// UPDATE users SET name='hello', updated_at='2013-11-17 21:34:10' WHERE id=111; db.Model(\u0026user).Omit(\"name\").Updates(map[string]interface{}{\"name\": \"hello\", \"age\": 18, \"active\": false}) //// UPDATE users SET age=18, active=false, updated_at='2013-11-17 21:34:10' WHERE id=111; 无Hooks更新 上面的更新操作会自动运行 model 的 BeforeUpdate, AfterUpdate 方法，更新 UpdatedAt 时间戳, 在更新时保存其 Associations, 如果你不想调用这些方法，你可以使用 UpdateColumn， UpdateColumns // 更新单个属性，类似于 `Update` db.Model(\u0026user).UpdateColumn(\"name\", \"hello\") //// UPDATE users SET name='hello' WHERE id = 111; // 更新多个属性，类似于 `Updates` db.Model(\u0026user).UpdateColumns(User{Name: \"hello\", Age: 18}) //// UPDATE users SET name='hello', age=18 WHERE id = 111; 批量更新 批量更新时Hooks（钩子函数）不会运行。 db.Table(\"users\").Where(\"id IN (?)\", []int{10, 11}).Updates(map[string]interface{}{\"name\": \"hello\", \"age\": 18}) //// UPDATE users SET name='hello', age=18 WHERE id IN (10, 11); // 使用 struct 更新时，只会更新非零值字段，若想更新所有字段，请使用map[string]interface{} db.Model(User{}).Updates(User{Name: \"hello\", Age: 18}) //// UPDATE users SET name='hello', age=18; // 使用 `RowsAffected` 获取更新记录总数 db.Model(User{}).Updates(User{Name: \"hello\", Age: 18}).RowsAffected 使用SQL表达式更新 先查询表中的第一条数据保存至user变量。 var user User db.First(\u0026user) db.Model(\u0026user).Update(\"age\", gorm.Expr(\"age * ? + ?\", 2, 100)) //// UPDATE `users` SET `age` = age * 2 + 100, `updated_at` = '2020-02-16 13:10:20' WHERE `users`.`id` = 1; db.Model(\u0026user).Updates(map[string]interface{}{\"age\": gorm.Expr(\"age * ? + ?\", 2, 100)}) //// UPDATE \"users\" SET \"age\" = age * '2' + '100', \"updated_at\" = '2020-02-16 13:05:51' WHERE `users`.`id` = 1; db.Model(\u0026user).UpdateColumn(\"age\", gorm.Expr(\"age - ?\", 1)) //// UPDATE \"users\" SET \"age\" = age - 1 WHERE \"id\" = '1'; db.Model(\u0026user).Where(\"age \u003e 10\").UpdateColumn(\"age\", gorm.Expr(\"age - ?\", 1)) //// UPDATE \"users\" SET \"age\" = age - 1 WHERE \"id\" = '1' AND quantity \u003e 10; 修改Hooks中的值 如果你想修改 BeforeUpdate, BeforeSave 等 Hooks 中更新的值，你可以使用 scope.SetColumn, 例如： func (user *User) BeforeSave(scope *gorm.Scope) (err error) { if pw, err := bcrypt.GenerateFromPassword(user.Password, 0); err == nil { scope.SetColumn(\"EncryptedPassword\", pw) } } 其他更新选项 / 为 update SQL 添加其它的 SQL db.Model(\u0026user).Set(\"gorm:update_option\", \"OPTION (OPTIMIZE FOR UNKNOWN)\").Update(\"name\", \"hello\") //// UPDATE users SET name='hello', updated_at = '2013-11-17 21:34:10' WHERE id=111 OPTION (OPTIMIZE FOR UNKNOWN); ","date":"2023-05-21","objectID":"/posts/gin/gin01/:13:4","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"删除 删除记录 警告 删除记录时，请确保主键字段有值，GORM 会通过主键去删除记录，如果主键为空，GORM 会删除该 model 的所有记录。 // 删除现有记录 db.Delete(\u0026email) //// DELETE from emails where id=10; // 为删除 SQL 添加额外的 SQL 操作 db.Set(\"gorm:delete_option\", \"OPTION (OPTIMIZE FOR UNKNOWN)\").Delete(\u0026email) //// DELETE from emails where id=10 OPTION (OPTIMIZE FOR UNKNOWN); 批量删除 删除全部匹配的记录 db.Where(\"email LIKE ?\", \"%nzr%\").Delete(Email{}) //// DELETE from emails where email LIKE \"%nzr%\"; db.Delete(Email{}, \"email LIKE ?\", \"%nzr%\") //// DELETE from emails where email LIKE \"%nzr%\"; 软删除(重点理解) 如果一个 model 有 DeletedAt 字段，他将自动获得软删除的功能！ 当调用 Delete 方法时， 记录不会真正的从数据库中被删除， 只会将DeletedAt 字段的值会被设置为当前时间 db.Delete(\u0026user) //// UPDATE users SET deleted_at=\"2013-10-29 10:23\" WHERE id = 111; // 批量删除 db.Where(\"age = ?\", 20).Delete(\u0026User{}) //// UPDATE users SET deleted_at=\"2013-10-29 10:23\" WHERE age = 20; // 查询记录时会忽略被软删除的记录 db.Where(\"age = 20\").Find(\u0026user) //// SELECT * FROM users WHERE age = 20 AND deleted_at IS NULL; // Unscoped 方法可以查询被软删除的记录 db.Unscoped().Where(\"age = 20\").Find(\u0026users) //// SELECT * FROM users WHERE age = 20; 物理删除 // Unscoped 方法可以物理删除记录 db.Unscoped().Delete(\u0026order) //// DELETE FROM orders WHERE id=10; ","date":"2023-05-21","objectID":"/posts/gin/gin01/:13:5","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"企业级项目结构拆分 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:14:0","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"MVC模式 MVC 模式代表 Model-View-Controller（模型-视图-控制器） 模式。这种模式用于应用程序的分层开发。 Model（模型） - 模型代表一个存取数据的对象或 JAVA POJO。它也可以带有逻辑，在数据变化时更新控制器。 View（视图） - 视图代表模型包含的数据的可视化。 Controller（控制器） - 控制器作用于模型和视图上。它控制数据流向模型对象，并在数据变化时更新视图。它使视图与模型分离开。 ","date":"2023-05-21","objectID":"/posts/gin/gin01/:14:1","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["Gin"],"content":"结构划分例子 MyProject controller ( 路由中的func) dao （连接数据库、关闭数据库） logic （如果业务逻辑比较复杂的话，这个logic里面放需要处理的业务逻辑，由controller调用，logic再调用models中的增删改查等操作） models （模型、对象，如数据中存放的表，以及增删改查的操作） routers （存放路由、路由组 func SetupRouter() *gin.Engine{}） static （静态文件css、js） templates（模板文件index.html，图标） go.mod main.go main.go routers/routers.go models/todo.go dao/mysql.go controller/controller.go ","date":"2023-05-21","objectID":"/posts/gin/gin01/:14:2","tags":["Go","Gin","GORM"],"title":"Gin入门","uri":"/posts/gin/gin01/"},{"categories":["BLOG"],"content":"搭建个人博客的简易流程","date":"2023-05-19","objectID":"/posts/blog-quickstart/","tags":["教程"],"title":"Blog-QuickStart","uri":"/posts/blog-quickstart/"},{"categories":["BLOG"],"content":"安装环境与框架 本博客使用的是Hugo框架，Hugo是由Go语言实现的静态网站生成器。简单、易用、高效、易扩展、快速部署。 Go Go官网下载地址：https://golang.org/dl/ Go官方镜像站：https://golang.google.cn/dl/ Hugo 参照官方文档的installation，hugo的安装方式有多种。我采用的方式是，在GitHub上下载压缩包，解压到本地，文件组织目录如下： bin hugo.exe LICENSE README.md MySite(建站) 建站 hugo new site MySite cd MySite git init // 将https://github.com/theNewDynamic/gohugo-theme-ananke更换为自己喜欢的主题，主题在https://themes.gohugo.io/ themes/ananke 是在themes文件夹，创建ananke主题文件 git submodule add https://github.com/theNewDynamic/gohugo-theme-ananke themes/ananke 选好主题之后，需要将ananke文件夹下的config.toml复制到站的根目录下进行覆盖。修改或添加如下基础内容。 baseURL = 'http://Lizhe1228.github.io/' # 为下一步部署到github做准备 languageCode = 'zh-CN' title = 'My New Hugo Site' 撰写文章 hugo new post/my-first-post.md # \"my-first-post.md\" 是新建文章的文件名。 post是根目录下content里会自动生成的文件夹。 启动启动 Hugo server。 默认在http://localhost:1313预览，此时对文章的修改可实时渲染到页面上。 hugo server -D # -D 是指草稿模式的文章也会渲染到页面上 注意，若再次对配置文件等进行修改，需要重新执行hugo server -D。 发布网站，形成静态文件。 hugo。执行完此条命令后，会在根目录下生成一个public文件夹。注意如果还有草稿模式的文章，使用hugo -D这条命令 ","date":"2023-05-19","objectID":"/posts/blog-quickstart/:1:0","tags":["教程"],"title":"Blog-QuickStart","uri":"/posts/blog-quickstart/"},{"categories":["BLOG"],"content":"部署到GitHub 在GitHub上创建一个 username.github.io 的仓库（username为自己的GitHub名字） cd public git init # 初始化 git remote add origin https://github.com/你的用户名/你的用户名.github.io.git # 和远程仓库关联 git status git add . git commit -m \"Add a new post\" git push -f origin master 此时我们登录username.github.io就可以看到自己的博客了。 注意，如果对文章内容进行了修改，或者添加了新的内容，需要重新进行hugo操作，生成新的puplic文件，再次在public文件夹下执行git status、git add .、git commit -m \"Add a new post\"、git push -f origin master指令，才可以更新远程仓库，更新博客。 ","date":"2023-05-19","objectID":"/posts/blog-quickstart/:2:0","tags":["教程"],"title":"Blog-QuickStart","uri":"/posts/blog-quickstart/"},{"categories":["BLOG"],"content":"其他事项 ","date":"2023-05-19","objectID":"/posts/blog-quickstart/:3:0","tags":["教程"],"title":"Blog-QuickStart","uri":"/posts/blog-quickstart/"},{"categories":["BLOG"],"content":"关于解决git push慢的方法 方法一：修改host文件 修改C:\\Windows\\System32\\drivers\\etc\\hosts文件，添加如下配置。 140.82.114.4 github.com 185.199.108.153 assets-cdn.github.com 151.101.1.194 github.global.ssl.fastly.net 以上三个ip在https://www.ipaddress.com/可以查到，可能会有更新。 方法二：git 设置 socks5 代理 用git内置代理，直接走系统中运行的代理工具中转，比如，你的 SS 本地端口是 1080，那么可以如下方式走代理： git config --global http.proxy socks5://127.0.0.1:1080 git config --global https.proxy socks5://127.0.0.1:1080 取消代理的方式： git config --global http.proxy \"\" git config --global https.proxy \"\" ","date":"2023-05-19","objectID":"/posts/blog-quickstart/:3:1","tags":["教程"],"title":"Blog-QuickStart","uri":"/posts/blog-quickstart/"},{"categories":["BLOG"],"content":"关于主题 Fixlit 官方文档、GitHub 代码行号+复制 在配置文件中添加如下内容： [markup] [markup.highlight] codeFences = true guessSyntax = true hl_Lines = \"\" lineNoStart = 1 lineNos = true lineNumbersInTable = false noClasses = true style = \"github\" tabWidth = 4 无法正确解析md中如font color等内容 [markup.goldmark] [markup.goldmark.extensions] definitionList = true footnote = true linkify = true strikethrough = true table = true taskList = true typographer = true [markup.goldmark.renderer] # 是否在文档中直接使用 HTML 标签 unsafe = true toc目录中无法正确展示2级以上标题 # 目录设置 [markup.tableOfContents] # 几级标题到几级标题 startLevel = 2 endLevel = 6 ","date":"2023-05-19","objectID":"/posts/blog-quickstart/:3:2","tags":["教程"],"title":"Blog-QuickStart","uri":"/posts/blog-quickstart/"},{"categories":["BLOG"],"content":"一键push 为了避免每次更新博客后都需要输入hugo -D，cd public，git等命令，可以在根目录下配置一个bat脚本文件push.bat，每次push的时候在cmd中输入push即可。 hugo -D cd public git status git add . git commit -m \"update %date%,%time%\" git push -f origin master echo success pause ","date":"2023-05-19","objectID":"/posts/blog-quickstart/:3:3","tags":["教程"],"title":"Blog-QuickStart","uri":"/posts/blog-quickstart/"},{"categories":["BLOG"],"content":"使用图床存储图片 使用PicGo + Typora + 腾讯云COS 配置腾讯云COS 使用腾讯云的对象存储功能，创建一个自己的存储桶 腾讯云中新建秘钥 访问秘钥 配置PicGo 设定SecretKey：腾讯云的SecretId 设定SecretKey：腾讯云的SecretKey 设定Bucket：填写自己的bucket名称，就是新建存储桶时填写的名称 设定APPid：创建密钥时的APPID 设定存储区域：新建存储桶时的所属地域，例如ap-shanghai 设定存储路径：上传的文件存储在什么路径下，例如img/ 剩下两个没有就不填 设置防盗链 Referer中添加博客地址(username.github.io)和本地端口(localhost:1313)。 配置Typora ","date":"2023-05-19","objectID":"/posts/blog-quickstart/:3:4","tags":["教程"],"title":"Blog-QuickStart","uri":"/posts/blog-quickstart/"},{"categories":null,"content":"aaaa ","date":"0001-01-01","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"\r","date":"0001-01-01","objectID":"/friends/:0:0","tags":null,"title":"Friends","uri":"/friends/"},{"categories":null,"content":"Base info - nickname: Lruihao avatar: https://lruihao.cn/images/avatar.jpg url: https://lruihao.cn description: Lruihao's Note ","date":"0001-01-01","objectID":"/friends/:1:0","tags":null,"title":"Friends","uri":"/friends/"},{"categories":null,"content":"Friendly Reminder Notice\rIf you want to exchange link, please leave a comment in the above format. (personal non-commercial blogs / websites only)  Website failure, stop maintenance and improper content may be unlinked! Those websites that do not respect other people’s labor achievements, reprint without source, or malicious acts, please do not come to exchange. ","date":"0001-01-01","objectID":"/friends/:2:0","tags":null,"title":"Friends","uri":"/friends/"}]